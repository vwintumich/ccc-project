{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4aa395",
   "metadata": {},
   "source": [
    "# Stage 3: Dimensionality Reduction\n",
    "\n",
    "**Primary author:** Victoria\n",
    "**Builds on:**\n",
    "- *Hierarchical_Clustering_Indicators_with_BGE_M3_Embeddings.ipynb* (Victoria/Sahana — UMAP reduction approach)\n",
    "- *NC_PCA_Analysis.ipynb* (Nathan — PCA exploration and visualization approach)\n",
    "- `02_embedding_generation.ipynb` (Stage 2 output: BGE-M3 embeddings)\n",
    "\n",
    "**Prompt engineering:** Victoria\n",
    "**AI assistance:** Claude (Anthropic)\n",
    "**Environment:** Great Lakes or Colab (GPU helps for UMAP)\n",
    "\n",
    "This notebook takes the 1024-dimensional BGE-M3 embeddings from Stage 2 and reduces them\n",
    "to lower dimensions for two purposes:\n",
    "1. **10 dimensions** for clustering input (Stage 4) — reduces noise while preserving structure\n",
    "2. **2 dimensions** for visualization (Stage 5) — enables scatter plots of the embedding space\n",
    "\n",
    "Two methods are applied: PCA (linear baseline) and UMAP (nonlinear, structure-preserving)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a8d7f",
   "metadata": {},
   "source": [
    "## Running on Google Colab\n",
    "\n",
    "If running on Google Colab:\n",
    "\n",
    "1. Go to **Runtime > Change runtime type**\n",
    "2. Select a **GPU** accelerator (T4 is sufficient)\n",
    "3. Click **Save**, then run all cells\n",
    "\n",
    "UMAP benefits from GPU acceleration but will run on CPU in ~2-5 minutes for this dataset\n",
    "size. PCA runs instantly on any hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062066a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import umap  # install via: pip install umap-learn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f137a",
   "metadata": {},
   "source": [
    "## Environment Auto-Detection and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03e337",
   "metadata": {},
   "outputs": [],
   "source": "# --- Environment Auto-Detection ---\ntry:\n    IS_COLAB = 'google.colab' in str(get_ipython())\nexcept NameError:\n    IS_COLAB = False\nIS_GREATLAKES = 'SLURM_JOB_ID' in os.environ  # Great Lakes sets this automatically\n\nif IS_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    PROJECT_ROOT = Path('/content/drive/MyDrive/SIADS 692 Milestone II/Milestone II - NLP Cryptic Crossword Clues')\nelif IS_GREATLAKES:\n    # Update YOUR_UNIQNAME to your actual UMich uniqname\n    PROJECT_ROOT = Path('/scratch/YOUR_UNIQNAME/ccc_project')\nelse:\n    # Local: move up from notebooks/ to project root\n    PROJECT_ROOT = Path.cwd().parent\n\nDATA_DIR = PROJECT_ROOT / 'data'\nOUTPUT_DIR = PROJECT_ROOT / 'outputs'\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f'Project root: {PROJECT_ROOT}')\nprint(f'Data directory: {DATA_DIR}')\nprint(f'Output directory: {OUTPUT_DIR}')"
  },
  {
   "cell_type": "markdown",
   "id": "puezovt3iar",
   "source": "**Note:** All figures produced by this notebook are saved as `.png` files to the\n`outputs/` directory (`OUTPUT_DIR`) for viewing outside the notebook environment.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93361d2e",
   "metadata": {},
   "source": [
    "## Input File Validation\n",
    "\n",
    "Before proceeding, we verify that the required input files from Stage 2 exist.\n",
    "These are produced by `02_embedding_generation.ipynb`:\n",
    "\n",
    "- `embeddings_bge_m3_all.npy` — the 1024-dimensional BGE-M3 embedding matrix\n",
    "- `indicator_index_all.csv` — maps each row index to its indicator string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that both input files exist before proceeding\n",
    "embedding_file = DATA_DIR / 'embeddings_bge_m3_all.npy'\n",
    "index_file = DATA_DIR / 'indicator_index_all.csv'\n",
    "\n",
    "assert embedding_file.exists(), (\n",
    "    f'Missing embedding file: {embedding_file}\\n'\n",
    "    f'Run 02_embedding_generation.ipynb first to produce this file.'\n",
    ")\n",
    "assert index_file.exists(), (\n",
    "    f'Missing index file: {index_file}\\n'\n",
    "    f'Run 02_embedding_generation.ipynb first to produce this file.'\n",
    ")\n",
    "\n",
    "print('Input files found:')\n",
    "print(f'  {embedding_file}')\n",
    "print(f'  {index_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b9b6f",
   "metadata": {},
   "source": [
    "## Load Embeddings\n",
    "\n",
    "We load the BGE-M3 embedding matrix and the indicator index. The embedding matrix has\n",
    "shape (12622, 1024) — one 1024-dimensional vector per unique verified indicator. The\n",
    "index CSV maps row number to indicator string so we can trace any point back to its\n",
    "indicator after dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f233bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(embedding_file)\n",
    "df_index = pd.read_csv(index_file, index_col=0)\n",
    "\n",
    "print(f'Embeddings shape: {embeddings.shape}')\n",
    "print(f'Index rows: {len(df_index)}')\n",
    "\n",
    "assert embeddings.shape == (12622, 1024), (\n",
    "    f'Expected shape (12622, 1024), got {embeddings.shape}'\n",
    ")\n",
    "assert len(df_index) == embeddings.shape[0], (\n",
    "    f'Index length {len(df_index)} does not match embedding rows {embeddings.shape[0]}'\n",
    ")\n",
    "\n",
    "print(f'Shape verified: {embeddings.shape[0]:,} indicators x {embeddings.shape[1]} dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5ae0b",
   "metadata": {},
   "source": [
    "## Why Reduce Dimensionality?\n",
    "\n",
    "Our BGE-M3 embeddings live in a 1024-dimensional space. While this high dimensionality\n",
    "captures rich semantic information, it poses challenges for downstream analysis:\n",
    "\n",
    "1. **The curse of dimensionality:** In very high dimensions, distances between points\n",
    "   become increasingly uniform. Clustering algorithms rely on meaningful distance\n",
    "   differences, so this uniformity degrades their performance.\n",
    "\n",
    "2. **Computational cost:** Pairwise distance computation is O(n^2 x d). Reducing d from\n",
    "   1024 to 10 gives a ~100x speedup for distance-based methods like HDBSCAN and DBSCAN.\n",
    "\n",
    "3. **Visualization:** Humans can only perceive 2D or 3D plots. Reducing to 2D lets us\n",
    "   inspect whether the embedding space has visible structure.\n",
    "\n",
    "We apply two methods:\n",
    "- **PCA** (Principal Component Analysis) — a linear projection that maximizes variance.\n",
    "  Fast and deterministic, but cannot capture nonlinear relationships.\n",
    "- **UMAP** (Uniform Manifold Approximation and Projection) — a nonlinear method that\n",
    "  preserves both local neighborhood structure and global topology. Better for semantic\n",
    "  embeddings but slower and stochastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53011e75",
   "metadata": {},
   "source": [
    "## PCA: A Linear Baseline\n",
    "\n",
    "### What is PCA?\n",
    "\n",
    "**Principal Component Analysis (PCA)** finds the directions of maximum variance in the\n",
    "data and projects onto those directions. The first principal component captures the most\n",
    "variance, the second captures the next most (orthogonal to the first), and so on.\n",
    "\n",
    "**Why is PCA a baseline, not our primary method?** PCA assumes that the important structure\n",
    "in the data is linear — that the most informative differences between points lie along\n",
    "straight-line directions. Semantic embeddings, however, often have **nonlinear** structure:\n",
    "words with similar meanings form curved manifolds in high-dimensional space, not flat\n",
    "planes. PCA will miss this curvature and may distort meaningful relationships.\n",
    "\n",
    "We include PCA for two reasons:\n",
    "1. **Comparison:** If UMAP and PCA produce similar clusterings, the structure is linear\n",
    "   and PCA suffices. If UMAP performs much better, the structure is genuinely nonlinear.\n",
    "2. **Explained variance analysis:** PCA's scree plot tells us how much of the total\n",
    "   variance each dimension captures, which helps us understand the intrinsic dimensionality\n",
    "   of the embedding space.\n",
    "\n",
    "Note: PCA implicitly uses Euclidean distance (it maximizes variance, which is based on\n",
    "squared Euclidean distances). For text embeddings, cosine similarity is usually more\n",
    "appropriate — this is one reason we prefer UMAP with `metric='cosine'` for the primary\n",
    "reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4faea80",
   "metadata": {},
   "source": [
    "### Fit PCA and Examine Explained Variance\n",
    "\n",
    "We fit PCA with 100 components (out of 1024) to see how quickly variance is captured.\n",
    "The **scree plot** shows:\n",
    "\n",
    "- Individual explained variance ratio per component (bar plot)\n",
    "- Cumulative explained variance (line plot)\n",
    "\n",
    "**What to look for:** An \"elbow\" in the cumulative curve indicates a natural\n",
    "dimensionality — the point where adding more components yields diminishing returns.\n",
    "If 10 components capture 80%+ of variance, the data is relatively low-dimensional.\n",
    "If 100 components are needed for 80%, the structure is more distributed across\n",
    "many dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0636a",
   "metadata": {},
   "outputs": [],
   "source": "# Fit PCA with 100 components to examine the variance structure\npca_full = PCA(n_components=100, random_state=42)\npca_full.fit(embeddings)\n\n# Print cumulative variance at key thresholds\ncumvar = np.cumsum(pca_full.explained_variance_ratio_)\nfor threshold in [0.50, 0.80, 0.90, 0.95, 0.99]:\n    n_needed = np.searchsorted(cumvar, threshold) + 1\n    print(f'{threshold:.0%} variance explained by {n_needed} components')\n\n# Scree plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: individual explained variance (first 50 components)\nax1.bar(range(1, 51), pca_full.explained_variance_ratio_[:50],\n        color='steelblue', alpha=0.8)\nax1.set_xlabel('Principal Component')\nax1.set_ylabel('Explained Variance Ratio')\nax1.set_title('Individual Explained Variance (first 50 components)')\n\n# Right: cumulative explained variance (all 100 components)\nax2.plot(range(1, 101), cumvar, 'o-', markersize=3, color='steelblue')\nax2.axhline(y=0.90, color='red', linestyle='--', alpha=0.5, label='90% variance')\nax2.axhline(y=0.80, color='orange', linestyle='--', alpha=0.5, label='80% variance')\nax2.axvline(x=10, color='green', linestyle='--', alpha=0.5, label='10 components')\nax2.set_xlabel('Number of Components')\nax2.set_ylabel('Cumulative Explained Variance')\nax2.set_title('Cumulative Explained Variance')\nax2.legend()\n\nplt.tight_layout()\nfig.savefig(OUTPUT_DIR / 'pca_explained_variance.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "58231586",
   "metadata": {},
   "source": [
    "### Project to 10D and 2D\n",
    "\n",
    "We project the full 1024-dimensional embeddings down to 10 and 2 dimensions using PCA.\n",
    "\n",
    "- **10D PCA** will serve as a baseline for clustering comparison against UMAP 10D in Stage 4.\n",
    "- **2D PCA** will serve as a baseline for visualization comparison against UMAP 2D in Stage 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c934f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to 10 dimensions (for clustering comparison)\n",
    "pca_10d = PCA(n_components=10, random_state=42)\n",
    "embeddings_pca_10d = pca_10d.fit_transform(embeddings)\n",
    "print(f'PCA 10D shape: {embeddings_pca_10d.shape}')\n",
    "print(f'Variance explained by 10 components: {pca_10d.explained_variance_ratio_.sum():.1%}')\n",
    "\n",
    "# Project to 2 dimensions (for visualization comparison)\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "embeddings_pca_2d = pca_2d.fit_transform(embeddings)\n",
    "print(f'PCA 2D shape: {embeddings_pca_2d.shape}')\n",
    "print(f'Variance explained by 2 components: {pca_2d.explained_variance_ratio_.sum():.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa640d34",
   "metadata": {},
   "source": [
    "## UMAP: Nonlinear Dimensionality Reduction\n",
    "\n",
    "### What is UMAP?\n",
    "\n",
    "**UMAP (Uniform Manifold Approximation and Projection)** is a nonlinear dimensionality\n",
    "reduction technique that preserves both local and global structure of high-dimensional\n",
    "data. Unlike PCA, UMAP can capture curved manifolds — for example, if all anagram\n",
    "indicators form a curved cluster in 1024D space, UMAP will preserve that cluster's\n",
    "shape in the reduced space, while PCA might flatten or distort it.\n",
    "\n",
    "UMAP works in two phases:\n",
    "1. **Build a neighborhood graph** in the original high-dimensional space\n",
    "2. **Optimize a low-dimensional layout** that preserves the graph's edge structure\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "- **`n_neighbors`** (default: 15) — Controls the balance between local and global\n",
    "  structure. Small values (5-10) emphasize fine-grained local clusters. Large values\n",
    "  (50+) preserve more global topology but blur local detail. We use 15 as a balanced\n",
    "  starting point.\n",
    "\n",
    "- **`min_dist`** (default: 0.1) — Controls how tightly UMAP packs points together.\n",
    "  Smaller values (0.0-0.05) produce tighter, more separated clusters. Larger values\n",
    "  (0.5-1.0) produce a more uniform spread. We use 0.1 as a moderate default.\n",
    "\n",
    "- **`metric`** — The distance measure used in the original space. We use `'cosine'`\n",
    "  because cosine similarity is the standard metric for comparing text embeddings.\n",
    "  It measures the angle between vectors, making it robust to differences in vector\n",
    "  magnitude.\n",
    "\n",
    "- **`random_state`** — UMAP is stochastic (it uses random initialization and\n",
    "  stochastic gradient descent). Setting `random_state=42` ensures reproducibility\n",
    "  across runs.\n",
    "\n",
    "These parameters have not been systematically tuned (see OPEN_QUESTIONS.md). The\n",
    "values used here are reasonable defaults for a first pass. Stage 4 clustering\n",
    "notebooks should investigate sensitivity to these choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbc4f4",
   "metadata": {},
   "source": [
    "### UMAP to 10 Dimensions (for Clustering Input)\n",
    "\n",
    "The 10-dimensional UMAP embedding is the primary input for clustering in Stage 4.\n",
    "Ten dimensions is a common choice that balances noise reduction with information\n",
    "preservation. This step typically takes 1-3 minutes depending on hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399518f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP reduction to 10 dimensions for clustering input\n",
    "reducer_10d = umap.UMAP(\n",
    "    n_components=10,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "embeddings_umap_10d = reducer_10d.fit_transform(embeddings)\n",
    "print(f'UMAP 10D shape: {embeddings_umap_10d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c9549",
   "metadata": {},
   "source": [
    "### UMAP to 2 Dimensions (for Visualization)\n",
    "\n",
    "The 2-dimensional UMAP embedding is used for scatter plots in Stage 5. Note that\n",
    "UMAP must be fitted separately for each target dimensionality — we cannot simply\n",
    "take the first 2 columns of the 10D output, because UMAP optimizes the layout\n",
    "for the specific number of dimensions requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP reduction to 2 dimensions for visualization\n",
    "reducer_2d = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "embeddings_umap_2d = reducer_2d.fit_transform(embeddings)\n",
    "print(f'UMAP 2D shape: {embeddings_umap_2d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8517f",
   "metadata": {},
   "source": [
    "### Quick Visual Check\n",
    "\n",
    "Before saving, we plot both 2D projections side by side to verify that the reductions\n",
    "look reasonable. At this stage we do not color by cluster or wordplay type — that comes\n",
    "in Stage 5. We are checking that:\n",
    "\n",
    "- Points are not all collapsed to a single blob (would indicate a degenerate reduction)\n",
    "- There is visible structure — clumps, filaments, or separated regions\n",
    "- No obvious artifacts (e.g., a uniform grid pattern would indicate a bug)\n",
    "\n",
    "Expect UMAP to show more distinct clumps than PCA, since UMAP preserves local\n",
    "neighborhood structure while PCA only maximizes variance along linear directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14018d",
   "metadata": {},
   "outputs": [],
   "source": "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# UMAP 2D\nax1.scatter(\n    embeddings_umap_2d[:, 0],\n    embeddings_umap_2d[:, 1],\n    s=1, alpha=0.3, color='steelblue'\n)\nax1.set_title('UMAP 2D Projection')\nax1.set_xlabel('UMAP 1')\nax1.set_ylabel('UMAP 2')\n\n# PCA 2D for comparison\nax2.scatter(\n    embeddings_pca_2d[:, 0],\n    embeddings_pca_2d[:, 1],\n    s=1, alpha=0.3, color='coral'\n)\nax2.set_title('PCA 2D Projection (for comparison)')\nax2.set_xlabel('PC 1')\nax2.set_ylabel('PC 2')\n\nplt.tight_layout()\nfig.savefig(OUTPUT_DIR / 'umap_vs_pca_2d_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\n# Print coordinate ranges as a sanity check\nprint(f'UMAP 2D range — '\n      f'x: [{embeddings_umap_2d[:, 0].min():.1f}, {embeddings_umap_2d[:, 0].max():.1f}], '\n      f'y: [{embeddings_umap_2d[:, 1].min():.1f}, {embeddings_umap_2d[:, 1].max():.1f}]')\nprint(f'PCA 2D range  — '\n      f'x: [{embeddings_pca_2d[:, 0].min():.2f}, {embeddings_pca_2d[:, 0].max():.2f}], '\n      f'y: [{embeddings_pca_2d[:, 1].min():.2f}, {embeddings_pca_2d[:, 1].max():.2f}]')"
  },
  {
   "cell_type": "markdown",
   "id": "2b120439",
   "metadata": {},
   "source": [
    "## Save All Outputs\n",
    "\n",
    "Four files are saved to `DATA_DIR`:\n",
    "\n",
    "| File | Shape | Purpose |\n",
    "|------|-------|---------|\n",
    "| `embeddings_umap_10d.npy` | (12622, 10) | Clustering input for Stage 4 |\n",
    "| `embeddings_umap_2d.npy` | (12622, 2) | Visualization in Stage 5 |\n",
    "| `embeddings_pca_10d.npy` | (12622, 10) | PCA baseline for clustering comparison |\n",
    "| `embeddings_pca_2d.npy` | (12622, 2) | PCA baseline for visualization comparison |\n",
    "\n",
    "Row `i` in every output file corresponds to row `i` in `indicator_index_all.csv`\n",
    "(the same mapping as the input embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_DIR / 'embeddings_umap_10d.npy', embeddings_umap_10d)\n",
    "np.save(DATA_DIR / 'embeddings_umap_2d.npy', embeddings_umap_2d)\n",
    "np.save(DATA_DIR / 'embeddings_pca_10d.npy', embeddings_pca_10d)\n",
    "np.save(DATA_DIR / 'embeddings_pca_2d.npy', embeddings_pca_2d)\n",
    "\n",
    "print('Saved:')\n",
    "for fname in ['embeddings_umap_10d.npy', 'embeddings_umap_2d.npy',\n",
    "              'embeddings_pca_10d.npy', 'embeddings_pca_2d.npy']:\n",
    "    fpath = DATA_DIR / fname\n",
    "    print(f'  {fname} ({fpath.stat().st_size / 1024:.0f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee665c42",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Reload all saved files and verify that shapes match expectations. This catches\n",
    "silent corruption (e.g., truncated writes on network-mounted filesystems like\n",
    "Google Drive or Great Lakes scratch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_shapes = {\n",
    "    'embeddings_umap_10d.npy': (12622, 10),\n",
    "    'embeddings_umap_2d.npy': (12622, 2),\n",
    "    'embeddings_pca_10d.npy': (12622, 10),\n",
    "    'embeddings_pca_2d.npy': (12622, 2),\n",
    "}\n",
    "\n",
    "for fname, expected_shape in expected_shapes.items():\n",
    "    loaded = np.load(DATA_DIR / fname)\n",
    "    assert loaded.shape == expected_shape, (\n",
    "        f'{fname}: expected {expected_shape}, got {loaded.shape}'\n",
    "    )\n",
    "    print(f'{fname}: {loaded.shape} OK')\n",
    "\n",
    "print('\\nAll verification checks passed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}