{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9444644",
   "metadata": {},
   "source": [
    "# Stage 5: Constrained and Targeted Experiments\n",
    "\n",
    "**Primary author:** Victoria\n",
    "**Builds on:** `04_clustering.ipynb` (Stage 4: unconstrained clustering results)\n",
    "**Prompt engineering:** Victoria\n",
    "**AI assistance:** Claude (Anthropic)\n",
    "**Environment:** Great Lakes (for definitions embedding); Colab (for subset experiments); Local (for label evaluation)\n",
    "\n",
    "**Research question: \"Does expert knowledge improve clustering, and do theoretically\n",
    "motivated subsets behave as predicted?\"**\n",
    "\n",
    "Stage 4 asked what structure emerges when we let clustering algorithms explore freely.\n",
    "The answer: strong local structure at fine granularity (282 HDBSCAN clusters, metrics\n",
    "improving up to k=250 for agglomerative), but no natural k=8 grouping and no stable\n",
    "intermediate level in HDBSCAN.\n",
    "\n",
    "This notebook introduces domain knowledge for the first time:\n",
    "- **Wordplay type labels** (Ho blog labels and algorithmically derived GT labels) to\n",
    "  evaluate whether unconstrained clusters correspond to known types\n",
    "- **Seed words** from expert sources to guide constrained clustering\n",
    "- **Subset experiments** to test specific hypotheses about which types should be easy\n",
    "  vs. hard to separate\n",
    "\n",
    "The four sections:\n",
    "1. **Setup, Load Data, Build Label Sets** — load all inputs and create per-indicator\n",
    "   label mappings\n",
    "2. **Label-Based Evaluation of NB 04 Results** — overlay labels on unconstrained\n",
    "   clusters to see what they captured\n",
    "3. **Constrained Agglomerative Clustering** — use seed words to guide clustering\n",
    "4. **Subset Experiments** — test separation and overlap hypotheses on targeted subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7167c1",
   "metadata": {},
   "source": [
    "## Running on Google Colab\n",
    "\n",
    "If running on Google Colab:\n",
    "\n",
    "1. Go to **Runtime > Change runtime type**\n",
    "2. A GPU is not required for Sections 1-2 (label evaluation). GPU is needed only for\n",
    "   definitions embedding in Section 3.\n",
    "3. Click **Save**, then run all cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36da475",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40699a21",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58646e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e48ac5",
   "metadata": {},
   "source": [
    "### Environment Auto-Detection and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d899c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/victoria/Desktop/MADS/ccc-project/indicator_clustering\n",
      "Data directory: /Users/victoria/Desktop/MADS/ccc-project/indicator_clustering/data\n",
      "Output directory: /Users/victoria/Desktop/MADS/ccc-project/indicator_clustering/outputs\n",
      "Figures directory: /Users/victoria/Desktop/MADS/ccc-project/indicator_clustering/outputs/figures\n"
     ]
    }
   ],
   "source": [
    "# --- Environment Auto-Detection ---\n",
    "try:\n",
    "    IS_COLAB = 'google.colab' in str(get_ipython())\n",
    "except NameError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "IS_GREATLAKES = 'SLURM_JOB_ID' in os.environ\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PROJECT_ROOT = Path('/content/drive/MyDrive/SIADS 692 Milestone II/Milestone II - NLP Cryptic Crossword Clues')\n",
    "elif IS_GREATLAKES:\n",
    "    # Update YOUR_UNIQNAME to your actual UMich uniqname\n",
    "    PROJECT_ROOT = Path('/scratch/YOUR_UNIQNAME/ccc_project')\n",
    "else:\n",
    "    try:\n",
    "        PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs'\n",
    "FIGURES_DIR = OUTPUT_DIR / 'figures'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Data directory: {DATA_DIR}')\n",
    "print(f'Output directory: {OUTPUT_DIR}')\n",
    "print(f'Figures directory: {FIGURES_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beda800",
   "metadata": {},
   "source": [
    "### Input File Validation\n",
    "\n",
    "This notebook requires outputs from Stages 1–4. We check that all required files exist\n",
    "before proceeding, rather than failing partway through.\n",
    "\n",
    "| File | Produced by | Description |\n",
    "|------|-------------|-------------|\n",
    "| `embeddings_umap_10d.npy` | Stage 3 | 10D UMAP embeddings for clustering |\n",
    "| `embeddings_umap_2d.npy` | Stage 3 | 2D UMAP embeddings for visualization |\n",
    "| `indicator_index_all.csv` | Stage 2 | Row-to-indicator-string mapping |\n",
    "| `verified_clues_labeled.csv` | Stage 1 | Clue-indicator pairs with Ho and GT labels |\n",
    "| `cluster_labels_hdbscan_eps_0p0000.csv` | Stage 4 | Best HDBSCAN labels (eps=0.0) |\n",
    "| `cluster_labels_agglo_k8.csv` | Stage 4 | Agglomerative k=8 labels |\n",
    "| `cluster_labels_agglo_k10.csv` | Stage 4 | Agglomerative k=10 labels |\n",
    "| `cluster_labels_agglo_k34.csv` | Stage 4 | Agglomerative k=34 labels |\n",
    "| `clustering_metrics_summary.csv` | Stage 4 | Metrics from all Stage 4 runs |\n",
    "| `wordplay_seeds.xlsx` | Manual (expert) | Seed words for constrained clustering (Section 3) |\n",
    "\n",
    "**New in this notebook:** `verified_clues_labeled.csv` and `wordplay_seeds.xlsx`. These\n",
    "were deliberately excluded from Notebook 04 to keep the unconstrained analysis label-free.\n",
    "This is where domain knowledge enters the clustering pipeline for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1136f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All input files found.\n"
     ]
    }
   ],
   "source": [
    "required_files = {\n",
    "    # Stage 2-3: embeddings\n",
    "    'embeddings_umap_10d.npy': 'Run 03_dimensionality_reduction.ipynb',\n",
    "    'embeddings_umap_2d.npy': 'Run 03_dimensionality_reduction.ipynb',\n",
    "    'indicator_index_all.csv': 'Run 02_embedding_generation.ipynb',\n",
    "    # Stage 1: labels\n",
    "    'verified_clues_labeled.csv': 'Run 01_data_cleaning.ipynb',\n",
    "    # Stage 4: cluster assignments\n",
    "    'cluster_labels_hdbscan_eps_0p0000.csv': 'Run 04_clustering.ipynb',\n",
    "    'cluster_labels_agglo_k8.csv': 'Run 04_clustering.ipynb',\n",
    "    'cluster_labels_agglo_k10.csv': 'Run 04_clustering.ipynb',\n",
    "    'cluster_labels_agglo_k34.csv': 'Run 04_clustering.ipynb',\n",
    "    # Seed words (used in Section 3)\n",
    "    'wordplay_seeds.xlsx': 'Manually created from expert sources (Minute Cryptic, CC for Dummies)',\n",
    "}\n",
    "\n",
    "# Metrics summary is in OUTPUT_DIR, not DATA_DIR\n",
    "required_output_files = {\n",
    "    'clustering_metrics_summary.csv': 'Run 04_clustering.ipynb',\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for fname, fix_msg in required_files.items():\n",
    "    fpath = DATA_DIR / fname\n",
    "    if not fpath.exists():\n",
    "        print(f'MISSING: {fpath}')\n",
    "        print(f'  Fix: {fix_msg}')\n",
    "        all_ok = False\n",
    "\n",
    "for fname, fix_msg in required_output_files.items():\n",
    "    fpath = OUTPUT_DIR / fname\n",
    "    if not fpath.exists():\n",
    "        print(f'MISSING: {fpath}')\n",
    "        print(f'  Fix: {fix_msg}')\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print('All input files found.')\n",
    "else:\n",
    "    raise FileNotFoundError('One or more required files are missing. See messages above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2bf697",
   "metadata": {},
   "source": [
    "### Load Embeddings and Indicator Index\n",
    "\n",
    "These are the same files loaded in Notebook 04. The 10D embeddings are used for\n",
    "clustering; the 2D embeddings are used for scatter plot visualization. The indicator\n",
    "index maps each row number to its indicator string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa024c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10D embeddings shape: (12622, 10)\n",
      "2D embeddings shape:  (12622, 2)\n",
      "Indicator count:      12,622\n",
      "Shape checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Load UMAP embeddings\n",
    "embeddings_10d = np.load(DATA_DIR / 'embeddings_umap_10d.npy')\n",
    "embeddings_2d = np.load(DATA_DIR / 'embeddings_umap_2d.npy')\n",
    "\n",
    "# Load indicator index (maps row i -> indicator string)\n",
    "df_index = pd.read_csv(DATA_DIR / 'indicator_index_all.csv', index_col=0)\n",
    "indicator_names = df_index['indicator'].values\n",
    "\n",
    "n_indicators = len(df_index)\n",
    "print(f'10D embeddings shape: {embeddings_10d.shape}')\n",
    "print(f'2D embeddings shape:  {embeddings_2d.shape}')\n",
    "print(f'Indicator count:      {n_indicators:,}')\n",
    "\n",
    "assert embeddings_10d.shape == (n_indicators, 10)\n",
    "assert embeddings_2d.shape == (n_indicators, 2)\n",
    "print('Shape checks passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7bf477",
   "metadata": {},
   "source": [
    "### Load Wordplay Labels\n",
    "\n",
    "**This is the first time labels enter the clustering pipeline.**\n",
    "\n",
    "`verified_clues_labeled.csv` contains one row per verified (clue_id, indicator) pair —\n",
    "76,015 rows total. Each row carries two kinds of wordplay labels:\n",
    "\n",
    "#### Ho Labels (`wordplay_ho`)\n",
    "\n",
    "These are the original wordplay type labels parsed from cryptic crossword blog\n",
    "commentary by George Ho. They cover **all 8 wordplay types**: anagram, reversal,\n",
    "hidden, container, insertion, deletion, homophone, and alternation. Every row in the\n",
    "file has a Ho label.\n",
    "\n",
    "**Strengths:** Complete coverage of all types; large sample size.\n",
    "**Weaknesses:** Parsed from informal blog text, so some labels may be noisy or\n",
    "inconsistent. The parsing treats the blogger's description as ground truth, but\n",
    "bloggers occasionally mislabel or use ambiguous terminology.\n",
    "\n",
    "#### GT Labels (`wordplay_gt`)\n",
    "\n",
    "These are algorithmically derived \"ground truth\" labels produced by Victoria's\n",
    "verification code in Stage 1. The algorithm checks whether the answer can be\n",
    "mechanically derived from the clue components using the rules of each wordplay type.\n",
    "It covers **only 4 types**: hidden, reversal, alternation, and anagram — the types\n",
    "where the transformation can be verified algorithmically (e.g., checking that the\n",
    "answer's letters appear consecutively in the fodder for hidden-word clues).\n",
    "\n",
    "**Strengths:** High precision — if the algorithm says it's a hidden-word indicator,\n",
    "the mechanical check confirms it. No human judgment involved.\n",
    "**Weaknesses:** Only 4 of 8 types are covered. Container, insertion, deletion, and\n",
    "homophone require contextual understanding that the algorithm cannot perform. About\n",
    "74% of rows have no GT label.\n",
    "\n",
    "#### Why Both Matter\n",
    "\n",
    "Neither label set supersedes the other:\n",
    "- **Ho labels** give us full coverage but lower precision\n",
    "- **GT labels** give us high precision but partial coverage\n",
    "\n",
    "When they disagree, that's informative — it highlights indicators where the blog\n",
    "commentary and the mechanical verification diverge. The `label_match` column tracks\n",
    "this agreement (92.6% match rate where GT exists).\n",
    "\n",
    "#### Multi-Label Indicators\n",
    "\n",
    "A single indicator string can appear under **multiple wordplay types**. For example,\n",
    "\"about\" is used as a container indicator, a reversal indicator, and an anagram\n",
    "indicator in different clues. This is linguistically real — the word genuinely serves\n",
    "multiple functions — not parsing noise. In `verified_clues_labeled.csv`, such an\n",
    "indicator appears in multiple rows with different `wordplay_ho` values.\n",
    "\n",
    "For this analysis, we build:\n",
    "- A **label set** per indicator: all Ho (or GT) types it appears under (for overlay\n",
    "  plots where a multi-label indicator should appear in every relevant type's subplot)\n",
    "- A **primary label**: the single most frequent Ho (or GT) type across that\n",
    "  indicator's clue appearances (for heatmaps and coloring where a single assignment\n",
    "  is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb318c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels file: 76,015 rows\n",
      "Unique indicators: 12,622\n",
      "\n",
      "Ho label distribution (instance-level):\n",
      "wordplay_ho\n",
      "anagram        38226\n",
      "container      10836\n",
      "reversal       10149\n",
      "insertion       8305\n",
      "homophone       3642\n",
      "hidden          2595\n",
      "deletion        1608\n",
      "alternation      654\n",
      "\n",
      "GT label distribution (NaN = no GT label):\n",
      "wordplay_gt\n",
      "NaN            56348\n",
      "anagram        15346\n",
      "hidden          2556\n",
      "reversal        1506\n",
      "alternation      259\n"
     ]
    }
   ],
   "source": [
    "# Load the full labels file\n",
    "df_labels = pd.read_csv(DATA_DIR / 'verified_clues_labeled.csv')\n",
    "\n",
    "print(f'Labels file: {len(df_labels):,} rows')\n",
    "print(f'Unique indicators: {df_labels[\"indicator\"].nunique():,}')\n",
    "print(f'\\nHo label distribution (instance-level):')\n",
    "print(df_labels['wordplay_ho'].value_counts().to_string())\n",
    "print(f'\\nGT label distribution (NaN = no GT label):')\n",
    "print(df_labels['wordplay_gt'].value_counts(dropna=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c5f36",
   "metadata": {},
   "source": [
    "### Build Per-Indicator Label Sets\n",
    "\n",
    "For each unique indicator, we compute:\n",
    "\n",
    "1. **`ho_labels`** — the set of all Ho wordplay types this indicator appears under\n",
    "   (e.g., `{'container', 'reversal', 'anagram'}` for \"about\")\n",
    "2. **`gt_labels`** — the set of all GT wordplay types (may be empty if no GT label\n",
    "   exists)\n",
    "3. **`primary_ho`** — the single Ho type this indicator is most frequently labeled as\n",
    "   (the mode across all its clue appearances)\n",
    "4. **`primary_gt`** — the single most frequent GT type, or NaN if no GT labels exist\n",
    "\n",
    "The label sets (1–2) are used for the per-type overlay plots, where an indicator should\n",
    "appear in every subplot for every type it belongs to. The primary labels (3–4) are used\n",
    "for heatmaps and single-color scatter plots where each indicator needs exactly one label.\n",
    "\n",
    "We align everything with `indicator_index_all.csv` so that row `i` in the label arrays\n",
    "corresponds to row `i` in the embedding matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e32e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataframe: 12,622 indicators\n",
      "Indicators with GT labels: 5,827 (46.2%)\n",
      "Indicators without GT labels: 6,795\n"
     ]
    }
   ],
   "source": [
    "# --- Build label sets per indicator ---\n",
    "\n",
    "# Ho label sets: for each indicator, the set of all Ho types it appears under\n",
    "ho_label_sets = (\n",
    "    df_labels\n",
    "    .groupby('indicator')['wordplay_ho']\n",
    "    .apply(lambda x: frozenset(x.dropna().unique()))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# GT label sets: for each indicator, the set of all GT types it appears under\n",
    "gt_label_sets = (\n",
    "    df_labels\n",
    "    .groupby('indicator')['wordplay_gt']\n",
    "    .apply(lambda x: frozenset(x.dropna().unique()))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Primary Ho label: the most common Ho label across all clue appearances\n",
    "primary_ho_map = (\n",
    "    df_labels\n",
    "    .groupby('indicator')['wordplay_ho']\n",
    "    .agg(lambda x: x.value_counts().index[0])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Primary GT label: the most common GT label, if any GT labels exist for this indicator\n",
    "df_labels_gt = df_labels[df_labels['wordplay_gt'].notna()]\n",
    "primary_gt_map = (\n",
    "    df_labels_gt\n",
    "    .groupby('indicator')['wordplay_gt']\n",
    "    .agg(lambda x: x.value_counts().index[0])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# --- Create master dataframe aligned with embedding order ---\n",
    "# This ensures row i matches embeddings_10d[i] and embeddings_2d[i]\n",
    "df_master = df_index[['indicator']].copy()\n",
    "df_master['ho_labels'] = df_master['indicator'].map(ho_label_sets)\n",
    "df_master['gt_labels'] = df_master['indicator'].map(gt_label_sets)\n",
    "df_master['primary_ho'] = df_master['indicator'].map(primary_ho_map)\n",
    "df_master['primary_gt'] = df_master['indicator'].map(primary_gt_map)\n",
    "\n",
    "# Verify alignment: every indicator should have at least one Ho label\n",
    "assert df_master['primary_ho'].notna().all(), 'Some indicators have no Ho label!'\n",
    "print(f'Master dataframe: {len(df_master):,} indicators')\n",
    "print(f'Indicators with GT labels: {df_master[\"primary_gt\"].notna().sum():,} '\n",
    "      f'({df_master[\"primary_gt\"].notna().mean():.1%})')\n",
    "print(f'Indicators without GT labels: {df_master[\"primary_gt\"].isna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5993e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Primary Ho Label Distribution (unique indicators) ===\n",
      "       anagram: 6,453 (51.1%)\n",
      "     container: 1,523 (12.1%)\n",
      "     insertion: 1,385 (11.0%)\n",
      "      reversal: 1,350 (10.7%)\n",
      "      deletion:   604 (4.8%)\n",
      "        hidden:   560 (4.4%)\n",
      "     homophone:   541 (4.3%)\n",
      "   alternation:   206 (1.6%)\n",
      "\n",
      "=== Primary GT Label Distribution (unique indicators) ===\n",
      "       anagram: 4,364 (34.6%)\n",
      "        hidden:   867 (6.9%)\n",
      "      reversal:   474 (3.8%)\n",
      "   alternation:   122 (1.0%)\n",
      "       (no GT): 6,795 (53.8%)\n",
      "\n",
      "Multi-label indicators (Ho): 1,248 (9.9%)\n",
      "Multi-label indicators (GT): 304\n",
      "\n",
      "Examples of multi-label indicators (Ho):\n",
      "  \"a bit of\" → hidden, insertion\n",
      "  \"a little\" → hidden, insertion\n",
      "  \"abandoned\" → anagram, deletion\n",
      "  \"abducted by\" → hidden, insertion\n",
      "  \"aboard\" → container, hidden, insertion\n",
      "  \"aborted\" → anagram, deletion\n",
      "  \"about\" → anagram, container, hidden, insertion, reversal\n",
      "  \"absorbed\" → container, hidden\n"
     ]
    }
   ],
   "source": [
    "# --- Label statistics ---\n",
    "\n",
    "# Ho type counts (unique indicators, using primary label)\n",
    "print('=== Primary Ho Label Distribution (unique indicators) ===')\n",
    "ho_counts = df_master['primary_ho'].value_counts()\n",
    "for wtype, count in ho_counts.items():\n",
    "    print(f'  {wtype:>12s}: {count:>5,} ({count / len(df_master):.1%})')\n",
    "\n",
    "print(f'\\n=== Primary GT Label Distribution (unique indicators) ===')\n",
    "gt_counts = df_master['primary_gt'].value_counts()\n",
    "for wtype, count in gt_counts.items():\n",
    "    print(f'  {wtype:>12s}: {count:>5,} ({count / len(df_master):.1%})')\n",
    "n_no_gt = df_master['primary_gt'].isna().sum()\n",
    "print(f'  {\"(no GT)\":>12s}: {n_no_gt:>5,} ({n_no_gt / len(df_master):.1%})')\n",
    "\n",
    "# Multi-label indicators\n",
    "n_multi_ho = sum(1 for s in df_master['ho_labels'] if len(s) > 1)\n",
    "print(f'\\nMulti-label indicators (Ho): {n_multi_ho:,} '\n",
    "      f'({n_multi_ho / len(df_master):.1%})')\n",
    "\n",
    "n_multi_gt = sum(1 for s in df_master['gt_labels'] if len(s) > 1)\n",
    "print(f'Multi-label indicators (GT): {n_multi_gt:,}')\n",
    "\n",
    "# Examples of multi-label indicators\n",
    "multi_ho_df = df_master[df_master['ho_labels'].apply(len) > 1]\n",
    "print(f'\\nExamples of multi-label indicators (Ho):')\n",
    "for _, row in multi_ho_df.head(8).iterrows():\n",
    "    types_str = ', '.join(sorted(row['ho_labels']))\n",
    "    print(f'  \"{row[\"indicator\"]}\" \\u2192 {types_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5db8b",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Label-Based Evaluation of Notebook 04 Results\n",
    "\n",
    "Now that we have wordplay type labels attached to each indicator, we can answer:\n",
    "**do the unconstrained clusters from Notebook 04 correspond to known wordplay types?**\n",
    "\n",
    "Recall from NB 04:\n",
    "- **HDBSCAN at eps=0.0** found 282 tight clusters with 33.4% noise — high silhouette\n",
    "  (0.631) but many excluded points\n",
    "- **Agglomerative k=8** is the reference point matching the number of Ho types\n",
    "- **Agglomerative k=10** is the local silhouette optimum (the only evidence for coarse\n",
    "  structure in the metrics sweep)\n",
    "- **Agglomerative k=34** is a mid-range granularity where clusters become semantically\n",
    "  more coherent\n",
    "\n",
    "This section produces:\n",
    "1. **Per-type overlay plots** — where does each wordplay type's indicators live in the\n",
    "   2D UMAP space? This shows the \"ground truth\" spatial layout of types.\n",
    "2. **Per-cluster type distribution heatmaps** — for each clustering run, what is the\n",
    "   Ho type composition of each cluster? This reveals whether clusters are type-pure or\n",
    "   mixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63469d73",
   "metadata": {},
   "source": [
    "### Load Cluster Labels from Notebook 04\n",
    "\n",
    "We load the cluster assignments saved by NB 04 for the four runs we want to evaluate.\n",
    "Each CSV has columns `indicator` and `cluster_label`, aligned with\n",
    "`indicator_index_all.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67fa8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN eps=0.0: 282 clusters, 4212 noise points\n",
      "Agglomerative k=8: 8 clusters, 0 noise points\n",
      "Agglomerative k=10: 10 clusters, 0 noise points\n",
      "Agglomerative k=34: 34 clusters, 0 noise points\n",
      "\n",
      "Loaded 4 clustering runs.\n"
     ]
    }
   ],
   "source": [
    "# Define the clustering runs to evaluate\n",
    "runs_to_evaluate = {\n",
    "    'HDBSCAN eps=0.0': {\n",
    "        'file': 'cluster_labels_hdbscan_eps_0p0000.csv',\n",
    "        'has_noise': True,\n",
    "    },\n",
    "    'Agglomerative k=8': {\n",
    "        'file': 'cluster_labels_agglo_k8.csv',\n",
    "        'has_noise': False,\n",
    "    },\n",
    "    'Agglomerative k=10': {\n",
    "        'file': 'cluster_labels_agglo_k10.csv',\n",
    "        'has_noise': False,\n",
    "    },\n",
    "    'Agglomerative k=34': {\n",
    "        'file': 'cluster_labels_agglo_k34.csv',\n",
    "        'has_noise': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "cluster_labels_dict = {}\n",
    "for run_name, run_info in runs_to_evaluate.items():\n",
    "    df_cl = pd.read_csv(DATA_DIR / run_info['file'])\n",
    "    # Verify alignment with indicator index\n",
    "    assert list(df_cl['indicator']) == list(indicator_names), (\n",
    "        f'Indicator order mismatch in {run_info[\"file\"]}'\n",
    "    )\n",
    "    cluster_labels_dict[run_name] = df_cl['cluster_label'].values\n",
    "    n_clusters = len(set(df_cl['cluster_label'])) - (1 if run_info['has_noise'] else 0)\n",
    "    n_noise = (df_cl['cluster_label'] == -1).sum() if run_info['has_noise'] else 0\n",
    "    print(f'{run_name}: {n_clusters} clusters, {n_noise} noise points')\n",
    "\n",
    "print(f'\\nLoaded {len(cluster_labels_dict)} clustering runs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba4e90",
   "metadata": {},
   "source": [
    "### Color Palette and Helper Functions\n",
    "\n",
    "We define a consistent color palette for the 8 Ho wordplay types. The same colors are\n",
    "used in every plot throughout this notebook and in Notebook 06, making it easy to track\n",
    "types across visualizations.\n",
    "\n",
    "The palette is chosen to be colorblind-accessible where possible, with high-frequency\n",
    "types (anagram, container, reversal) getting the most visually distinct colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867916ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho type indicator counts (an indicator can appear in multiple types):\n",
      "       anagram: 6,610\n",
      "      reversal: 1,495\n",
      "        hidden:   971\n",
      "     container: 1,728\n",
      "     insertion: 1,915\n",
      "      deletion:   695\n",
      "     homophone:   565\n",
      "   alternation:   216\n",
      "\n",
      "GT type indicator counts:\n",
      "       anagram: 4,436\n",
      "      reversal:   631\n",
      "        hidden:   964\n",
      "   alternation:   131\n"
     ]
    }
   ],
   "source": [
    "# --- Consistent color palette for wordplay types ---\n",
    "# Used in all overlay plots, heatmaps, and scatter plots throughout NB 05 and 06\n",
    "\n",
    "HO_TYPES = ['anagram', 'reversal', 'hidden', 'container',\n",
    "            'insertion', 'deletion', 'homophone', 'alternation']\n",
    "\n",
    "GT_TYPES = ['anagram', 'reversal', 'hidden', 'alternation']\n",
    "\n",
    "TYPE_COLORS = {\n",
    "    'anagram':     '#e41a1c',  # red\n",
    "    'reversal':    '#377eb8',  # blue\n",
    "    'hidden':      '#4daf4a',  # green\n",
    "    'container':   '#984ea3',  # purple\n",
    "    'insertion':   '#ff7f00',  # orange\n",
    "    'deletion':    '#a65628',  # brown\n",
    "    'homophone':   '#f781bf',  # pink\n",
    "    'alternation': '#999999',  # gray\n",
    "}\n",
    "\n",
    "# Pre-compute boolean masks for each Ho type:\n",
    "# ho_type_masks['anagram'][i] is True if indicator i has ever been labeled 'anagram'\n",
    "ho_type_masks = {}\n",
    "for wtype in HO_TYPES:\n",
    "    ho_type_masks[wtype] = np.array([\n",
    "        wtype in label_set for label_set in df_master['ho_labels']\n",
    "    ])\n",
    "\n",
    "# Same for GT types\n",
    "gt_type_masks = {}\n",
    "for wtype in GT_TYPES:\n",
    "    gt_type_masks[wtype] = np.array([\n",
    "        wtype in label_set for label_set in df_master['gt_labels']\n",
    "    ])\n",
    "\n",
    "# Print type counts for overlay reference\n",
    "print('Ho type indicator counts (an indicator can appear in multiple types):')\n",
    "for wtype in HO_TYPES:\n",
    "    n = ho_type_masks[wtype].sum()\n",
    "    print(f'  {wtype:>12s}: {n:>5,}')\n",
    "\n",
    "print(f'\\nGT type indicator counts:')\n",
    "for wtype in GT_TYPES:\n",
    "    n = gt_type_masks[wtype].sum()\n",
    "    print(f'  {wtype:>12s}: {n:>5,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2257a",
   "metadata": {},
   "source": [
    "### Per-Type Overlay: Ho Labels\n",
    "\n",
    "Each subplot below highlights the indicators belonging to one Ho wordplay type,\n",
    "plotted on top of the full 2D UMAP cloud (shown in light gray). This reveals\n",
    "**where each type lives in the embedding space**:\n",
    "\n",
    "- **Concentrated clusters:** If a type's indicators form a tight region, the\n",
    "  embedding model captured something distinctive about that type's vocabulary.\n",
    "- **Dispersed clouds:** If a type's indicators are scattered across the full space,\n",
    "  the type's vocabulary is semantically diverse and may not form a natural cluster.\n",
    "- **Overlapping types:** If two types occupy the same region, their indicators share\n",
    "  semantic properties and will be hard to separate by clustering.\n",
    "\n",
    "These plots use all Ho labels (not just the primary label), so a multi-label indicator\n",
    "like \"about\" appears in every type subplot where it has been used. This gives the\n",
    "complete picture of where each type's vocabulary lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b60208",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(22, 10))\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for i, wtype in enumerate(HO_TYPES):\n",
    "    ax = axes_flat[i]\n",
    "    mask = ho_type_masks[wtype]\n",
    "    n_type = mask.sum()\n",
    "\n",
    "    # Background: all indicators in light gray\n",
    "    ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "               s=1, alpha=0.08, color='lightgray', rasterized=True)\n",
    "\n",
    "    # Foreground: this type's indicators\n",
    "    ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n",
    "               s=3, alpha=0.4, color=TYPE_COLORS[wtype], rasterized=True)\n",
    "\n",
    "    ax.set_title(f'{wtype} (n={n_type:,})', fontsize=11,\n",
    "                 color=TYPE_COLORS[wtype], fontweight='bold')\n",
    "    ax.set_xlabel('UMAP 1', fontsize=8)\n",
    "    ax.set_ylabel('UMAP 2', fontsize=8)\n",
    "    ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.suptitle('Ho Label Overlay: Where Each Wordplay Type Lives in Embedding Space',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'overlay_ho_types.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Saved: {FIGURES_DIR / \"overlay_ho_types.png\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7adf7fc",
   "metadata": {},
   "source": [
    "### Per-Type Overlay: GT Labels\n",
    "\n",
    "The same visualization using the algorithmically derived GT labels. Only 4 types are\n",
    "covered (anagram, reversal, hidden, alternation). Indicators without a GT label are\n",
    "part of the gray background only.\n",
    "\n",
    "Comparing this to the Ho overlay above reveals:\n",
    "- GT labels tend to highlight a **subset** of each type's indicators (the ones where\n",
    "  the transformation could be mechanically verified)\n",
    "- If the GT-highlighted region is a spatial subset of the Ho-highlighted region for\n",
    "  the same type, the two label sources are consistent\n",
    "- If GT highlights indicators in a different part of the space than Ho, there may be\n",
    "  labeling disagreements worth investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "\n",
    "for i, wtype in enumerate(GT_TYPES):\n",
    "    ax = axes[i]\n",
    "    mask = gt_type_masks[wtype]\n",
    "    n_type = mask.sum()\n",
    "\n",
    "    # Background: all indicators in light gray\n",
    "    ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "               s=1, alpha=0.08, color='lightgray', rasterized=True)\n",
    "\n",
    "    # Foreground: this type's GT-verified indicators\n",
    "    ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n",
    "               s=4, alpha=0.5, color=TYPE_COLORS[wtype], rasterized=True)\n",
    "\n",
    "    ax.set_title(f'{wtype} — GT verified (n={n_type:,})', fontsize=11,\n",
    "                 color=TYPE_COLORS[wtype], fontweight='bold')\n",
    "    ax.set_xlabel('UMAP 1', fontsize=8)\n",
    "    ax.set_ylabel('UMAP 2', fontsize=8)\n",
    "    ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.suptitle('GT Label Overlay: Algorithmically Verified Types in Embedding Space',\n",
    "             fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'overlay_gt_types.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Saved: {FIGURES_DIR / \"overlay_gt_types.png\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3af50",
   "metadata": {},
   "source": [
    "### Per-Cluster Type Distribution Heatmaps\n",
    "\n",
    "For each of the four clustering runs from NB 04, we create a heatmap showing the Ho\n",
    "type composition of each cluster. Each row is a cluster, each column is a wordplay\n",
    "type, and each cell shows the **proportion** of that cluster's indicators that have\n",
    "that type as their primary Ho label. Rows sum to 1.0.\n",
    "\n",
    "**How to read these heatmaps:**\n",
    "- A **pure cluster** has one bright cell in its row and near-zero everywhere else —\n",
    "  the cluster captured a single wordplay type.\n",
    "- A **mixed cluster** has color spread across multiple columns — it contains a blend\n",
    "  of types that the algorithm could not separate.\n",
    "- The **dominant type** of each cluster is the column with the highest value.\n",
    "- Clusters are sorted by size (largest at top) for readability.\n",
    "\n",
    "For HDBSCAN, which labels some points as noise (cluster = −1), we include a separate\n",
    "\"noise\" row showing the type distribution of noise points. If noise points are\n",
    "distributed similarly to the full dataset, the density-based method is not\n",
    "systematically excluding any particular type. If noise is concentrated in certain\n",
    "types, those types' indicators may be more dispersed in the embedding space.\n",
    "\n",
    "These heatmaps use the **primary Ho label** (single most common type per indicator)\n",
    "to avoid double-counting multi-label indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_type_distribution(cluster_labels, primary_ho, ho_types, type_colors,\n",
    "                           title, filename, max_clusters=20, show_noise=False):\n",
    "    \"\"\"Heatmap showing the Ho type composition of each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster_labels : array of int\n",
    "        Cluster assignment for each indicator (-1 = noise for HDBSCAN).\n",
    "    primary_ho : array of str\n",
    "        Primary Ho label for each indicator.\n",
    "    ho_types : list of str\n",
    "        Ordered list of Ho type names (column order in heatmap).\n",
    "    type_colors : dict\n",
    "        Colors per type (used for column header coloring).\n",
    "    title : str\n",
    "        Plot title.\n",
    "    filename : str\n",
    "        Output filename (saved to FIGURES_DIR).\n",
    "    max_clusters : int\n",
    "        Maximum number of cluster rows to display (largest first).\n",
    "    show_noise : bool\n",
    "        If True, include a 'noise' row for cluster=-1 points.\n",
    "    \"\"\"\n",
    "    df_temp = pd.DataFrame({\n",
    "        'cluster': cluster_labels,\n",
    "        'type': primary_ho,\n",
    "    })\n",
    "\n",
    "    # Separate noise if applicable\n",
    "    if show_noise:\n",
    "        noise_df = df_temp[df_temp['cluster'] == -1]\n",
    "        df_clean = df_temp[df_temp['cluster'] != -1]\n",
    "    else:\n",
    "        noise_df = pd.DataFrame()\n",
    "        df_clean = df_temp\n",
    "\n",
    "    # Crosstab: rows = cluster, columns = type\n",
    "    ct = pd.crosstab(df_clean['cluster'], df_clean['type'])\n",
    "    for t in ho_types:\n",
    "        if t not in ct.columns:\n",
    "            ct[t] = 0\n",
    "    ct = ct[ho_types]\n",
    "\n",
    "    # Sort by cluster size (descending)\n",
    "    ct = ct.loc[ct.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "    # Limit to top N clusters if there are too many rows\n",
    "    if len(ct) > max_clusters:\n",
    "        ct = ct.head(max_clusters)\n",
    "\n",
    "    # Add noise row if applicable\n",
    "    if show_noise and len(noise_df) > 0:\n",
    "        noise_counts = noise_df['type'].value_counts()\n",
    "        noise_row = pd.DataFrame(\n",
    "            [[noise_counts.get(t, 0) for t in ho_types]],\n",
    "            columns=ho_types,\n",
    "            index=['noise']\n",
    "        )\n",
    "        ct = pd.concat([ct, noise_row])\n",
    "\n",
    "    # Row labels with cluster sizes\n",
    "    sizes = ct.sum(axis=1).astype(int)\n",
    "    row_labels = [f'{idx} (n={int(sizes[idx]):,})' for idx in ct.index]\n",
    "\n",
    "    # Normalize by row (proportions)\n",
    "    ct_norm = ct.div(ct.sum(axis=1), axis=0)\n",
    "\n",
    "    # Decide whether to annotate cells (skip for large heatmaps)\n",
    "    n_rows = len(ct_norm)\n",
    "    do_annot = n_rows <= 15\n",
    "    height = max(4, n_rows * 0.45 + 2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, height))\n",
    "    sns.heatmap(\n",
    "        ct_norm.values.astype(float),\n",
    "        annot=ct_norm.values.astype(float) if do_annot else False,\n",
    "        fmt='.2f' if do_annot else '',\n",
    "        cmap='YlOrRd',\n",
    "        ax=ax,\n",
    "        vmin=0, vmax=0.8,\n",
    "        linewidths=0.5,\n",
    "        xticklabels=ho_types,\n",
    "        yticklabels=row_labels,\n",
    "    )\n",
    "    ax.set_title(title, fontsize=13, pad=12)\n",
    "    ax.set_xlabel('Primary Ho Wordplay Type', fontsize=11)\n",
    "    ax.set_ylabel('Cluster (sorted by size)', fontsize=11)\n",
    "\n",
    "    # Color the x-axis tick labels by type for visual consistency\n",
    "    for tick_label in ax.get_xticklabels():\n",
    "        wtype = tick_label.get_text()\n",
    "        if wtype in type_colors:\n",
    "            tick_label.set_color(type_colors[wtype])\n",
    "            tick_label.set_fontweight('bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(FIGURES_DIR / filename, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Saved: {FIGURES_DIR / filename}')\n",
    "\n",
    "    return ct_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate heatmaps for each clustering run ---\n",
    "primary_ho_array = df_master['primary_ho'].values\n",
    "\n",
    "type_dist_results = {}\n",
    "for run_name, labels in cluster_labels_dict.items():\n",
    "    run_info = runs_to_evaluate[run_name]\n",
    "    # Create a filename-safe version of the run name\n",
    "    safe_name = run_name.lower().replace(' ', '_').replace('=', '').replace('.', '')\n",
    "    ct_norm = plot_type_distribution(\n",
    "        cluster_labels=labels,\n",
    "        primary_ho=primary_ho_array,\n",
    "        ho_types=HO_TYPES,\n",
    "        type_colors=TYPE_COLORS,\n",
    "        title=f'Per-Cluster Ho Type Distribution \\u2014 {run_name}',\n",
    "        filename=f'type_distribution_{safe_name}.png',\n",
    "        max_clusters=20 if run_info['has_noise'] else 40,\n",
    "        show_noise=run_info['has_noise'],\n",
    "    )\n",
    "    type_dist_results[run_name] = ct_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf075520",
   "metadata": {},
   "source": [
    "### Dominant Type per Cluster\n",
    "\n",
    "As a complement to the heatmaps, we print each cluster's **dominant type** (the Ho type\n",
    "with the highest proportion) and its **purity** (that proportion). A purity of 1.0 means\n",
    "every indicator in the cluster has the same primary Ho label; a purity of 0.3 means the\n",
    "cluster is a mixture with no single type dominating.\n",
    "\n",
    "This is a quick summary for comparing runs: higher average purity means the clustering\n",
    "better separates wordplay types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef964fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_name, ct_norm in type_dist_results.items():\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'{run_name}')\n",
    "    print(f'{\"=\" * 60}')\n",
    "    for idx in ct_norm.index:\n",
    "        row = ct_norm.loc[idx]\n",
    "        dominant_type = row.idxmax()\n",
    "        purity = row.max()\n",
    "        print(f'  Cluster {str(idx):>6s}: dominant={dominant_type:<12s} purity={purity:.2f}')\n",
    "\n",
    "    # Average purity (excluding noise row if present)\n",
    "    numeric_rows = ct_norm.loc[ct_norm.index != 'noise']\n",
    "    avg_purity = numeric_rows.max(axis=1).mean()\n",
    "    print(f'\\n  Average cluster purity: {avg_purity:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcb5b6",
   "metadata": {},
   "source": [
    "### Save Section 2 Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the per-cluster type distribution tables for use in NB 06\n",
    "for run_name, ct_norm in type_dist_results.items():\n",
    "    safe_name = run_name.lower().replace(' ', '_').replace('=', '').replace('.', '')\n",
    "    out_path = OUTPUT_DIR / f'type_distribution_{safe_name}.csv'\n",
    "    ct_norm.to_csv(out_path)\n",
    "    print(f'Saved: {out_path}')\n",
    "\n",
    "# List all figures produced in this section\n",
    "print(f'\\nFigures saved to {FIGURES_DIR}:')\n",
    "for f in sorted(FIGURES_DIR.glob('overlay_*.png')):\n",
    "    print(f'  {f.name}')\n",
    "for f in sorted(FIGURES_DIR.glob('type_distribution_*.png')):\n",
    "    print(f'  {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf878",
   "metadata": {},
   "source": [
    "### Interpretation: Do Unconstrained Clusters Correspond to Wordplay Types?\n",
    "\n",
    "#### Type Overlay Findings\n",
    "\n",
    "The per-type overlay plots reveal the spatial distribution of each wordplay type in\n",
    "the embedding space. Key observations:\n",
    "\n",
    "- **Homophone** indicators are expected to be the most spatially concentrated — words\n",
    "  like \"sounds like\", \"I hear\", and \"reportedly\" share a distinctive hearing/speaking\n",
    "  semantic field that is well-separated from other types.\n",
    "- **Anagram** indicators are expected to be the most dispersed — they span many\n",
    "  conceptual metaphors (disorder, cooking, damage, movement) and occupy a large region\n",
    "  of the space. This is consistent with anagram having the largest and most diverse\n",
    "  indicator vocabulary (6,610 unique verified indicators).\n",
    "- **Container and insertion** indicators are expected to heavily overlap in space,\n",
    "  since they share placement/containment conceptual metaphors and many of the same\n",
    "  indicator phrases (\"in\", \"about\", \"around\" appear under both types).\n",
    "- **Reversal** indicators likely form a moderately concentrated region, especially the\n",
    "  up/rising words (for down clues) and the back/return words.\n",
    "- **Hidden** indicators may partially overlap with container/insertion due to shared\n",
    "  placement metaphors (\"in\", \"within\", \"inside\" are shared across these types).\n",
    "\n",
    "The GT overlay confirms the spatial patterns using the higher-precision algorithmic\n",
    "labels, covering only the 4 types where mechanical verification is possible.\n",
    "\n",
    "#### Per-Cluster Distribution Findings\n",
    "\n",
    "The heatmaps answer the core question of whether unconstrained clusters align with\n",
    "wordplay types:\n",
    "\n",
    "- **At k=8**: If clusters perfectly aligned with types, each row would have a single\n",
    "  bright cell and near-zero elsewhere. In practice, most clusters are likely mixed —\n",
    "  especially those spanning the container/insertion/hidden region.\n",
    "- **At k=10**: The local silhouette optimum from NB 04. Compare the purity of the k=10\n",
    "  heatmap to k=8 to see whether the two extra clusters help isolate overlapping types.\n",
    "- **At k=34**: Finer granularity should produce purer clusters, but now multiple\n",
    "  clusters correspond to the same type. This is consistent with the NB 04 finding that\n",
    "  the data's natural structure is finer-grained than 8 types.\n",
    "- **HDBSCAN eps=0.0**: The 282 tight clusters are very fine-grained. The top 20 largest\n",
    "  clusters likely show high type purity — each tight cluster contains indicators of\n",
    "  mostly one type. The noise row reveals which types have the most \"ambiguous\" indicators\n",
    "  that don't fit neatly into any dense region.\n",
    "\n",
    "#### Key Takeaway\n",
    "\n",
    "The alignment between unconstrained clusters and wordplay types establishes the baseline\n",
    "for Section 3, where we ask: **can domain knowledge (seed words, constraints) improve\n",
    "this alignment?** If the unconstrained clusters already separate types well for some\n",
    "types (e.g., homophone, reversal) but not others (e.g., container/insertion/hidden),\n",
    "that tells us exactly where constrained clustering has room to help — and where the\n",
    "linguistic reality of shared indicator vocabulary may make clean separation impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df6947",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Constrained Agglomerative Clustering\n",
    "\n",
    "Unconstrained clustering (NB 04) found no natural k=8 grouping — metrics improve\n",
    "monotonically with finer granularity, and HDBSCAN transitions abruptly from 282\n",
    "clusters to 3–4 with no stable middle ground.\n",
    "\n",
    "This section asks: **can domain knowledge impose meaningful structure that doesn't\n",
    "emerge naturally?**\n",
    "\n",
    "We use **constrained agglomerative clustering** (Ward's linkage with a connectivity\n",
    "matrix) to bias clustering toward expert-defined groups. The idea:\n",
    "\n",
    "1. Expert sources provide **seed words** — indicators with known wordplay type\n",
    "   affiliations (from CCC tutorial books and our conceptual analysis)\n",
    "2. Seeds in the same group are connected in a **connectivity matrix**, which tells\n",
    "   Ward's method \"these points should be neighbors\"\n",
    "3. The algorithm clusters all 12,622 indicators, with seeds gently biased toward\n",
    "   their assigned groups\n",
    "\n",
    "Two constrained runs:\n",
    "\n",
    "| Run | Seed source | k | Philosophy |\n",
    "|-----|-------------|---|------------|\n",
    "| MC7 | `minute_cryptic_ho_7` tab | 7 | Wordplay-type level: one group per Ho type, container+insertion merged |\n",
    "| CG34 | `conceptual_groups` tab | 34 | Conceptual-metaphor level: one group per semantic concept |\n",
    "\n",
    "We compare each constrained run to its unconstrained counterpart from NB 04 to\n",
    "measure the effect of expert knowledge on cluster quality and type alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a567816",
   "metadata": {},
   "source": [
    "### 3A: Load and Validate Seed Words\n",
    "\n",
    "Seed words come from `wordplay_seeds.xlsx`, compiled from two expert sources:\n",
    "\n",
    "- **Minute Cryptic** (Tiernan & Runnalls, 2025) — a CCC tutorial book with\n",
    "  indicator examples organized by wordplay type\n",
    "- **Conceptual groups** — Victoria's analysis of underlying semantic metaphors\n",
    "  that connect indicators to their wordplay functions\n",
    "\n",
    "We load two tabs from the spreadsheet:\n",
    "\n",
    "**`minute_cryptic_ho_7`** (wide format): Paired columns per wordplay type. We use\n",
    "the `_multiword` columns (which preserve full phrases like \"exhibit in\", \"leaking\n",
    "out of\") since our verified indicators include multi-word expressions. For types\n",
    "without a `_multiword` variant (`anagram`, `selector_alternating`), we use the base\n",
    "column. Container and insertion seeds are combined into one group because they are\n",
    "inverse operations sharing most indicator vocabulary (see DOMAIN_KNOWLEDGE.md).\n",
    "\n",
    "**`conceptual_groups`** (long format): Each row maps an indicator to a conceptual\n",
    "category (e.g., \"movement\", \"disorder\", \"containing\") and the wordplay types it\n",
    "serves. We group by concept, giving 34 groups organized by semantic metaphor rather\n",
    "than wordplay type. This is the most theoretically motivated seed set.\n",
    "\n",
    "After parsing, we validate each seed against our verified indicator list\n",
    "(`indicator_index_all.csv`) to see how many seeds actually appear in the data we\n",
    "are clustering. Seeds that don't match any verified indicator still inform our\n",
    "understanding of each group's intended meaning, but they cannot contribute to the\n",
    "connectivity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Parse minute_cryptic_ho_7 seeds\n",
    "# =====================================================================\n",
    "df_mc7_raw = pd.read_excel(DATA_DIR / 'wordplay_seeds.xlsx', 'minute_cryptic_ho_7')\n",
    "\n",
    "# Column mapping: use _multiword variants where available, base columns otherwise.\n",
    "# 7 groups: one per Ho type, with container and insertion combined.\n",
    "mc7_column_map = {\n",
    "    'anagram':             'anagram',                   # no _multiword column\n",
    "    'alternation':         'selector_alternating',       # no _multiword column\n",
    "    'hidden':              'hidden_ALL_multiword',\n",
    "    'reversal':            'reversal_ALL_multiword',\n",
    "    'container_insertion': 'container_ALL_multiword',    # combined group\n",
    "    'deletion':            'deletion_ALL_multiword',\n",
    "    'homophone':           'homophone_multiword',\n",
    "}\n",
    "\n",
    "mc7_seeds = {}\n",
    "for group_name, col_name in mc7_column_map.items():\n",
    "    seeds = df_mc7_raw[col_name].dropna().str.strip().tolist()\n",
    "    mc7_seeds[group_name] = seeds\n",
    "\n",
    "print('=== minute_cryptic_ho_7: Raw Seed Counts ===')\n",
    "for group, seeds in mc7_seeds.items():\n",
    "    print(f'  {group:>20s}: {len(seeds):>3d} seeds')\n",
    "total_mc7 = sum(len(s) for s in mc7_seeds.values())\n",
    "print(f'  {\"TOTAL\":>20s}: {total_mc7:>3d}')\n",
    "\n",
    "# =====================================================================\n",
    "# Parse conceptual_groups seeds\n",
    "# =====================================================================\n",
    "df_cg_raw = pd.read_excel(DATA_DIR / 'wordplay_seeds.xlsx', 'conceptual_groups')\n",
    "\n",
    "# Drop rows with missing concept or indicator (handles potential formula rows)\n",
    "df_cg_raw = df_cg_raw.dropna(subset=['concept', 'indicator'])\n",
    "\n",
    "# Group by concept\n",
    "cg_seeds = {}\n",
    "for concept, grp in df_cg_raw.groupby('concept'):\n",
    "    seeds = grp['indicator'].str.strip().tolist()\n",
    "    cg_seeds[concept] = seeds\n",
    "\n",
    "print(f'\\n=== conceptual_groups: Raw Seed Counts ({len(cg_seeds)} groups) ===')\n",
    "for concept in sorted(cg_seeds.keys()):\n",
    "    seeds = cg_seeds[concept]\n",
    "    print(f'  {concept:>20s}: {len(seeds):>3d} seeds')\n",
    "total_cg = sum(len(s) for s in cg_seeds.values())\n",
    "print(f'  {\"TOTAL\":>20s}: {total_cg:>3d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5219697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Validate seeds against verified indicator list\n",
    "# =====================================================================\n",
    "indicator_set = set(indicator_names)\n",
    "\n",
    "\n",
    "def validate_seeds(seed_dict, name):\n",
    "    \"\"\"Check which seeds match our verified indicator list.\n",
    "\n",
    "    Returns a dict of group_name -> list of matched seed strings,\n",
    "    and prints a validation report with match counts and cross-group duplicates.\n",
    "    \"\"\"\n",
    "    matched_dict = {}\n",
    "    rows = []\n",
    "\n",
    "    for group in sorted(seed_dict.keys()):\n",
    "        seeds = seed_dict[group]\n",
    "        matched = [s for s in seeds if s in indicator_set]\n",
    "        unmatched = [s for s in seeds if s not in indicator_set]\n",
    "        matched_dict[group] = matched\n",
    "        rows.append({\n",
    "            'Group': group,\n",
    "            'Total': len(seeds),\n",
    "            'Matched': len(matched),\n",
    "            'Unmatched': len(unmatched),\n",
    "        })\n",
    "        if unmatched:\n",
    "            print(f'  {group}: unmatched: {unmatched}')\n",
    "\n",
    "    df_summary = pd.DataFrame(rows)\n",
    "    total_seeds = df_summary['Total'].sum()\n",
    "    total_matched = df_summary['Matched'].sum()\n",
    "    print(f'\\n  Overall: {total_matched}/{total_seeds} seeds matched '\n",
    "          f'({total_matched / total_seeds:.1%})')\n",
    "\n",
    "    # Check for cross-group duplicates (same seed in multiple groups)\n",
    "    seed_to_groups = {}\n",
    "    for group, seeds in matched_dict.items():\n",
    "        for s in seeds:\n",
    "            seed_to_groups.setdefault(s, []).append(group)\n",
    "\n",
    "    duplicates = {s: gs for s, gs in seed_to_groups.items() if len(gs) > 1}\n",
    "    if duplicates:\n",
    "        print(f'\\n  Cross-group duplicates ({len(duplicates)}):')\n",
    "        for seed in sorted(duplicates.keys()):\n",
    "            print(f'    \"{seed}\" -> {\", \".join(duplicates[seed])}')\n",
    "    else:\n",
    "        print('\\n  No cross-group duplicates.')\n",
    "\n",
    "    print(f'\\n{name} validation summary:')\n",
    "    print(df_summary.to_string(index=False))\n",
    "    return matched_dict\n",
    "\n",
    "\n",
    "print('=== minute_cryptic_ho_7 ===')\n",
    "mc7_matched = validate_seeds(mc7_seeds, 'minute_cryptic_ho_7')\n",
    "\n",
    "print(f'\\n{\"=\" * 60}\\n')\n",
    "\n",
    "print('=== conceptual_groups ===')\n",
    "cg_matched = validate_seeds(cg_seeds, 'conceptual_groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d4164",
   "metadata": {},
   "source": [
    "### 3B: Build Connectivity Matrices\n",
    "\n",
    "**What is a connectivity matrix?**\n",
    "\n",
    "Sklearn's `AgglomerativeClustering` accepts an optional `connectivity` parameter —\n",
    "a sparse matrix where entry `(i, j) = 1` means \"points i and j are neighbors.\"\n",
    "When provided, Ward's method will only consider merging clusters that share at\n",
    "least one connected pair of points. This biases the algorithm toward keeping\n",
    "connected points in the same cluster.\n",
    "\n",
    "**Our approach combines two layers:**\n",
    "\n",
    "1. **Base connectivity (kNN graph):** We connect each of the 12,622 indicators to\n",
    "   its 15 closest neighbors in 10D UMAP space. This preserves the standard local\n",
    "   structure that Ward's would discover on its own. We use k=15 to match the\n",
    "   `n_neighbors` parameter from UMAP dimensionality reduction (NB 03).\n",
    "\n",
    "2. **Seed connections (additive):** Within each seed group, we add edges between\n",
    "   all pairs of matched seeds, creating a complete subgraph per group. This\n",
    "   encourages Ward's to keep those seeds — and by extension, their neighborhoods —\n",
    "   in the same cluster.\n",
    "\n",
    "**What we do NOT do:**\n",
    "\n",
    "- We do not add connections between seeds in **different** groups. Cross-group edges\n",
    "  may already exist in the kNN base graph (if two seeds from different groups happen\n",
    "  to be embedding-space neighbors), and that is fine — we just don't add extra\n",
    "  encouragement for cross-group merging.\n",
    "- **Non-seed points** keep their normal kNN connections with no additional constraints.\n",
    "\n",
    "**This is a soft constraint, not a hard partition.** If the embedding distances\n",
    "strongly disagree with the seed groupings, Ward's can still separate seeds from\n",
    "their intended group. The connectivity matrix biases the algorithm toward\n",
    "expert-defined structure without forcing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "# --- Base connectivity: k-nearest-neighbors graph ---\n",
    "# k=15 matches the n_neighbors used in UMAP (NB 03)\n",
    "knn_connectivity = kneighbors_graph(\n",
    "    embeddings_10d,\n",
    "    n_neighbors=15,\n",
    "    mode='connectivity',\n",
    "    include_self=False,\n",
    ")\n",
    "print(f'Base kNN graph: {knn_connectivity.shape}, '\n",
    "      f'{knn_connectivity.nnz:,} nonzero entries')\n",
    "\n",
    "# --- Fast lookup: indicator string -> row index ---\n",
    "indicator_to_idx = {name: idx for idx, name in enumerate(indicator_names)}\n",
    "\n",
    "\n",
    "def build_seed_connectivity(matched_seeds_dict, base_knn, indicator_to_idx):\n",
    "    \"\"\"Build a connectivity matrix: kNN base + within-group seed connections.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matched_seeds_dict : dict\n",
    "        group_name -> list of matched seed strings\n",
    "    base_knn : sparse matrix\n",
    "        k-nearest-neighbors connectivity (n_samples x n_samples)\n",
    "    indicator_to_idx : dict\n",
    "        indicator string -> row index in embedding matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    connectivity : sparse CSR matrix\n",
    "        Combined connectivity matrix (kNN + seed edges)\n",
    "    seed_indices_by_group : dict\n",
    "        group_name -> list of row indices for matched seeds\n",
    "    \"\"\"\n",
    "    n = base_knn.shape[0]\n",
    "    # Start from the kNN base; lil_matrix allows efficient element-wise edits\n",
    "    conn = lil_matrix(base_knn)\n",
    "\n",
    "    seed_indices_by_group = {}\n",
    "    n_edges_added = 0\n",
    "\n",
    "    for group_name, seeds in matched_seeds_dict.items():\n",
    "        indices = [indicator_to_idx[s] for s in seeds]\n",
    "        seed_indices_by_group[group_name] = indices\n",
    "\n",
    "        # Connect all seed pairs within this group (complete subgraph)\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(i + 1, len(indices)):\n",
    "                a, b = indices[i], indices[j]\n",
    "                if conn[a, b] == 0:\n",
    "                    n_edges_added += 1\n",
    "                conn[a, b] = 1\n",
    "                conn[b, a] = 1  # keep symmetric\n",
    "\n",
    "    connectivity = conn.tocsr()\n",
    "    total_seeds = sum(len(v) for v in seed_indices_by_group.values())\n",
    "    print(f'  Seed groups: {len(seed_indices_by_group)}')\n",
    "    print(f'  Matched seeds: {total_seeds}')\n",
    "    print(f'  New edges added by seeds: {n_edges_added:,}')\n",
    "    print(f'  Final nonzero entries: {connectivity.nnz:,}')\n",
    "    return connectivity, seed_indices_by_group\n",
    "\n",
    "\n",
    "# --- MC7 connectivity (for k=7 run) ---\n",
    "print('\\nBuilding MC7 connectivity (minute_cryptic_ho_7 seeds):')\n",
    "conn_mc7, seed_idx_mc7 = build_seed_connectivity(\n",
    "    mc7_matched, knn_connectivity, indicator_to_idx\n",
    ")\n",
    "\n",
    "# --- CG34 connectivity (for k=34 run) ---\n",
    "print('\\nBuilding CG34 connectivity (conceptual_groups seeds):')\n",
    "conn_cg34, seed_idx_cg34 = build_seed_connectivity(\n",
    "    cg_matched, knn_connectivity, indicator_to_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4c91f",
   "metadata": {},
   "source": [
    "### 3C: Run Constrained Clustering\n",
    "\n",
    "We run two constrained agglomerative clustering experiments using Ward's linkage\n",
    "with the connectivity matrices built above.\n",
    "\n",
    "| Run | k | Seed source | Comparison baseline |\n",
    "|-----|---|-------------|---------------------|\n",
    "| **MC7** | 7 | minute_cryptic_ho_7 | Unconstrained agglomerative k=8 |\n",
    "| **CG34** | 34 | conceptual_groups | Unconstrained agglomerative k=34 |\n",
    "\n",
    "**Why k=7 for MC7?** The minute_cryptic_ho_7 seed set has 7 groups (container and\n",
    "insertion are merged into one group because they share most indicator vocabulary).\n",
    "The closest unconstrained baseline is k=8 (one cluster per Ho type).\n",
    "\n",
    "**Why k=34 for CG34?** The conceptual_groups seed set has exactly 34 concepts. The\n",
    "unconstrained agglomerative k=34 from NB 04 provides a direct comparison at the\n",
    "same granularity.\n",
    "\n",
    "**Metrics computed for each run:**\n",
    "- **Silhouette score** — how well each point matches its own cluster vs. its nearest\n",
    "  neighboring cluster (range −1 to 1; higher is better)\n",
    "- **Davies-Bouldin index** — average ratio of within-cluster scatter to between-cluster\n",
    "  separation (lower is better; 0 would mean perfectly separated clusters)\n",
    "- **Calinski-Harabasz index** — ratio of between-cluster to within-cluster variance\n",
    "  (higher is better, but has a known bias toward fewer clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def run_constrained_clustering(embeddings, connectivity, n_clusters, run_name):\n",
    "    \"\"\"Run Ward's agglomerative clustering with a connectivity constraint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : ndarray, shape (n_samples, n_features)\n",
    "        Input data (10D UMAP embeddings).\n",
    "    connectivity : sparse matrix\n",
    "        Connectivity constraint matrix (kNN + seed edges).\n",
    "    n_clusters : int\n",
    "        Number of clusters to produce.\n",
    "    run_name : str\n",
    "        Label for this run (used in print output).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : ndarray of int\n",
    "        Cluster assignment for each indicator.\n",
    "    metrics : dict\n",
    "        Silhouette, Davies-Bouldin, and Calinski-Harabasz scores.\n",
    "    \"\"\"\n",
    "    print(f\"Running constrained Ward's clustering: {run_name} (k={n_clusters})...\")\n",
    "\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters=n_clusters,\n",
    "        linkage='ward',\n",
    "        connectivity=connectivity,\n",
    "    )\n",
    "    labels = model.fit_predict(embeddings)\n",
    "\n",
    "    sil = silhouette_score(embeddings, labels)\n",
    "    db = davies_bouldin_score(embeddings, labels)\n",
    "    ch = calinski_harabasz_score(embeddings, labels)\n",
    "    metrics = {\n",
    "        'Silhouette': sil,\n",
    "        'Davies-Bouldin': db,\n",
    "        'Calinski-Harabasz': ch,\n",
    "    }\n",
    "\n",
    "    sizes = pd.Series(labels).value_counts()\n",
    "    print(f'  Silhouette:        {sil:.4f}')\n",
    "    print(f'  Davies-Bouldin:    {db:.4f}')\n",
    "    print(f'  Calinski-Harabasz: {ch:.1f}')\n",
    "    print(f'  Cluster sizes: min={sizes.min()}, '\n",
    "          f'max={sizes.max()}, median={sizes.median():.0f}')\n",
    "\n",
    "    return labels, metrics\n",
    "\n",
    "\n",
    "# --- Run 1: MC7 (k=7, minute_cryptic_ho_7 seeds) ---\n",
    "labels_mc7, metrics_mc7 = run_constrained_clustering(\n",
    "    embeddings_10d, conn_mc7, n_clusters=7, run_name='MC7'\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "# --- Run 2: CG34 (k=34, conceptual_groups seeds) ---\n",
    "labels_cg34, metrics_cg34 = run_constrained_clustering(\n",
    "    embeddings_10d, conn_cg34, n_clusters=34, run_name='CG34'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e9d2e",
   "metadata": {},
   "source": [
    "### Metrics Comparison: Constrained vs. Unconstrained\n",
    "\n",
    "The central question: **does adding seed-word connectivity constraints improve\n",
    "clustering quality** compared to the unconstrained Ward's runs from NB 04?\n",
    "\n",
    "- A higher silhouette / lower Davies-Bouldin for the constrained run would suggest\n",
    "  that expert knowledge helps organize the embedding space into more coherent groups.\n",
    "- If constrained metrics are *worse*, it means the seed groupings conflict with the\n",
    "  embedding geometry — the expert categories do not match how the model organized\n",
    "  these words in semantic space.\n",
    "- If metrics are roughly equal, the seeds are compatible with the natural structure\n",
    "  but do not improve upon it.\n",
    "\n",
    "**Note:** Comparing k=7 (constrained) to k=8 (unconstrained) is slightly unequal\n",
    "because fewer clusters tend to lower silhouette (fewer, larger clusters are harder\n",
    "to keep internally coherent). The comparison is still informative about whether\n",
    "constraints help within a similar granularity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unconstrained metrics for direct comparison\n",
    "# (recomputed here to ensure identical metric calculations)\n",
    "unconstrained_metrics = {}\n",
    "for run_name in ['Agglomerative k=8', 'Agglomerative k=34']:\n",
    "    labels_unc = cluster_labels_dict[run_name]\n",
    "    unconstrained_metrics[run_name] = {\n",
    "        'Silhouette': silhouette_score(embeddings_10d, labels_unc),\n",
    "        'Davies-Bouldin': davies_bouldin_score(embeddings_10d, labels_unc),\n",
    "        'Calinski-Harabasz': calinski_harabasz_score(embeddings_10d, labels_unc),\n",
    "    }\n",
    "\n",
    "# Build comparison table\n",
    "comparison_rows = [\n",
    "    {\n",
    "        'Run': 'Unconstrained k=8',\n",
    "        'k': 8,\n",
    "        'Seeds': 'None',\n",
    "        **unconstrained_metrics['Agglomerative k=8'],\n",
    "    },\n",
    "    {\n",
    "        'Run': 'Constrained MC7',\n",
    "        'k': 7,\n",
    "        'Seeds': 'minute_cryptic_ho_7',\n",
    "        **metrics_mc7,\n",
    "    },\n",
    "    {\n",
    "        'Run': 'Unconstrained k=34',\n",
    "        'k': 34,\n",
    "        'Seeds': 'None',\n",
    "        **unconstrained_metrics['Agglomerative k=34'],\n",
    "    },\n",
    "    {\n",
    "        'Run': 'Constrained CG34',\n",
    "        'k': 34,\n",
    "        'Seeds': 'conceptual_groups',\n",
    "        **metrics_cg34,\n",
    "    },\n",
    "]\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_rows)\n",
    "\n",
    "# Formatted display\n",
    "df_display = df_comparison.copy()\n",
    "df_display['Silhouette'] = df_display['Silhouette'].map('{:.4f}'.format)\n",
    "df_display['Davies-Bouldin'] = df_display['Davies-Bouldin'].map('{:.4f}'.format)\n",
    "df_display['Calinski-Harabasz'] = df_display['Calinski-Harabasz'].map('{:.1f}'.format)\n",
    "\n",
    "print('=== Constrained vs. Unconstrained: Metrics Comparison ===\\n')\n",
    "print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265177f",
   "metadata": {},
   "source": [
    "### Cluster Scatter Plots\n",
    "\n",
    "The 2D UMAP projections below show each indicator colored by its constrained cluster\n",
    "assignment. Compare to the unconstrained scatter plots from NB 04:\n",
    "\n",
    "- **MC7 (k=7)**: 7 broad regions. If the seeds effectively anchored each wordplay\n",
    "  type, regions should roughly correspond to anagram, reversal, hidden,\n",
    "  container+insertion, deletion, homophone, and alternation.\n",
    "- **CG34 (k=34)**: More granular — each conceptual metaphor group defines a smaller\n",
    "  region. Adjacent regions sharing the same dominant Ho type may represent different\n",
    "  conceptual metaphors within the same wordplay type (e.g., \"disorder\" and \"movement\"\n",
    "  sub-clusters within anagram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b41786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(22, 9))\n",
    "\n",
    "constrained_runs = {\n",
    "    'Constrained MC7 (k=7)': labels_mc7,\n",
    "    'Constrained CG34 (k=34)': labels_cg34,\n",
    "}\n",
    "\n",
    "for ax, (title, labels) in zip(axes, constrained_runs.items()):\n",
    "    k = len(set(labels))\n",
    "    cmap = plt.cm.get_cmap('tab10' if k <= 10 else 'nipy_spectral', k)\n",
    "\n",
    "    ax.scatter(\n",
    "        embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "        c=labels, cmap=cmap, s=2, alpha=0.4, rasterized=True,\n",
    "    )\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.set_xlabel('UMAP 1', fontsize=10)\n",
    "    ax.set_ylabel('UMAP 2', fontsize=10)\n",
    "    ax.tick_params(labelsize=8)\n",
    "\n",
    "plt.suptitle('Constrained Agglomerative Clustering \\u2014 2D UMAP Projection',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'scatter_constrained.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Saved: {FIGURES_DIR / \"scatter_constrained.png\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23657a3e",
   "metadata": {},
   "source": [
    "### Per-Cluster Type Distribution\n",
    "\n",
    "Using the same heatmap approach from Section 2, we examine the Ho type composition\n",
    "of each constrained cluster. The key comparison: **do seed-constrained clusters\n",
    "achieve higher type purity than unconstrained clusters at similar k?**\n",
    "\n",
    "If constrained MC7 (k=7) shows purer clusters than unconstrained k=8, the expert\n",
    "seed words are successfully imposing wordplay-type structure that the embedding\n",
    "space alone does not naturally produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20671cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-cluster type distribution heatmaps ---\n",
    "constrained_type_dists = {}\n",
    "\n",
    "for run_name, labels in constrained_runs.items():\n",
    "    safe_name = (run_name.lower()\n",
    "                 .replace(' ', '_').replace('(', '').replace(')', '')\n",
    "                 .replace('=', ''))\n",
    "    ct_norm = plot_type_distribution(\n",
    "        cluster_labels=labels,\n",
    "        primary_ho=primary_ho_array,\n",
    "        ho_types=HO_TYPES,\n",
    "        type_colors=TYPE_COLORS,\n",
    "        title=f'Per-Cluster Ho Type Distribution \\u2014 {run_name}',\n",
    "        filename=f'type_distribution_{safe_name}.png',\n",
    "        max_clusters=40,\n",
    "        show_noise=False,\n",
    "    )\n",
    "    constrained_type_dists[run_name] = ct_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dominant type and purity per cluster ---\n",
    "for run_name, ct_norm in constrained_type_dists.items():\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'{run_name}')\n",
    "    print(f'{\"=\" * 60}')\n",
    "    for idx in ct_norm.index:\n",
    "        row = ct_norm.loc[idx]\n",
    "        dominant = row.idxmax()\n",
    "        purity = row.max()\n",
    "        print(f'  Cluster {str(idx):>6s}: dominant={dominant:<20s} purity={purity:.2f}')\n",
    "    avg_purity = ct_norm.max(axis=1).mean()\n",
    "    print(f'\\n  Average cluster purity: {avg_purity:.3f}')\n",
    "\n",
    "# --- Summary: purity across ALL runs (unconstrained + constrained) ---\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "print('Average Cluster Purity \\u2014 All Runs')\n",
    "print(f'{\"=\" * 60}')\n",
    "\n",
    "# Unconstrained (from Section 2)\n",
    "for run_name, ct_norm in type_dist_results.items():\n",
    "    numeric_rows = ct_norm.loc[ct_norm.index != 'noise']\n",
    "    avg = numeric_rows.max(axis=1).mean()\n",
    "    print(f'  {run_name:<40s}: {avg:.3f}')\n",
    "\n",
    "# Constrained (this section)\n",
    "for run_name, ct_norm in constrained_type_dists.items():\n",
    "    avg = ct_norm.max(axis=1).mean()\n",
    "    print(f'  {run_name:<40s}: {avg:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b8d8c",
   "metadata": {},
   "source": [
    "### Qualitative Inspection: Centroid-Nearest Indicators\n",
    "\n",
    "For each constrained cluster, we compute the cluster centroid (mean of the 10D\n",
    "embeddings of all indicators in the cluster) and find the 8 indicators closest\n",
    "to that centroid. These \"most representative\" indicators reveal what each cluster\n",
    "is about — whether it captured a coherent theme and whether that theme aligns\n",
    "with a specific wordplay type.\n",
    "\n",
    "**How to interpret:**\n",
    "- If centroid-nearest indicators all serve the same wordplay type, the cluster\n",
    "  successfully captured that type's vocabulary.\n",
    "- If they span multiple types, the cluster is organized around a **conceptual\n",
    "  metaphor** (e.g., spatial placement) that crosses type boundaries. This is\n",
    "  expected for types like container/insertion/hidden that share placement concepts.\n",
    "- Compare to the unconstrained k=8 and k=34 centroids from NB 04 to see if\n",
    "  constraints shifted cluster centers toward more type-coherent positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261aefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def inspect_cluster_centroids(labels, embeddings, indicator_names, primary_ho,\n",
    "                               n_nearest=8, max_clusters=None):\n",
    "    \"\"\"Print centroid-nearest indicators and type distribution per cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : array of int\n",
    "        Cluster assignment for each indicator.\n",
    "    embeddings : ndarray, shape (n_samples, n_features)\n",
    "        Embedding matrix (10D).\n",
    "    indicator_names : array of str\n",
    "        Indicator strings aligned with embeddings.\n",
    "    primary_ho : array of str\n",
    "        Primary Ho label per indicator.\n",
    "    n_nearest : int\n",
    "        Number of nearest indicators to show per cluster.\n",
    "    max_clusters : int or None\n",
    "        If set, only show this many clusters (largest first).\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(set(labels))\n",
    "\n",
    "    if max_clusters is not None:\n",
    "        # Sort by cluster size descending, take top N\n",
    "        sizes = {cl: (labels == cl).sum() for cl in unique_labels}\n",
    "        unique_labels = sorted(sizes, key=sizes.get, reverse=True)[:max_clusters]\n",
    "\n",
    "    for cl in unique_labels:\n",
    "        mask = labels == cl\n",
    "        cluster_size = mask.sum()\n",
    "\n",
    "        # Cluster centroid in 10D\n",
    "        centroid = embeddings[mask].mean(axis=0).reshape(1, -1)\n",
    "\n",
    "        # Distances from centroid to all cluster members\n",
    "        dists = cdist(centroid, embeddings[mask], metric='euclidean')[0]\n",
    "        nearest_local = np.argsort(dists)[:n_nearest]\n",
    "\n",
    "        # Map local indices back to full-array indices\n",
    "        cluster_indices = np.where(mask)[0]\n",
    "        nearest_full = cluster_indices[nearest_local]\n",
    "\n",
    "        # Type distribution for this cluster\n",
    "        types_in_cluster = pd.Series(primary_ho[mask])\n",
    "        type_dist = types_in_cluster.value_counts(normalize=True)\n",
    "        dominant = type_dist.index[0]\n",
    "        purity = type_dist.iloc[0]\n",
    "        type_str = ', '.join(f'{t}: {p:.0%}' for t, p in type_dist.head(3).items())\n",
    "\n",
    "        # Nearest indicators\n",
    "        nearest_strs = [indicator_names[i] for i in nearest_full]\n",
    "\n",
    "        print(f'Cluster {cl} (n={cluster_size:,}, '\n",
    "              f'dominant={dominant}, purity={purity:.2f}):')\n",
    "        print(f'  Types: {type_str}')\n",
    "        print(f'  Nearest: {nearest_strs}')\n",
    "        print()\n",
    "\n",
    "\n",
    "print('=== Constrained MC7 (k=7): Centroid-Nearest Indicators ===\\n')\n",
    "inspect_cluster_centroids(\n",
    "    labels_mc7, embeddings_10d, indicator_names, primary_ho_array,\n",
    ")\n",
    "\n",
    "print(f'\\n{\"=\" * 60}\\n')\n",
    "\n",
    "print('=== Constrained CG34 (k=34): Centroid-Nearest Indicators ===\\n')\n",
    "inspect_cluster_centroids(\n",
    "    labels_cg34, embeddings_10d, indicator_names, primary_ho_array,\n",
    "    max_clusters=20,  # top 20 by size to keep output manageable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb94614",
   "metadata": {},
   "source": [
    "### Save Section 3 Outputs\n",
    "\n",
    "We save constrained cluster labels and metrics for use in Notebook 06 (evaluation\n",
    "and report figures) and for comparison across all clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ddd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save constrained cluster labels ---\n",
    "for label_name, labels, filename in [\n",
    "    ('Constrained MC7', labels_mc7, 'cluster_labels_constrained_mc7.csv'),\n",
    "    ('Constrained CG34', labels_cg34, 'cluster_labels_constrained_cg34.csv'),\n",
    "]:\n",
    "    df_out = pd.DataFrame({\n",
    "        'indicator': indicator_names,\n",
    "        'cluster_label': labels,\n",
    "    })\n",
    "    out_path = DATA_DIR / filename\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f'Saved: {out_path}')\n",
    "\n",
    "# --- Save metrics comparison ---\n",
    "df_comparison.to_csv(\n",
    "    OUTPUT_DIR / 'constrained_vs_unconstrained_metrics.csv', index=False)\n",
    "print(f'Saved: {OUTPUT_DIR / \"constrained_vs_unconstrained_metrics.csv\"}')\n",
    "\n",
    "# --- Save constrained type distribution tables ---\n",
    "for run_name, ct_norm in constrained_type_dists.items():\n",
    "    safe_name = (run_name.lower()\n",
    "                 .replace(' ', '_').replace('(', '').replace(')', '')\n",
    "                 .replace('=', ''))\n",
    "    out_path = OUTPUT_DIR / f'type_distribution_{safe_name}.csv'\n",
    "    ct_norm.to_csv(out_path)\n",
    "    print(f'Saved: {out_path}')\n",
    "\n",
    "# --- List all Section 3 outputs ---\n",
    "print(f'\\nSection 3 figures in {FIGURES_DIR}:')\n",
    "for pattern in ['scatter_constrained*', 'type_distribution_constrained*']:\n",
    "    for f in sorted(FIGURES_DIR.glob(pattern)):\n",
    "        print(f'  {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c1141",
   "metadata": {},
   "source": [
    "### Interpretation: Does Expert Knowledge Improve Clustering?\n",
    "\n",
    "#### MC7 (k=7): Wordplay-Type Level\n",
    "\n",
    "Compare constrained MC7 purity to the unconstrained k=8 baseline:\n",
    "\n",
    "- **Which types benefited most from constraints?** Expect homophone and reversal\n",
    "  to remain strong (they were already spatially concentrated in the overlay plots).\n",
    "  The most interesting question is whether container+insertion, hidden, and deletion\n",
    "  — the types that overlapped most in the unconstrained analysis — improved.\n",
    "- **Did merging container+insertion help?** If the combined cluster is purer than\n",
    "  the separate container and insertion clusters would be, the merge was justified.\n",
    "  This confirms the DOMAIN_KNOWLEDGE.md prediction that these inverse operations\n",
    "  share too much indicator vocabulary to separate.\n",
    "- **Anagram dominance:** Anagram accounts for ~51% of indicators. In unconstrained\n",
    "  k=8, multiple clusters were anagram-dominated simply by base rate. Did the MC7\n",
    "  seeds help confine anagram to fewer, purer clusters?\n",
    "\n",
    "#### CG34 (k=34): Conceptual-Metaphor Level\n",
    "\n",
    "Compare constrained CG34 to unconstrained k=34:\n",
    "\n",
    "- **Do conceptual-metaphor clusters align better with types?** If clusters like\n",
    "  \"movement\", \"disorder\", \"tamper\" all map cleanly to anagram, while \"containing\",\n",
    "  \"surrounding\", \"holding\" map to container/insertion, the conceptual hierarchy from\n",
    "  DOMAIN_KNOWLEDGE.md is empirically supported.\n",
    "- **Which concepts span multiple types?** These are the shared-metaphor groups\n",
    "  (e.g., \"containing\" seeds appear under container, hidden, AND insertion). Their\n",
    "  type distribution reveals whether the embedding space respects the type boundary\n",
    "  or the conceptual-metaphor boundary.\n",
    "- **Centroid inspection:** Do the nearest-to-centroid indicators confirm the\n",
    "  conceptual-metaphor interpretation? If the \"movement\" cluster's nearest words\n",
    "  are \"dancing\", \"stirring\", \"mixing\", the conceptual label is validated.\n",
    "\n",
    "#### What These Results Mean for the Report\n",
    "\n",
    "**If constrained > unconstrained:** Expert knowledge provides meaningful structure\n",
    "that the embedding space alone does not produce. The report can frame this as\n",
    "\"semi-supervised clustering outperforms purely unsupervised methods.\"\n",
    "\n",
    "**If constrained ≈ unconstrained:** Seeds are compatible with the natural structure\n",
    "but redundant — the embedding model already captured the relevant organization.\n",
    "This is still a positive finding: the BGE-M3 embeddings faithfully encode\n",
    "wordplay-relevant semantics without needing expert guidance.\n",
    "\n",
    "**If constrained < unconstrained:** The expert categories conflict with the embedding\n",
    "geometry. This would suggest that the traditional wordplay taxonomy does not map\n",
    "cleanly onto distributional semantics — a meaningful finding about the gap between\n",
    "how CCC solvers categorize indicators and how language models represent them.\n",
    "\n",
    "Any of these outcomes advances the project's central question about whether\n",
    "wordplay type structure is recoverable from indicator semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac581cea",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Subset Experiments — to be added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ccc)",
   "language": "python",
   "name": "crossword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
