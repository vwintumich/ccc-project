{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWXoqfou2Nhd"
   },
   "source": "# Cluster Verified Indicators with BGE-M3 Embeddings\n\n**Primary authors:** Victoria (HDBSCAN clustering, embedding pipeline, cohesion analysis), Sahana (agglomerative clustering, seed word integration)\n**Builds on:** Data Cleaning for Indicator Clustering copy.ipynb (Victoria)\n**Prompt engineering:** Victoria\n**AI assistance:** Claude (Anthropic), Gemini (Google)\n**Environment:** Local (with sentence-transformers installed) or Colab (GPU recommended)\n\n---\n\nWith 14,000 examples, you have enough data for patterns to emerge, but you also have enough \"density\" to make the \"Curse of Dimensionality\" a real problem.\nIn a 14k dataset of short phrases, many will be near-duplicates or highly similar. Here is how to adjust the previous approach for this larger volume:\n\n## 1. Scaling the Parameters\nWith 14,000 rows, a n_neighbors=5 setting is too small; it will be too sensitive to tiny variations and create thousands of tiny clusters.\n* <b>Increase `n_neighbors`</b>: Try <b>15 to 30</b>. This forces UMAP to look at the broader \"neighborhood\" of a phrase, which helps group various ways of saying the same thing (e.g., grouping \"ignoring odds\" with all 15 variations of that concept).\n* <b>Dimensions</b>: Stick to <b>5–10</b> for clustering. Even with 14k rows, the semantic \"concepts\" in 1–6 word phrases aren't complex enough to justify 50 dimensions.\n## 2. The Clustering Strategy (HDBSCAN)\nStandard K-Means is a bad fit for 14,000 phrases because it assumes all clusters are \"round\" and of similar size. <b>HDBSCAN</b> is far superior here because:\n* It handles <b>varying densities</b> (some clusters might have 500 phrases, others only 10).\n* It identifies <b>noise</b> (out of 14k phrases, a few thousand will likely be unique \"junk\" that shouldn't be forced into a cluster).\n## 3. Optimized Workflow for 14k Rows\nSince BGE-M3 is a heavy model, you should process this in <b>batches</b> to avoid memory errors."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 59704,
     "status": "ok",
     "timestamp": 1771272809757,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "nPtz4xew-BVX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m       \u001b[38;5;66;03m# umap may take 15-60 seconds to import\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap       # umap may take 15-60 seconds to import\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# PATHS & CONFIG\n",
    "# ==========================\n",
    "# 1. Detect environment\n",
    "IS_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PROJECT_ROOT = Path('/content/drive/MyDrive/SIADS 692 Milestone II/Milestone II - NLP Cryptic Crossword Clues')\n",
    "else:\n",
    "    # On local, move up from notebooks/ to project root\n",
    "    # Adjust the number of .parent calls based on where this notebook sits\n",
    "    PROJECT_ROOT = Path.cwd().parent \n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1771273105023,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "JCpAJ2n38CoD"
   },
   "outputs": [],
   "source": [
    "# Load the data (using pandas) to make a list of verified indicators\n",
    "df = pd.read_csv(f'{DATA_DIR}/verified_indicators.csv', header=None)\n",
    "#df = pd.read_csv('verified_indicators.csv', header=None)\n",
    "\n",
    "# Name the column\n",
    "df.rename(columns={0: 'indicator'}, inplace=True)\n",
    "\n",
    "# Make the data into a list as the BGE-M3 model requires\n",
    "verified_indicators_list = df['indicator'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiOPQUnlULF7"
   },
   "source": [
    "The next cell is SLOW to create the embeddings. See instructions below to adjust Colab settings and use alternative code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d7db1bab60f1444baf54e838dbe94917",
      "4226318d44d14a9bac2ae0e51be39219"
     ]
    },
    "id": "LVPPuZem3Akr",
    "outputId": "819aa27d-b1c9-4d6c-925d-c5461cb11818"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581ccbe5eaf4180ab9dd4e034886155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vwinters/.conda/envs/nlp_env/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Embed the indicator phrases and cluster them\n",
    "\n",
    "# 1. Load the BGE-M3 model (for dense embeddings)\n",
    "# This model is specifically designed for short-to-long text consistency\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# 2. Generate the Embeddings\n",
    "# batch_size=32 or 64 helps manage GPU/RAM memory\n",
    "embeddings = model.encode(\n",
    "    verified_indicators_list,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True\n",
    "    )\n",
    "\n",
    "# 3. Dimensionality Reduction with UMAP\n",
    "# We reduce from BGE-M3's 1024 dimensions to 5-10 to \"distill\"\n",
    "# the semantic signal\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=30,      # Increased for larger dataset\n",
    "    min_dist=0.0,        # Helps HDBSCAN find dense clusters\n",
    "    n_components=10,     # Slightly more \"room\" for 14k rows\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "embeddings_reduced = reducer.fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original embeddings as parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzrbaCMZTjjz"
   },
   "source": [
    "Since you are on Google Colab, you have access to a free T4 GPU, which is the single best way to make your 14,000-row analysis fly. Without the GPU, BGE-M3 will be painfully slow on Colab's standard CPU.\n",
    "### Step 1: Turn on the GPU\n",
    "1. Go to the Runtime menu at the top.\n",
    "2. Select Change runtime type.\n",
    "3. Under \"Hardware accelerator,\" choose T4 GPU (or any available GPU).\n",
    "4. Click Save.\n",
    "### Step 2: High-Speed Encoding Code\n",
    "Now that the GPU is active, use this specific configuration to process your 14k list in a fraction of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "K6txKZ-0TX9u"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Load the model directly to the GPU\n",
    "# 'cuda' is the engine that powers the NVIDIA T4 GPU\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#model = SentenceTransformer('BAAI/bge-m3', device=device)\n",
    "\n",
    "# 2. Encode with a larger batch size\n",
    "# Colab's T4 can easily handle a batch_size of 128 for short phrases\n",
    "#embeddings = model.encode(\n",
    "#    your_14k_list,\n",
    "#    batch_size=128,\n",
    "#    show_progress_bar=True,\n",
    "#    convert_to_numpy=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rxOtrSLKFZZ6",
    "outputId": "a83fe237-353d-4d6a-f2b3-640053dda5f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vwinters/.conda/envs/nlp_env/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:722: FutureWarning: The default value of `copy` will change from False to True in 1.10. Explicitly set a value for `copy` to silence this warning.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Clustering with HDBSCAN - Find the natural groups\n",
    "# This algorithm doesn't force us to pick the number of clusters k\n",
    "clusterer = HDBSCAN(\n",
    "    min_cluster_size=10 # Minimum number of phrases to form a \"theme\"\n",
    ")\n",
    "cluster_labels = clusterer.fit_predict(embeddings_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9cXMSkU-HO83"
   },
   "outputs": [],
   "source": [
    "# Store the data and results in a summary dataframe\n",
    "df_results = pd.DataFrame({\n",
    "    \"phrase\": verified_indicators_list,  # The exact list used for model.encode\n",
    "    \"cluster\": clusterer.labels_,        # The output from clusterer.fit_predict\n",
    "    \"probability\": clusterer.probabilities_\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBlVevkL6mY_"
   },
   "source": [
    "To extract representative phrases from HDBSCAN, we leverage the `probabilities_` attribute.\n",
    "\n",
    "In density-based clustering, the \"most representative\" points aren't just in the spatial center; they are the points with the highest <b>membership probability</b>, meaning they are located in the densest, most stable part of the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4A5_F2O5GpyO",
    "outputId": "c868f730-aa60-49a4-e392-0ccc37262006",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Clusters Found: 352\n",
      "Total Noise Points (Cluster -1): 4210\n",
      "\n",
      "=== Cluster 176 | Size: 185 phrases ===\n",
      "  1. volunteers up\n",
      "  2. when growing up\n",
      "  3. when climbing\n",
      "  4. upward\n",
      "  5. upped\n",
      "----------------------------------------\n",
      "=== Cluster 95 | Size: 150 phrases ===\n",
      "  1. recounted\n",
      "  2. after reorganisation\n",
      "  3. after replanting\n",
      "  4. being replanted\n",
      "  5. being redeveloped\n",
      "----------------------------------------\n",
      "=== Cluster 175 | Size: 150 phrases ===\n",
      "  1. return of\n",
      "  2. made a return\n",
      "  3. it will come back\n",
      "  4. has come back\n",
      "  5. having got back\n",
      "----------------------------------------\n",
      "=== Cluster 321 | Size: 131 phrases ===\n",
      "  1. becoming odd\n",
      "  2. in a strange way\n",
      "  3. in an odd way\n",
      "  4. in an unconventional way\n",
      "  5. in peculiar guise\n",
      "----------------------------------------\n",
      "=== Cluster 327 | Size: 126 phrases ===\n",
      "  1. scatty\n",
      "  2. sally\n",
      "  3. shabby\n",
      "  4. shaggy\n",
      "  5. shaky\n",
      "----------------------------------------\n",
      "=== Cluster 64 | Size: 115 phrases ===\n",
      "  1. affair\n",
      "  2. becomes involved\n",
      "  3. to take part in\n",
      "  4. taking part\n",
      "  5. taking part in\n",
      "----------------------------------------\n",
      "=== Cluster 273 | Size: 106 phrases ===\n",
      "  1. dressed\n",
      "  2. clothed\n",
      "  3. clad in\n",
      "  4. clothed in\n",
      "  5. dressed in\n",
      "----------------------------------------\n",
      "=== Cluster 266 | Size: 101 phrases ===\n",
      "  1. after breaking\n",
      "  2. and falling apart\n",
      "  3. being broken\n",
      "  4. being shattered\n",
      "  5. being shot to pieces\n",
      "----------------------------------------\n",
      "=== Cluster 236 | Size: 100 phrases ===\n",
      "  1. made out\n",
      "  2. being fabricated\n",
      "  3. produced\n",
      "  4. fabricated\n",
      "  5. fabricating\n",
      "----------------------------------------\n",
      "=== Cluster 154 | Size: 97 phrases ===\n",
      "  1. to set up\n",
      "  2. to be set up\n",
      "  3. set\n",
      "  4. set about\n",
      "  5. set up\n",
      "----------------------------------------\n",
      "=== Cluster 91 | Size: 84 phrases ===\n",
      "  1. to gain entry to\n",
      "  2. thematically entered\n",
      "  3. are into\n",
      "  4. coming to grief\n",
      "  5. being entry for\n",
      "----------------------------------------\n",
      "=== Cluster 339 | Size: 81 phrases ===\n",
      "  1. uneven\n",
      "  2. become untidy\n",
      "  3. uncouth\n",
      "  4. unholy\n",
      "  5. unsound\n",
      "----------------------------------------\n",
      "=== Cluster 342 | Size: 81 phrases ===\n",
      "  1. catastrophic\n",
      "  2. catastrophically\n",
      "  3. disastrous\n",
      "  4. horrendous\n",
      "  5. horrid\n",
      "----------------------------------------\n",
      "=== Cluster 99 | Size: 80 phrases ===\n",
      "  1. admitting\n",
      "  2. accepting\n",
      "  3. accept\n",
      "  4. accepted\n",
      "  5. accepted by\n",
      "----------------------------------------\n",
      "=== Cluster 116 | Size: 78 phrases ===\n",
      "  1. taken\n",
      "  2. taken\n",
      "  3. taken by\n",
      "  4. taken in\n",
      "  5. taking\n",
      "----------------------------------------\n",
      "=== Cluster 130 | Size: 77 phrases ===\n",
      "  1. staying\n",
      "  2. kept by\n",
      "  3. to be kept within\n",
      "  4. in keeping of\n",
      "  5. in the keeping of\n",
      "----------------------------------------\n",
      "=== Cluster 344 | Size: 72 phrases ===\n",
      "  1. can upset\n",
      "  2. must be upset\n",
      "  3. get upset\n",
      "  4. if upset\n",
      "  5. getting upset\n",
      "----------------------------------------\n",
      "=== Cluster 146 | Size: 70 phrases ===\n",
      "  1. what turns\n",
      "  2. when it turns\n",
      "  3. turning\n",
      "  4. turning around\n",
      "  5. turning heads\n",
      "----------------------------------------\n",
      "=== Cluster 334 | Size: 70 phrases ===\n",
      "  1. twirling\n",
      "  2. swivelling\n",
      "  3. in a whirl\n",
      "  4. in a whirl\n",
      "  5. swirling\n",
      "----------------------------------------\n",
      "=== Cluster 187 | Size: 70 phrases ===\n",
      "  1. to provide home for\n",
      "  2. to house\n",
      "  3. to provide accommodation for\n",
      "  4. accommodation\n",
      "  5. resident in\n",
      "----------------------------------------\n",
      "=== Cluster 189 | Size: 69 phrases ===\n",
      "  1. to secure\n",
      "  2. secured\n",
      "  3. protected\n",
      "  4. protected by\n",
      "  5. protects\n",
      "----------------------------------------\n",
      "=== Cluster 148 | Size: 67 phrases ===\n",
      "  1. listened to\n",
      "  2. heard\n",
      "  3. given a hearing\n",
      "  4. hearing\n",
      "  5. hearing of\n",
      "----------------------------------------\n",
      "=== Cluster 240 | Size: 65 phrases ===\n",
      "  1. a new\n",
      "  2. anew\n",
      "  3. in new style\n",
      "  4. new\n",
      "  5. new production\n",
      "----------------------------------------\n",
      "=== Cluster 209 | Size: 62 phrases ===\n",
      "  1. at work\n",
      "  2. employed by\n",
      "  3. employing\n",
      "  4. employed\n",
      "  5. employ\n",
      "----------------------------------------\n",
      "=== Cluster 92 | Size: 61 phrases ===\n",
      "  1. all change\n",
      "  2. change\n",
      "  3. change in\n",
      "  4. change of\n",
      "  5. changes to\n",
      "----------------------------------------\n",
      "=== Cluster 197 | Size: 59 phrases ===\n",
      "  1. encapsulates\n",
      "  2. engulfing\n",
      "  3. encapsulated\n",
      "  4. encapsulates\n",
      "  5. encapsulates\n",
      "----------------------------------------\n",
      "=== Cluster 6 | Size: 58 phrases ===\n",
      "  1. being distributed\n",
      "  2. being widespread\n",
      "  3. disseminating\n",
      "  4. distribute\n",
      "  5. distributed\n",
      "----------------------------------------\n",
      "=== Cluster 77 | Size: 57 phrases ===\n",
      "  1. regularly clipping\n",
      "  2. regularly displayed\n",
      "  3. regularly throughout\n",
      "  4. regularly use\n",
      "  5. regularly spotted\n",
      "----------------------------------------\n",
      "=== Cluster 66 | Size: 57 phrases ===\n",
      "  1. conversion\n",
      "  2. convert\n",
      "  3. converts\n",
      "  4. converter\n",
      "  5. for conversion\n",
      "----------------------------------------\n",
      "=== Cluster 218 | Size: 55 phrases ===\n",
      "  1. being cooked\n",
      "  2. casserole\n",
      "  3. cook\n",
      "  4. cook up\n",
      "  5. gets cooked\n",
      "----------------------------------------\n",
      "=== Cluster 42 | Size: 54 phrases ===\n",
      "  1. could appear as\n",
      "  2. could be\n",
      "  3. could be clued as\n",
      "  4. it might be\n",
      "  5. it could be\n",
      "----------------------------------------\n",
      "=== Cluster 242 | Size: 53 phrases ===\n",
      "  1. for organising\n",
      "  2. get organised\n",
      "  3. having been organised\n",
      "  4. orchestrated\n",
      "  5. orchestrating\n",
      "----------------------------------------\n",
      "=== Cluster 238 | Size: 53 phrases ===\n",
      "  1. cut\n",
      "  2. cut up\n",
      "  3. cutting taken from\n",
      "  4. cut\n",
      "  5. cut of\n",
      "----------------------------------------\n",
      "=== Cluster 98 | Size: 53 phrases ===\n",
      "  1. within\n",
      "  2. on the inside\n",
      "  3. innately\n",
      "  4. inside\n",
      "  5. interior of\n",
      "----------------------------------------\n",
      "=== Cluster 128 | Size: 53 phrases ===\n",
      "  1. so the saying goes\n",
      "  2. so they say\n",
      "  3. say\n",
      "  4. it is said\n",
      "  5. is said\n",
      "----------------------------------------\n",
      "=== Cluster 279 | Size: 52 phrases ===\n",
      "  1. to be ignored\n",
      "  2. ignore\n",
      "  3. ignore\n",
      "  4. ignores\n",
      "  5. ignoring\n",
      "----------------------------------------\n",
      "=== Cluster 260 | Size: 52 phrases ===\n",
      "  1. destructed\n",
      "  2. in ruin\n",
      "  3. is destroyed\n",
      "  4. ruin\n",
      "  5. ruination\n",
      "----------------------------------------\n",
      "=== Cluster 50 | Size: 51 phrases ===\n",
      "  1. regular treatment\n",
      "  2. be treated\n",
      "  3. given treatment\n",
      "  4. requires treatment\n",
      "  5. to be treated\n",
      "----------------------------------------\n",
      "=== Cluster 207 | Size: 51 phrases ===\n",
      "  1. a mixture of\n",
      "  2. gets mixed\n",
      "  3. hybrid\n",
      "  4. is mixed\n",
      "  5. mix\n",
      "----------------------------------------\n",
      "=== Cluster 63 | Size: 51 phrases ===\n",
      "  1. wrote up\n",
      "  2. written in\n",
      "  3. written in the\n",
      "  4. to pen\n",
      "  5. spelled out in\n",
      "----------------------------------------\n",
      "=== Cluster 306 | Size: 50 phrases ===\n",
      "  1. after moving\n",
      "  2. being relocated\n",
      "  3. could be moved\n",
      "  4. is to be relocated\n",
      "  5. may be moved\n",
      "----------------------------------------\n",
      "=== Cluster 143 | Size: 50 phrases ===\n",
      "  1. of speaking\n",
      "  2. of speech\n",
      "  3. speaking\n",
      "  4. talking\n",
      "  5. in speaking\n",
      "----------------------------------------\n",
      "=== Cluster 283 | Size: 49 phrases ===\n",
      "  1. oddly removed\n",
      "  2. wiping out\n",
      "  3. with dismissal of\n",
      "  4. wanting rid of\n",
      "  5. when discarding\n",
      "----------------------------------------\n",
      "=== Cluster 255 | Size: 49 phrases ===\n",
      "  1. plunging into\n",
      "  2. being submerged in\n",
      "  3. dipped in\n",
      "  4. drowned in\n",
      "  5. drowning in\n",
      "----------------------------------------\n",
      "=== Cluster 213 | Size: 48 phrases ===\n",
      "  1. demanded by drunkard\n",
      "  2. drunk\n",
      "  3. drunk with\n",
      "  4. having got drunk\n",
      "  5. having inebriated\n",
      "----------------------------------------\n",
      "=== Cluster 210 | Size: 48 phrases ===\n",
      "  1. being played\n",
      "  2. for play\n",
      "  3. for playing\n",
      "  4. in play\n",
      "  5. is being played\n",
      "----------------------------------------\n",
      "=== Cluster 288 | Size: 48 phrases ===\n",
      "  1. can be unravelled\n",
      "  2. uncovered\n",
      "  3. unmasked\n",
      "  4. unwrapped\n",
      "  5. uncorked\n",
      "----------------------------------------\n",
      "=== Cluster 104 | Size: 48 phrases ===\n",
      "  1. advertised\n",
      "  2. showing\n",
      "  3. shown by\n",
      "  4. displayed\n",
      "  5. displayed\n",
      "----------------------------------------\n",
      "=== Cluster 331 | Size: 47 phrases ===\n",
      "  1. after fiddling\n",
      "  2. fiddle\n",
      "  3. fiddle with\n",
      "  4. fiddled with\n",
      "  5. fidget\n",
      "----------------------------------------\n",
      "=== Cluster 44 | Size: 47 phrases ===\n",
      "  1. can be produced\n",
      "  2. capable of making\n",
      "  3. can make\n",
      "  4. can produce\n",
      "  5. could be made of\n",
      "----------------------------------------\n",
      "=== Cluster 223 | Size: 47 phrases ===\n",
      "  1. eating\n",
      "  2. eating\n",
      "  3. eats\n",
      "  4. when eating\n",
      "  5. stomachs\n",
      "----------------------------------------\n",
      "=== Cluster 156 | Size: 47 phrases ===\n",
      "  1. westbound\n",
      "  2. westward\n",
      "  3. to west\n",
      "  4. travelling westward\n",
      "  5. region to the west\n",
      "----------------------------------------\n",
      "=== Cluster 21 | Size: 46 phrases ===\n",
      "  1. a contingent of\n",
      "  2. gathered round\n",
      "  3. gathered\n",
      "  4. gathered in\n",
      "  5. gathered\n",
      "----------------------------------------\n",
      "=== Cluster 35 | Size: 45 phrases ===\n",
      "  1. on board\n",
      "  2. being loaded on board\n",
      "  3. boarding\n",
      "  4. taking on board\n",
      "  5. going aboard\n",
      "----------------------------------------\n",
      "=== Cluster 262 | Size: 45 phrases ===\n",
      "  1. deformed\n",
      "  2. deforming\n",
      "  3. degenerate\n",
      "  4. decrepit\n",
      "  5. defaced\n",
      "----------------------------------------\n",
      "=== Cluster 2 | Size: 45 phrases ===\n",
      "  1. embraces\n",
      "  2. embracing\n",
      "  3. embraced\n",
      "  4. embraces\n",
      "  5. embracing\n",
      "----------------------------------------\n",
      "=== Cluster 138 | Size: 43 phrases ===\n",
      "  1. roughly\n",
      "  2. mostly\n",
      "  3. practically\n",
      "  4. nearly\n",
      "  5. most\n",
      "----------------------------------------\n",
      "=== Cluster 101 | Size: 43 phrases ===\n",
      "  1. characters reincarnated\n",
      "  2. revived\n",
      "  3. retrieved\n",
      "  4. retrieving\n",
      "  5. resurrected\n",
      "----------------------------------------\n",
      "=== Cluster 15 | Size: 42 phrases ===\n",
      "  1. include\n",
      "  2. included\n",
      "  3. included by\n",
      "  4. is inclusive of\n",
      "  5. included\n",
      "----------------------------------------\n",
      "=== Cluster 271 | Size: 42 phrases ===\n",
      "  1. without a\n",
      "  2. without any\n",
      "  3. without love\n",
      "  4. without one\n",
      "  5. without secrets now and then\n",
      "----------------------------------------\n",
      "=== Cluster 268 | Size: 42 phrases ===\n",
      "  1. not altogether\n",
      "  2. not completely\n",
      "  3. not entirely\n",
      "  4. not for the most part\n",
      "  5. not totally\n",
      "----------------------------------------\n",
      "=== Cluster 276 | Size: 42 phrases ===\n",
      "  1. milk producer rejected\n",
      "  2. is rejected\n",
      "  3. turned down\n",
      "  4. rejected\n",
      "  5. oddly rejected\n",
      "----------------------------------------\n",
      "=== Cluster 204 | Size: 42 phrases ===\n",
      "  1. attracted by\n",
      "  2. enthralled by\n",
      "  3. captivated\n",
      "  4. captivated by\n",
      "  5. in thrall to\n",
      "----------------------------------------\n",
      "=== Cluster 350 | Size: 41 phrases ===\n",
      "  1. misheard\n",
      "  2. mislaid\n",
      "  3. misguided\n",
      "  4. misapplying\n",
      "  5. misdealt\n",
      "----------------------------------------\n",
      "=== Cluster 170 | Size: 41 phrases ===\n",
      "  1. a runner in\n",
      "  2. running back\n",
      "  3. going on a mazy run\n",
      "  4. having run\n",
      "  5. is running\n",
      "----------------------------------------\n",
      "=== Cluster 96 | Size: 41 phrases ===\n",
      "  1. seen around in\n",
      "  2. seen around\n",
      "  3. seen across\n",
      "  4. seen around\n",
      "  5. seen around opening of\n",
      "----------------------------------------\n",
      "=== Cluster 102 | Size: 41 phrases ===\n",
      "  1. it has to be said\n",
      "  2. it must be said\n",
      "  3. must contribute\n",
      "  4. must have\n",
      "  5. must perform\n",
      "----------------------------------------\n",
      "=== Cluster 166 | Size: 40 phrases ===\n",
      "  1. when going over\n",
      "  2. is over\n",
      "  3. got over\n",
      "  4. going over limits\n",
      "  5. dad getting over\n",
      "----------------------------------------\n",
      "=== Cluster 317 | Size: 39 phrases ===\n",
      "  1. knocked about\n",
      "  2. getting knocked over\n",
      "  3. gets knocked over\n",
      "  4. knocked over\n",
      "  5. knocking off\n",
      "----------------------------------------\n",
      "=== Cluster 88 | Size: 38 phrases ===\n",
      "  1. change required in\n",
      "  2. must change\n",
      "  3. needing adjustment\n",
      "  4. needing to change\n",
      "  5. needs adjustment\n",
      "----------------------------------------\n",
      "=== Cluster 332 | Size: 38 phrases ===\n",
      "  1. rambling\n",
      "  2. when rambling\n",
      "  3. rambles\n",
      "  4. rambling\n",
      "  5. rambling about\n",
      "----------------------------------------\n",
      "=== Cluster 291 | Size: 38 phrases ===\n",
      "  1. roll\n",
      "  2. roll up\n",
      "  3. rolled\n",
      "  4. rolled over\n",
      "  5. rolls\n",
      "----------------------------------------\n",
      "=== Cluster 84 | Size: 37 phrases ===\n",
      "  1. regional broadcast\n",
      "  2. of broadcasters\n",
      "  3. broadcast\n",
      "  4. broadcasting\n",
      "  5. broadcast\n",
      "----------------------------------------\n",
      "=== Cluster 37 | Size: 37 phrases ===\n",
      "  1. picked up\n",
      "  2. picked up from\n",
      "  3. picked up on the mike\n",
      "  4. having picked up\n",
      "  5. being picked up\n",
      "----------------------------------------\n",
      "=== Cluster 229 | Size: 37 phrases ===\n",
      "  1. capturing\n",
      "  2. captures\n",
      "  3. capturing\n",
      "  4. wants to capture\n",
      "  5. to capture\n",
      "----------------------------------------\n",
      "=== Cluster 222 | Size: 37 phrases ===\n",
      "  1. and is consumed therein\n",
      "  2. has consumed\n",
      "  3. consumed\n",
      "  4. consumed by\n",
      "  5. consumed in\n",
      "----------------------------------------\n",
      "=== Cluster 215 | Size: 36 phrases ===\n",
      "  1. to serve up\n",
      "  2. to be served up\n",
      "  3. served up portion\n",
      "  4. serving up\n",
      "  5. serve up\n",
      "----------------------------------------\n",
      "=== Cluster 36 | Size: 36 phrases ===\n",
      "  1. being set free\n",
      "  2. free\n",
      "  3. freed\n",
      "  4. freeform\n",
      "  5. freestyle\n",
      "----------------------------------------\n",
      "=== Cluster 118 | Size: 36 phrases ===\n",
      "  1. get some\n",
      "  2. gets\n",
      "  3. getting bolshie\n",
      "  4. getting\n",
      "  5. getting\n",
      "----------------------------------------\n",
      "=== Cluster 115 | Size: 36 phrases ===\n",
      "  1. stored\n",
      "  2. stowing\n",
      "  3. stashed\n",
      "  4. stored\n",
      "  5. storing\n",
      "----------------------------------------\n",
      "=== Cluster 234 | Size: 35 phrases ===\n",
      "  1. being messed about\n",
      "  2. i mess about when lapsed\n",
      "  3. if messed around\n",
      "  4. making a mess of\n",
      "  5. made a mess of\n",
      "----------------------------------------\n",
      "=== Cluster 113 | Size: 35 phrases ===\n",
      "  1. a variety\n",
      "  2. appearing in variety\n",
      "  3. at variance\n",
      "  4. in variety\n",
      "  5. is variable\n",
      "----------------------------------------\n",
      "=== Cluster 38 | Size: 35 phrases ===\n",
      "  1. being developed\n",
      "  2. develop\n",
      "  3. developed as\n",
      "  4. developing\n",
      "  5. development of\n",
      "----------------------------------------\n",
      "=== Cluster 267 | Size: 35 phrases ===\n",
      "  1. dividing up\n",
      "  2. divide\n",
      "  3. divided\n",
      "  4. dividing\n",
      "  5. to be divided by\n",
      "----------------------------------------\n",
      "=== Cluster 127 | Size: 35 phrases ===\n",
      "  1. provided by\n",
      "  2. provided\n",
      "  3. providing\n",
      "  4. donated by\n",
      "  5. donated by\n",
      "----------------------------------------\n",
      "=== Cluster 68 | Size: 35 phrases ===\n",
      "  1. the heart of\n",
      "  2. at heart\n",
      "  3. is at heart\n",
      "  4. her heart\n",
      "  5. heart of\n",
      "----------------------------------------\n",
      "=== Cluster 277 | Size: 34 phrases ===\n",
      "  1. after loss\n",
      "  2. to lose\n",
      "  3. to be losing heart\n",
      "  4. loses heart\n",
      "  5. losing head\n",
      "----------------------------------------\n",
      "=== Cluster 244 | Size: 34 phrases ===\n",
      "  1. order from\n",
      "  2. for ordering\n",
      "  3. order\n",
      "  4. order to\n",
      "  5. ordered\n",
      "----------------------------------------\n",
      "=== Cluster 217 | Size: 34 phrases ===\n",
      "  1. used up\n",
      "  2. using up\n",
      "  3. used in\n",
      "  4. uses\n",
      "  5. using\n",
      "----------------------------------------\n",
      "=== Cluster 235 | Size: 34 phrases ===\n",
      "  1. be creative\n",
      "  2. creative\n",
      "  3. creatively\n",
      "  4. illusion\n",
      "  5. imaginatively\n",
      "----------------------------------------\n",
      "=== Cluster 90 | Size: 34 phrases ===\n",
      "  1. carried about\n",
      "  2. carried away\n",
      "  3. carried out\n",
      "  4. carrying\n",
      "  5. carried\n",
      "----------------------------------------\n",
      "=== Cluster 191 | Size: 34 phrases ===\n",
      "  1. decked out\n",
      "  2. outside\n",
      "  3. outside of\n",
      "  4. on the outside of\n",
      "  5. on outside of\n",
      "----------------------------------------\n",
      "=== Cluster 253 | Size: 33 phrases ===\n",
      "  1. detonated\n",
      "  2. detonating\n",
      "  3. exploded\n",
      "  4. explodes\n",
      "  5. exploding\n",
      "----------------------------------------\n",
      "=== Cluster 251 | Size: 33 phrases ===\n",
      "  1. thrown on\n",
      "  2. tossed in\n",
      "  3. thrown\n",
      "  4. thrown in\n",
      "  5. thrown into\n",
      "----------------------------------------\n",
      "=== Cluster 338 | Size: 33 phrases ===\n",
      "  1. can be confused\n",
      "  2. confusion\n",
      "  3. confused\n",
      "  4. get confused\n",
      "  5. gets confused\n",
      "----------------------------------------\n",
      "=== Cluster 192 | Size: 32 phrases ===\n",
      "  1. regularly allowed to go out\n",
      "  2. to go out\n",
      "  3. go out\n",
      "  4. going out\n",
      "  5. to go outside\n",
      "----------------------------------------\n",
      "=== Cluster 325 | Size: 32 phrases ===\n",
      "  1. beating\n",
      "  2. beating up\n",
      "  3. beat it\n",
      "  4. for beating\n",
      "  5. for beating up\n",
      "----------------------------------------\n",
      "=== Cluster 26 | Size: 32 phrases ===\n",
      "  1. significant\n",
      "  2. is essential to\n",
      "  3. essential\n",
      "  4. essential to\n",
      "  5. crucial to\n",
      "----------------------------------------\n",
      "=== Cluster 231 | Size: 32 phrases ===\n",
      "  1. totally revolting\n",
      "  2. revolting\n",
      "  3. rebelling\n",
      "  4. in rebellion\n",
      "  5. rebels\n",
      "----------------------------------------\n",
      "=== Cluster 97 | Size: 32 phrases ===\n",
      "  1. injected into\n",
      "  2. infusing\n",
      "  3. infused\n",
      "  4. infusion\n",
      "  5. injects\n",
      "----------------------------------------\n",
      "=== Cluster 129 | Size: 32 phrases ===\n",
      "  1. hold\n",
      "  2. holding\n",
      "  3. holds\n",
      "  4. is holding\n",
      "  5. holding\n",
      "----------------------------------------\n",
      "=== Cluster 174 | Size: 32 phrases ===\n",
      "  1. running backwards\n",
      "  2. backfired\n",
      "  3. backfiring\n",
      "  4. backpedals\n",
      "  5. backsliding\n",
      "----------------------------------------\n",
      "=== Cluster 48 | Size: 31 phrases ===\n",
      "  1. suppressing every other\n",
      "  2. suppressing\n",
      "  3. suppresses\n",
      "  4. suppressing\n",
      "  5. initially suppressed\n",
      "----------------------------------------\n",
      "=== Cluster 349 | Size: 31 phrases ===\n",
      "  1. a problem\n",
      "  2. trouble over\n",
      "  3. cause trouble in\n",
      "  4. problems\n",
      "  5. to trouble\n",
      "----------------------------------------\n",
      "=== Cluster 54 | Size: 31 phrases ===\n",
      "  1. reviewing\n",
      "  2. reviewing\n",
      "  3. paper reviewed\n",
      "  4. on review\n",
      "  5. for review\n",
      "----------------------------------------\n",
      "=== Cluster 330 | Size: 31 phrases ===\n",
      "  1. aimless\n",
      "  2. aimlessly\n",
      "  3. careless\n",
      "  4. used heartlessly\n",
      "  5. totally heartless\n",
      "----------------------------------------\n",
      "=== Cluster 214 | Size: 31 phrases ===\n",
      "  1. to swallow\n",
      "  2. swallows up\n",
      "  3. chew\n",
      "  4. chewing\n",
      "  5. for chewing\n",
      "----------------------------------------\n",
      "=== Cluster 65 | Size: 31 phrases ===\n",
      "  1. unveiled\n",
      "  2. reveal\n",
      "  3. revealed\n",
      "  4. revealing\n",
      "  5. reveals\n",
      "----------------------------------------\n",
      "=== Cluster 94 | Size: 31 phrases ===\n",
      "  1. invading\n",
      "  2. penetrated by\n",
      "  3. invaded by\n",
      "  4. to invade\n",
      "  5. invade\n",
      "----------------------------------------\n",
      "=== Cluster 282 | Size: 30 phrases ===\n",
      "  1. being dropped in\n",
      "  2. to drop\n",
      "  3. in which one drops\n",
      "  4. having dropped\n",
      "  5. drops\n",
      "----------------------------------------\n",
      "=== Cluster 220 | Size: 30 phrases ===\n",
      "  1. exercise\n",
      "  2. exercised\n",
      "  3. may be worked out\n",
      "  4. needing exercise\n",
      "  5. to be exercised\n",
      "----------------------------------------\n",
      "=== Cluster 85 | Size: 30 phrases ===\n",
      "  1. in\n",
      "  2. in course of\n",
      "  3. in its\n",
      "  4. the year\n",
      "  5. in which\n",
      "----------------------------------------\n",
      "=== Cluster 158 | Size: 30 phrases ===\n",
      "  1. to retreat\n",
      "  2. somewhat when retreating\n",
      "  3. retreats\n",
      "  4. retreats somewhat\n",
      "  5. retreat\n",
      "----------------------------------------\n",
      "=== Cluster 160 | Size: 29 phrases ===\n",
      "  1. traversed\n",
      "  2. crossed\n",
      "  3. crossing borders\n",
      "  4. crossed by\n",
      "  5. crossed by\n",
      "----------------------------------------\n",
      "=== Cluster 322 | Size: 29 phrases ===\n",
      "  1. amazing\n",
      "  2. exceptional\n",
      "  3. extraordinary\n",
      "  4. fabulous\n",
      "  5. fantastic\n",
      "----------------------------------------\n",
      "=== Cluster 270 | Size: 29 phrases ===\n",
      "  1. regularly failed\n",
      "  2. after failing\n",
      "  3. failing\n",
      "  4. fail\n",
      "  5. failed\n",
      "----------------------------------------\n",
      "=== Cluster 316 | Size: 29 phrases ===\n",
      "  1. abuse of\n",
      "  2. abused\n",
      "  3. abusing\n",
      "  4. abuse\n",
      "  5. being abused\n",
      "----------------------------------------\n",
      "=== Cluster 351 | Size: 29 phrases ===\n",
      "  1. being incorrect\n",
      "  2. being wrong\n",
      "  3. got it wrong\n",
      "  4. in error\n",
      "  5. incorrectly delivered\n",
      "----------------------------------------\n",
      "=== Cluster 28 | Size: 29 phrases ===\n",
      "  1. contribute to\n",
      "  2. contributes to\n",
      "  3. contributing in\n",
      "  4. contribution from\n",
      "  5. contribution to\n",
      "----------------------------------------\n",
      "=== Cluster 340 | Size: 28 phrases ===\n",
      "  1. acting badly\n",
      "  2. badly cooked\n",
      "  3. badly produced\n",
      "  4. badly written\n",
      "  5. badly made\n",
      "----------------------------------------\n",
      "=== Cluster 284 | Size: 27 phrases ===\n",
      "  1. being fired\n",
      "  2. being sent off\n",
      "  3. fired\n",
      "  4. getting sacked\n",
      "  5. getting fired\n",
      "----------------------------------------\n",
      "=== Cluster 93 | Size: 27 phrases ===\n",
      "  1. adjust\n",
      "  2. adjusting\n",
      "  3. adjustments to\n",
      "  4. adjusts\n",
      "  5. adjustment\n",
      "----------------------------------------\n",
      "=== Cluster 24 | Size: 27 phrases ===\n",
      "  1. wash up\n",
      "  2. after a tidy up\n",
      "  3. cleaned up\n",
      "  4. clean bra\n",
      "  5. gets tidied\n",
      "----------------------------------------\n",
      "=== Cluster 248 | Size: 27 phrases ===\n",
      "  1. twist\n",
      "  2. twisting\n",
      "  3. after twisting\n",
      "  4. having been twisted\n",
      "  5. is twisted\n",
      "----------------------------------------\n",
      "=== Cluster 239 | Size: 27 phrases ===\n",
      "  1. built specially\n",
      "  2. designed for\n",
      "  3. designed to\n",
      "  4. is customised\n",
      "  5. made specially\n",
      "----------------------------------------\n",
      "=== Cluster 22 | Size: 27 phrases ===\n",
      "  1. collected\n",
      "  2. collecting\n",
      "  3. collection\n",
      "  4. collected\n",
      "  5. collects\n",
      "----------------------------------------\n",
      "=== Cluster 329 | Size: 27 phrases ===\n",
      "  1. crazy\n",
      "  2. gets crazy\n",
      "  3. going crazy\n",
      "  4. go crazy\n",
      "  5. is crazy\n",
      "----------------------------------------\n",
      "=== Cluster 196 | Size: 27 phrases ===\n",
      "  1. wraps\n",
      "  2. wrap\n",
      "  3. wrapper for\n",
      "  4. wraps\n",
      "  5. wraps up\n",
      "----------------------------------------\n",
      "=== Cluster 145 | Size: 27 phrases ===\n",
      "  1. sound of\n",
      "  2. sounds\n",
      "  3. sounds as if\n",
      "  4. makes sound of\n",
      "  5. sounds like him\n",
      "----------------------------------------\n",
      "=== Cluster 82 | Size: 26 phrases ===\n",
      "  1. extract from\n",
      "  2. extracted from\n",
      "  3. extraction of\n",
      "  4. extractable from\n",
      "  5. an extract from\n",
      "----------------------------------------\n",
      "=== Cluster 241 | Size: 26 phrases ===\n",
      "  1. after preparing\n",
      "  2. for preparation\n",
      "  3. for preparing\n",
      "  4. in preparation\n",
      "  5. preparation of\n",
      "----------------------------------------\n",
      "=== Cluster 1 | Size: 26 phrases ===\n",
      "  1. welcomed by\n",
      "  2. to welcome\n",
      "  3. welcoming\n",
      "  4. welcoming of\n",
      "  5. welcomed by\n",
      "----------------------------------------\n",
      "=== Cluster 227 | Size: 26 phrases ===\n",
      "  1. grasping\n",
      "  2. grabs\n",
      "  3. grasp\n",
      "  4. grasps\n",
      "  5. grips\n",
      "----------------------------------------\n",
      "=== Cluster 45 | Size: 25 phrases ===\n",
      "  1. can supply\n",
      "  2. could be provided by\n",
      "  3. could convey\n",
      "  4. could deliver\n",
      "  5. could hold the key\n",
      "----------------------------------------\n",
      "=== Cluster 23 | Size: 25 phrases ===\n",
      "  1. to be laid back\n",
      "  2. lying around\n",
      "  3. lying back\n",
      "  4. laid back\n",
      "  5. being laid back\n",
      "----------------------------------------\n",
      "=== Cluster 5 | Size: 25 phrases ===\n",
      "  1. upon retirement\n",
      "  2. to be retired\n",
      "  3. retirement\n",
      "  4. retirement of\n",
      "  5. retires\n",
      "----------------------------------------\n",
      "=== Cluster 343 | Size: 24 phrases ===\n",
      "  1. wrong way\n",
      "  2. wrong way up\n",
      "  3. up the wrong way\n",
      "  4. the wrong way\n",
      "  5. though facing the wrong way\n",
      "----------------------------------------\n",
      "=== Cluster 319 | Size: 24 phrases ===\n",
      "  1. in a tangle\n",
      "  2. in tangle\n",
      "  3. mangle\n",
      "  4. tangle\n",
      "  5. tangles\n",
      "----------------------------------------\n",
      "=== Cluster 195 | Size: 24 phrases ===\n",
      "  1. byzantine\n",
      "  2. besetting\n",
      "  3. besieged\n",
      "  4. beset\n",
      "  5. besieging\n",
      "----------------------------------------\n",
      "=== Cluster 293 | Size: 24 phrases ===\n",
      "  1. stuck in\n",
      "  2. stuck into\n",
      "  3. come unstuck\n",
      "  4. comes unstuck\n",
      "  5. getting stuck\n",
      "----------------------------------------\n",
      "=== Cluster 122 | Size: 23 phrases ===\n",
      "  1. alternative way\n",
      "  2. another\n",
      "  3. another way\n",
      "  4. another way round\n",
      "  5. one way and another\n",
      "----------------------------------------\n",
      "=== Cluster 216 | Size: 23 phrases ===\n",
      "  1. dance\n",
      "  2. dance about\n",
      "  3. danced\n",
      "  4. dances\n",
      "  5. dancing\n",
      "----------------------------------------\n",
      "=== Cluster 100 | Size: 23 phrases ===\n",
      "  1. being remodelled\n",
      "  2. being renovated\n",
      "  3. for renovation\n",
      "  4. getting renovated\n",
      "  5. refurbishing\n",
      "----------------------------------------\n",
      "=== Cluster 290 | Size: 23 phrases ===\n",
      "  1. spin\n",
      "  2. spinning\n",
      "  3. for a spin\n",
      "  4. in a spin\n",
      "  5. given a spin\n",
      "----------------------------------------\n",
      "=== Cluster 163 | Size: 23 phrases ===\n",
      "  1. brought out\n",
      "  2. brought about\n",
      "  3. brought\n",
      "  4. brought in\n",
      "  5. brought in by\n",
      "----------------------------------------\n",
      "=== Cluster 73 | Size: 23 phrases ===\n",
      "  1. found among\n",
      "  2. found back in\n",
      "  3. discovered in\n",
      "  4. found in jumble\n",
      "  5. found unexpectedly in\n",
      "----------------------------------------\n",
      "=== Cluster 294 | Size: 23 phrases ===\n",
      "  1. nicked\n",
      "  2. to nail\n",
      "  3. to nick\n",
      "  4. nicking\n",
      "  5. nicks\n",
      "----------------------------------------\n",
      "=== Cluster 112 | Size: 23 phrases ===\n",
      "  1. on the phone\n",
      "  2. over the phone\n",
      "  3. call\n",
      "  4. called\n",
      "  5. called for\n",
      "----------------------------------------\n",
      "=== Cluster 117 | Size: 23 phrases ===\n",
      "  1. acquiring safe\n",
      "  2. acquiring\n",
      "  3. when acquiring\n",
      "  4. upon acquiring\n",
      "  5. to purchase\n",
      "----------------------------------------\n",
      "=== Cluster 121 | Size: 23 phrases ===\n",
      "  1. reported\n",
      "  2. reporting\n",
      "  3. is reported\n",
      "  4. getting reported\n",
      "  5. for report\n",
      "----------------------------------------\n",
      "=== Cluster 140 | Size: 23 phrases ===\n",
      "  1. talked about\n",
      "  2. in discussion\n",
      "  3. in discussions\n",
      "  4. is discussed\n",
      "  5. to discuss\n",
      "----------------------------------------\n",
      "=== Cluster 335 | Size: 22 phrases ===\n",
      "  1. are suffering\n",
      "  2. is suffering\n",
      "  3. might suffer\n",
      "  4. must suffer\n",
      "  5. suffer\n",
      "----------------------------------------\n",
      "=== Cluster 4 | Size: 22 phrases ===\n",
      "  1. absorbing time\n",
      "  2. absorbs\n",
      "  3. absorbed by\n",
      "  4. absorbed in\n",
      "  5. absorbs\n",
      "----------------------------------------\n",
      "=== Cluster 252 | Size: 22 phrases ===\n",
      "  1. blows\n",
      "  2. blowing\n",
      "  3. blowing up\n",
      "  4. blown\n",
      "  5. blown up\n",
      "----------------------------------------\n",
      "=== Cluster 105 | Size: 22 phrases ===\n",
      "  1. appearing in\n",
      "  2. appears in\n",
      "  3. makes appearance in\n",
      "  4. featured in\n",
      "  5. appearing in\n",
      "----------------------------------------\n",
      "=== Cluster 60 | Size: 22 phrases ===\n",
      "  1. described\n",
      "  2. describes\n",
      "  3. described\n",
      "  4. describes\n",
      "  5. when describing\n",
      "----------------------------------------\n",
      "=== Cluster 311 | Size: 22 phrases ===\n",
      "  1. when touring\n",
      "  2. tour\n",
      "  3. toured\n",
      "  4. touring\n",
      "  5. when touring\n",
      "----------------------------------------\n",
      "=== Cluster 226 | Size: 22 phrases ===\n",
      "  1. seized by\n",
      "  2. confiscated by\n",
      "  3. seized\n",
      "  4. has seized\n",
      "  5. seized\n",
      "----------------------------------------\n",
      "=== Cluster 177 | Size: 22 phrases ===\n",
      "  1. lifted from\n",
      "  2. needing lift\n",
      "  3. lifts\n",
      "  4. lifting\n",
      "  5. lift\n",
      "----------------------------------------\n",
      "=== Cluster 123 | Size: 21 phrases ===\n",
      "  1. are different\n",
      "  2. but different\n",
      "  3. completely different\n",
      "  4. different\n",
      "  5. differently composed\n",
      "----------------------------------------\n",
      "=== Cluster 298 | Size: 21 phrases ===\n",
      "  1. after flying\n",
      "  2. after flying around\n",
      "  3. flying\n",
      "  4. flying around\n",
      "  5. having flown\n",
      "----------------------------------------\n",
      "=== Cluster 198 | Size: 21 phrases ===\n",
      "  1. shouted\n",
      "  2. shouting\n",
      "  3. moaning\n",
      "  4. cry of\n",
      "  5. crying\n",
      "----------------------------------------\n",
      "=== Cluster 152 | Size: 21 phrases ===\n",
      "  1. retrospective focusing\n",
      "  2. retrospect\n",
      "  3. retrospectively\n",
      "  4. reading back\n",
      "  5. looking back\n",
      "----------------------------------------\n",
      "=== Cluster 237 | Size: 21 phrases ===\n",
      "  1. chopped\n",
      "  2. chopped up\n",
      "  3. chopping\n",
      "  4. choppy\n",
      "  5. chops\n",
      "----------------------------------------\n",
      "=== Cluster 106 | Size: 21 phrases ===\n",
      "  1. packs\n",
      "  2. would pack\n",
      "  3. to pack\n",
      "  4. to package\n",
      "  5. packaging\n",
      "----------------------------------------\n",
      "=== Cluster 136 | Size: 21 phrases ===\n",
      "  1. a slice of\n",
      "  2. piece\n",
      "  3. piece of\n",
      "  4. piece out of\n",
      "  5. chunk\n",
      "----------------------------------------\n",
      "=== Cluster 180 | Size: 21 phrases ===\n",
      "  1. reducing\n",
      "  2. reduced\n",
      "  3. reduced\n",
      "  4. reduced by\n",
      "  5. reduction\n",
      "----------------------------------------\n",
      "=== Cluster 230 | Size: 21 phrases ===\n",
      "  1. arrested\n",
      "  2. arrested by\n",
      "  3. arrested in\n",
      "  4. arresting\n",
      "  5. arresting\n",
      "----------------------------------------\n",
      "=== Cluster 59 | Size: 20 phrases ===\n",
      "  1. for revision\n",
      "  2. having revised\n",
      "  3. is revised\n",
      "  4. revision of\n",
      "  5. revised\n",
      "----------------------------------------\n",
      "=== Cluster 297 | Size: 20 phrases ===\n",
      "  1. battling\n",
      "  2. battle\n",
      "  3. battles\n",
      "  4. characters fighting\n",
      "  5. fighting\n",
      "----------------------------------------\n",
      "=== Cluster 261 | Size: 20 phrases ===\n",
      "  1. being dissolute\n",
      "  2. decomposing\n",
      "  3. disintegrated\n",
      "  4. disintegrating\n",
      "  5. disintegration\n",
      "----------------------------------------\n",
      "=== Cluster 67 | Size: 20 phrases ===\n",
      "  1. for translation\n",
      "  2. gets translated\n",
      "  3. has been translated\n",
      "  4. in translation\n",
      "  5. needing translation\n",
      "----------------------------------------\n",
      "=== Cluster 86 | Size: 20 phrases ===\n",
      "  1. held in\n",
      "  2. held in during\n",
      "  3. held\n",
      "  4. held during\n",
      "  5. held\n",
      "----------------------------------------\n",
      "=== Cluster 309 | Size: 20 phrases ===\n",
      "  1. pinching\n",
      "  2. has pinched\n",
      "  3. to pinch\n",
      "  4. pinched\n",
      "  5. pinches\n",
      "----------------------------------------\n",
      "=== Cluster 224 | Size: 20 phrases ===\n",
      "  1. a prisoner of\n",
      "  2. being imprisoned\n",
      "  3. imprisoned\n",
      "  4. imprisoned\n",
      "  5. imprisoning\n",
      "----------------------------------------\n",
      "=== Cluster 62 | Size: 19 phrases ===\n",
      "  1. characters\n",
      "  2. characters from\n",
      "  3. characters in\n",
      "  4. characters involved\n",
      "  5. characters of\n",
      "----------------------------------------\n",
      "=== Cluster 287 | Size: 19 phrases ===\n",
      "  1. go off\n",
      "  2. goes off\n",
      "  3. going off\n",
      "  4. seeing off\n",
      "  5. head off\n",
      "----------------------------------------\n",
      "=== Cluster 257 | Size: 19 phrases ===\n",
      "  1. after crashing\n",
      "  2. crash\n",
      "  3. crashed\n",
      "  4. crashing\n",
      "  5. having crashed\n",
      "----------------------------------------\n",
      "=== Cluster 249 | Size: 19 phrases ===\n",
      "  1. by storm\n",
      "  2. hurricane\n",
      "  3. in a storm\n",
      "  4. in storm\n",
      "  5. storm\n",
      "----------------------------------------\n",
      "=== Cluster 310 | Size: 19 phrases ===\n",
      "  1. after travelling\n",
      "  2. gone travelling\n",
      "  3. involves travelling\n",
      "  4. travelling across\n",
      "  5. travelling in\n",
      "----------------------------------------\n",
      "=== Cluster 285 | Size: 19 phrases ===\n",
      "  1. away with the fairies\n",
      "  2. out of\n",
      "  3. out by\n",
      "  4. out of\n",
      "  5. out with\n",
      "----------------------------------------\n",
      "=== Cluster 57 | Size: 19 phrases ===\n",
      "  1. being fixed\n",
      "  2. caused by fixing\n",
      "  3. fix\n",
      "  4. for fixing\n",
      "  5. fixup\n",
      "----------------------------------------\n",
      "=== Cluster 345 | Size: 19 phrases ===\n",
      "  1. gets worried about\n",
      "  2. getting worried\n",
      "  3. if worried\n",
      "  4. is worried\n",
      "  5. must be worried\n",
      "----------------------------------------\n",
      "=== Cluster 295 | Size: 19 phrases ===\n",
      "  1. knitted\n",
      "  2. get knotted\n",
      "  3. in a knot\n",
      "  4. knot\n",
      "  5. knots\n",
      "----------------------------------------\n",
      "=== Cluster 19 | Size: 19 phrases ===\n",
      "  1. stuffed\n",
      "  2. stuffing\n",
      "  3. stuffed with\n",
      "  4. stuffing\n",
      "  5. stuffed\n",
      "----------------------------------------\n",
      "=== Cluster 292 | Size: 19 phrases ===\n",
      "  1. trapped by\n",
      "  2. trapped in\n",
      "  3. and almost trapped\n",
      "  4. being trapped in\n",
      "  5. trapped in\n",
      "----------------------------------------\n",
      "=== Cluster 125 | Size: 19 phrases ===\n",
      "  1. proclamation\n",
      "  2. to be announced\n",
      "  3. for announcement\n",
      "  4. declares\n",
      "  5. being announced\n",
      "----------------------------------------\n",
      "=== Cluster 151 | Size: 19 phrases ===\n",
      "  1. viewed from behind\n",
      "  2. view from rear\n",
      "  3. seen from the rear\n",
      "  4. seen from behind\n",
      "  5. rear\n",
      "----------------------------------------\n",
      "=== Cluster 47 | Size: 18 phrases ===\n",
      "  1. blocked\n",
      "  2. blocking\n",
      "  3. blocks\n",
      "  4. blocked\n",
      "  5. blocking out\n",
      "----------------------------------------\n",
      "=== Cluster 243 | Size: 18 phrases ===\n",
      "  1. a sort\n",
      "  2. for sorting out\n",
      "  3. get sorted out\n",
      "  4. sorting out\n",
      "  5. sort of\n",
      "----------------------------------------\n",
      "=== Cluster 49 | Size: 18 phrases ===\n",
      "  1. administration\n",
      "  2. control\n",
      "  3. controls\n",
      "  4. for control\n",
      "  5. managing\n",
      "----------------------------------------\n",
      "=== Cluster 53 | Size: 18 phrases ===\n",
      "  1. being solved\n",
      "  2. for resolution\n",
      "  3. for solving\n",
      "  4. resolution\n",
      "  5. resolution of\n",
      "----------------------------------------\n",
      "=== Cluster 233 | Size: 18 phrases ===\n",
      "  1. fitted\n",
      "  2. fit of\n",
      "  3. fitfully\n",
      "  4. fitted\n",
      "  5. to fit\n",
      "----------------------------------------\n",
      "=== Cluster 71 | Size: 18 phrases ===\n",
      "  1. probing\n",
      "  2. when probed by\n",
      "  3. probed by\n",
      "  4. probing\n",
      "  5. to probe\n",
      "----------------------------------------\n",
      "=== Cluster 259 | Size: 18 phrases ===\n",
      "  1. being smeared\n",
      "  2. smeared\n",
      "  3. smothering\n",
      "  4. smothers\n",
      "  5. smear\n",
      "----------------------------------------\n",
      "=== Cluster 305 | Size: 18 phrases ===\n",
      "  1. jockey\n",
      "  2. jockeys\n",
      "  3. jerks\n",
      "  4. junked\n",
      "  5. jerk\n",
      "----------------------------------------\n",
      "=== Cluster 0 | Size: 18 phrases ===\n",
      "  1. buried in\n",
      "  2. and buried in\n",
      "  3. interred in\n",
      "  4. buried\n",
      "  5. buried among\n",
      "----------------------------------------\n",
      "=== Cluster 34 | Size: 18 phrases ===\n",
      "  1. nurses\n",
      "  2. nurtures\n",
      "  3. geriatric\n",
      "  4. will nurture\n",
      "  5. to nurse\n",
      "----------------------------------------\n",
      "=== Cluster 320 | Size: 18 phrases ===\n",
      "  1. crack\n",
      "  2. cracking\n",
      "  3. cracked\n",
      "  4. cracking\n",
      "  5. cracks open\n",
      "----------------------------------------\n",
      "=== Cluster 301 | Size: 18 phrases ===\n",
      "  1. to flip\n",
      "  2. flipping\n",
      "  3. flipping out\n",
      "  4. having flipped\n",
      "  5. flipping over\n",
      "----------------------------------------\n",
      "=== Cluster 208 | Size: 18 phrases ===\n",
      "  1. gets stir\n",
      "  2. in stir\n",
      "  3. needs stirring\n",
      "  4. requiring stirring\n",
      "  5. stir\n",
      "----------------------------------------\n",
      "=== Cluster 313 | Size: 18 phrases ===\n",
      "  1. wandering round\n",
      "  2. may wander\n",
      "  3. meandered\n",
      "  4. meandering\n",
      "  5. sauntering\n",
      "----------------------------------------\n",
      "=== Cluster 32 | Size: 18 phrases ===\n",
      "  1. will hide\n",
      "  2. somewhat hidden\n",
      "  3. secret\n",
      "  4. secreted\n",
      "  5. partly hides\n",
      "----------------------------------------\n",
      "=== Cluster 182 | Size: 18 phrases ===\n",
      "  1. to find cover in\n",
      "  2. cover for\n",
      "  3. cover\n",
      "  4. covers\n",
      "  5. for the cover\n",
      "----------------------------------------\n",
      "=== Cluster 190 | Size: 18 phrases ===\n",
      "  1. refuge\n",
      "  2. given refuge\n",
      "  3. sheltering\n",
      "  4. provides shelter for\n",
      "  5. providing shelter for\n",
      "----------------------------------------\n",
      "=== Cluster 52 | Size: 18 phrases ===\n",
      "  1. restricted\n",
      "  2. constrained by\n",
      "  3. constrained by\n",
      "  4. restricted\n",
      "  5. limited\n",
      "----------------------------------------\n",
      "=== Cluster 81 | Size: 18 phrases ===\n",
      "  1. being introduced to\n",
      "  2. introduced by\n",
      "  3. introduced into\n",
      "  4. introduces\n",
      "  5. introducing\n",
      "----------------------------------------\n",
      "=== Cluster 11 | Size: 18 phrases ===\n",
      "  1. invested\n",
      "  2. when invested in\n",
      "  3. when investing in\n",
      "  4. invested\n",
      "  5. to invest in\n",
      "----------------------------------------\n",
      "=== Cluster 245 | Size: 18 phrases ===\n",
      "  1. undergoing withdrawal\n",
      "  2. to withdraw\n",
      "  3. withdrawals\n",
      "  4. can withdraw\n",
      "  5. withdraw\n",
      "----------------------------------------\n",
      "=== Cluster 40 | Size: 18 phrases ===\n",
      "  1. when held back\n",
      "  2. hold back\n",
      "  3. holding back\n",
      "  4. hold it back\n",
      "  5. holding back\n",
      "----------------------------------------\n",
      "=== Cluster 171 | Size: 18 phrases ===\n",
      "  1. staging a comeback\n",
      "  2. on the comeback\n",
      "  3. making a comeback\n",
      "  4. making a comeback in\n",
      "  5. making comeback\n",
      "----------------------------------------\n",
      "=== Cluster 80 | Size: 17 phrases ===\n",
      "  1. about\n",
      "  2. about\n",
      "  3. about one\n",
      "  4. pub about\n",
      "  5. about\n",
      "----------------------------------------\n",
      "=== Cluster 348 | Size: 17 phrases ===\n",
      "  1. being disturbed\n",
      "  2. characters being disturbed\n",
      "  3. disturbs\n",
      "  4. disturbance\n",
      "  5. disturbed\n",
      "----------------------------------------\n",
      "=== Cluster 183 | Size: 17 phrases ===\n",
      "  1. after shaking\n",
      "  2. is shaken\n",
      "  3. shake\n",
      "  4. shaken\n",
      "  5. shaken all about\n",
      "----------------------------------------\n",
      "=== Cluster 346 | Size: 17 phrases ===\n",
      "  1. agitating\n",
      "  2. agitated\n",
      "  3. agitates\n",
      "  4. becoming agitated\n",
      "  5. getting agitated\n",
      "----------------------------------------\n",
      "=== Cluster 326 | Size: 17 phrases ===\n",
      "  1. assassinated\n",
      "  2. assassination of\n",
      "  3. being punished\n",
      "  4. killing\n",
      "  5. beheaded\n",
      "----------------------------------------\n",
      "=== Cluster 179 | Size: 17 phrases ===\n",
      "  1. getting out of shape\n",
      "  2. is out of sorts\n",
      "  3. out of character\n",
      "  4. out of place\n",
      "  5. out of position\n",
      "----------------------------------------\n",
      "=== Cluster 304 | Size: 17 phrases ===\n",
      "  1. circulate\n",
      "  2. circulated\n",
      "  3. circulating\n",
      "  4. for circulation\n",
      "  5. getting circulation\n",
      "----------------------------------------\n",
      "=== Cluster 347 | Size: 17 phrases ===\n",
      "  1. fake\n",
      "  2. falsely\n",
      "  3. falsely posing as\n",
      "  4. falsified\n",
      "  5. falsifying\n",
      "----------------------------------------\n",
      "=== Cluster 164 | Size: 17 phrases ===\n",
      "  1. sending up old husband and wife\n",
      "  2. sent skyward\n",
      "  3. get sent out\n",
      "  4. getting sent up\n",
      "  5. being sent up\n",
      "----------------------------------------\n",
      "=== Cluster 203 | Size: 17 phrases ===\n",
      "  1. excitement to\n",
      "  2. excited\n",
      "  3. excitedly\n",
      "  4. excitement\n",
      "  5. for excitement\n",
      "----------------------------------------\n",
      "=== Cluster 114 | Size: 17 phrases ===\n",
      "  1. of the audience\n",
      "  2. to audience\n",
      "  3. in auditorium\n",
      "  4. in the auditorium\n",
      "  5. in the audience\n",
      "----------------------------------------\n",
      "=== Cluster 296 | Size: 17 phrases ===\n",
      "  1. tipped\n",
      "  2. tipped over\n",
      "  3. tipping\n",
      "  4. tips\n",
      "  5. guide\n",
      "----------------------------------------\n",
      "=== Cluster 167 | Size: 17 phrases ===\n",
      "  1. overly\n",
      "  2. overflowing\n",
      "  3. overcome\n",
      "  4. overcoming\n",
      "  5. overtaking\n",
      "----------------------------------------\n",
      "=== Cluster 149 | Size: 17 phrases ===\n",
      "  1. upon reflection\n",
      "  2. to reflect\n",
      "  3. reflected\n",
      "  4. reflecting\n",
      "  5. reflection\n",
      "----------------------------------------\n",
      "=== Cluster 314 | Size: 17 phrases ===\n",
      "  1. to show round\n",
      "  2. to go round\n",
      "  3. to get round\n",
      "  4. to get round\n",
      "  5. to go round\n",
      "----------------------------------------\n",
      "=== Cluster 12 | Size: 17 phrases ===\n",
      "  1. accommodate\n",
      "  2. accommodated\n",
      "  3. accommodating\n",
      "  4. accommodates\n",
      "  5. accommodating\n",
      "----------------------------------------\n",
      "=== Cluster 61 | Size: 17 phrases ===\n",
      "  1. among\n",
      "  2. between\n",
      "  3. from junction between\n",
      "  4. amongst\n",
      "  5. between\n",
      "----------------------------------------\n",
      "=== Cluster 205 | Size: 17 phrases ===\n",
      "  1. entertained by\n",
      "  2. entertained by\n",
      "  3. entertained\n",
      "  4. is entertaining\n",
      "  5. to entertain\n",
      "----------------------------------------\n",
      "=== Cluster 16 | Size: 17 phrases ===\n",
      "  1. contain\n",
      "  2. containing\n",
      "  3. contained\n",
      "  4. contained within\n",
      "  5. containing\n",
      "----------------------------------------\n",
      "=== Cluster 27 | Size: 17 phrases ===\n",
      "  1. supports\n",
      "  2. needing backing\n",
      "  3. having backed\n",
      "  4. having backing\n",
      "  5. given backing\n",
      "----------------------------------------\n",
      "=== Cluster 10 | Size: 17 phrases ===\n",
      "  1. tucked into\n",
      "  2. tucking into\n",
      "  3. tucking in\n",
      "  4. tucking in\n",
      "  5. tucking into\n",
      "----------------------------------------\n",
      "=== Cluster 147 | Size: 17 phrases ===\n",
      "  1. on the ear\n",
      "  2. through the earpiece\n",
      "  3. in the ear\n",
      "  4. in the ears\n",
      "  5. in your ear\n",
      "----------------------------------------\n",
      "=== Cluster 211 | Size: 16 phrases ===\n",
      "  1. acting\n",
      "  2. after performing\n",
      "  3. after performance\n",
      "  4. is performing\n",
      "  5. perform\n",
      "----------------------------------------\n",
      "=== Cluster 263 | Size: 16 phrases ===\n",
      "  1. after swimming\n",
      "  2. swaddling\n",
      "  3. paddling\n",
      "  4. splashing\n",
      "  5. splashing it around\n",
      "----------------------------------------\n",
      "=== Cluster 144 | Size: 16 phrases ===\n",
      "  1. agricultural\n",
      "  2. cultivated in\n",
      "  3. cultivating\n",
      "  4. cultivate\n",
      "  5. cultivated\n",
      "----------------------------------------\n",
      "=== Cluster 69 | Size: 16 phrases ===\n",
      "  1. all round\n",
      "  2. all over\n",
      "  3. by all accounts\n",
      "  4. all round\n",
      "  5. all over\n",
      "----------------------------------------\n",
      "=== Cluster 83 | Size: 16 phrases ===\n",
      "  1. make case\n",
      "  2. evidence in case\n",
      "  3. case\n",
      "  4. cases\n",
      "  5. case\n",
      "----------------------------------------\n",
      "=== Cluster 70 | Size: 16 phrases ===\n",
      "  1. being about\n",
      "  2. being\n",
      "  3. being rum\n",
      "  4. being among\n",
      "  5. being\n",
      "----------------------------------------\n",
      "=== Cluster 318 | Size: 16 phrases ===\n",
      "  1. being nasty\n",
      "  2. being naughty\n",
      "  3. getting nasty\n",
      "  4. got nasty\n",
      "  5. may get nasty\n",
      "----------------------------------------\n",
      "=== Cluster 202 | Size: 16 phrases ===\n",
      "  1. could excite\n",
      "  2. excite\n",
      "  3. ignited\n",
      "  4. provoked\n",
      "  5. stimulating\n",
      "----------------------------------------\n",
      "=== Cluster 328 | Size: 16 phrases ===\n",
      "  1. stridently\n",
      "  2. frantic\n",
      "  3. frantically\n",
      "  4. frenzy\n",
      "  5. frenetic\n",
      "----------------------------------------\n",
      "=== Cluster 232 | Size: 16 phrases ===\n",
      "  1. revolutionised\n",
      "  2. in revolution\n",
      "  3. in revolution\n",
      "  4. being revolutionary\n",
      "  5. revolutionary\n",
      "----------------------------------------\n",
      "=== Cluster 150 | Size: 16 phrases ===\n",
      "  1. to overturn\n",
      "  2. overturn\n",
      "  3. overturning\n",
      "  4. is overturned\n",
      "  5. having overturned\n",
      "----------------------------------------\n",
      "=== Cluster 120 | Size: 16 phrases ===\n",
      "  1. rumour of\n",
      "  2. rumoured\n",
      "  3. rumour\n",
      "  4. rumour has it\n",
      "  5. purportedly\n",
      "----------------------------------------\n",
      "=== Cluster 206 | Size: 16 phrases ===\n",
      "  1. needing wind\n",
      "  2. winding\n",
      "  3. winding in and out\n",
      "  4. winding up\n",
      "  5. winds\n",
      "----------------------------------------\n",
      "=== Cluster 7 | Size: 16 phrases ===\n",
      "  1. being full of\n",
      "  2. full of\n",
      "  3. filled with\n",
      "  4. is full of\n",
      "  5. full of\n",
      "----------------------------------------\n",
      "=== Cluster 9 | Size: 16 phrases ===\n",
      "  1. hosts\n",
      "  2. hosting\n",
      "  3. when hosting\n",
      "  4. to host\n",
      "  5. hosted by\n",
      "----------------------------------------\n",
      "=== Cluster 14 | Size: 16 phrases ===\n",
      "  1. content\n",
      "  2. content here\n",
      "  3. content to\n",
      "  4. contents\n",
      "  5. content of\n",
      "----------------------------------------\n",
      "=== Cluster 141 | Size: 16 phrases ===\n",
      "  1. a portion of\n",
      "  2. portion of\n",
      "  3. part of it\n",
      "  4. part thereof\n",
      "  5. part of\n",
      "----------------------------------------\n",
      "=== Cluster 79 | Size: 15 phrases ===\n",
      "  1. being reformed\n",
      "  2. for reform\n",
      "  3. get reformed\n",
      "  4. having reformed\n",
      "  5. reform\n",
      "----------------------------------------\n",
      "=== Cluster 212 | Size: 15 phrases ===\n",
      "  1. bottled in\n",
      "  2. bottles\n",
      "  3. bottling\n",
      "  4. bottled\n",
      "  5. bottled up\n",
      "----------------------------------------\n",
      "=== Cluster 3 | Size: 15 phrases ===\n",
      "  1. breaking open\n",
      "  2. breaking open\n",
      "  3. open\n",
      "  4. open out\n",
      "  5. open to\n",
      "----------------------------------------\n",
      "=== Cluster 137 | Size: 15 phrases ===\n",
      "  1. a quantity of\n",
      "  2. quantity of\n",
      "  3. amount of\n",
      "  4. measure of\n",
      "  5. much\n",
      "----------------------------------------\n",
      "=== Cluster 165 | Size: 15 phrases ===\n",
      "  1. came round\n",
      "  2. come round\n",
      "  3. comes round\n",
      "  4. coming round\n",
      "  5. comes round\n",
      "----------------------------------------\n",
      "=== Cluster 250 | Size: 15 phrases ===\n",
      "  1. jumps\n",
      "  2. leaping\n",
      "  3. jumping out\n",
      "  4. jump\n",
      "  5. jumps\n",
      "----------------------------------------\n",
      "=== Cluster 39 | Size: 15 phrases ===\n",
      "  1. to comprehend\n",
      "  2. comprehended\n",
      "  3. comprehending\n",
      "  4. comprehended by\n",
      "  5. comprehended by\n",
      "----------------------------------------\n",
      "=== Cluster 178 | Size: 15 phrases ===\n",
      "  1. popping up\n",
      "  2. popped\n",
      "  3. popping\n",
      "  4. poop\n",
      "  5. pop\n",
      "----------------------------------------\n",
      "=== Cluster 43 | Size: 15 phrases ===\n",
      "  1. for replacement\n",
      "  2. in replacement\n",
      "  3. on replacement\n",
      "  4. replaced\n",
      "  5. replacement\n",
      "----------------------------------------\n",
      "=== Cluster 188 | Size: 15 phrases ===\n",
      "  1. settled\n",
      "  2. getting settled\n",
      "  3. is settled\n",
      "  4. settling\n",
      "  5. settled\n",
      "----------------------------------------\n",
      "=== Cluster 159 | Size: 15 phrases ===\n",
      "  1. turning over\n",
      "  2. turn it over\n",
      "  3. turn over\n",
      "  4. turned over\n",
      "  5. having turned over\n",
      "----------------------------------------\n",
      "=== Cluster 119 | Size: 15 phrases ===\n",
      "  1. received\n",
      "  2. receiving\n",
      "  3. when receiving\n",
      "  4. when received by\n",
      "  5. received\n",
      "----------------------------------------\n",
      "=== Cluster 8 | Size: 15 phrases ===\n",
      "  1. to fill\n",
      "  2. filling\n",
      "  3. filling for\n",
      "  4. fill in\n",
      "  5. filling\n",
      "----------------------------------------\n",
      "=== Cluster 280 | Size: 14 phrases ===\n",
      "  1. after abandonment\n",
      "  2. abandon\n",
      "  3. abandoned\n",
      "  4. abandonment of\n",
      "  5. being abandoned\n",
      "----------------------------------------\n",
      "=== Cluster 256 | Size: 14 phrases ===\n",
      "  1. hurt\n",
      "  2. if injured\n",
      "  3. injured\n",
      "  4. injury\n",
      "  5. to be injured\n",
      "----------------------------------------\n",
      "=== Cluster 56 | Size: 14 phrases ===\n",
      "  1. being recycled\n",
      "  2. can be recycled\n",
      "  3. for recycling\n",
      "  4. getting recycled\n",
      "  5. recirculated\n",
      "----------------------------------------\n",
      "=== Cluster 336 | Size: 14 phrases ===\n",
      "  1. being silly\n",
      "  2. being stupid\n",
      "  3. stupid to climb\n",
      "  4. foolishly\n",
      "  5. fools\n",
      "----------------------------------------\n",
      "=== Cluster 247 | Size: 14 phrases ===\n",
      "  1. being squandered\n",
      "  2. wasting\n",
      "  3. to waste\n",
      "  4. is wasted\n",
      "  5. squandering\n",
      "----------------------------------------\n",
      "=== Cluster 169 | Size: 14 phrases ===\n",
      "  1. being wild\n",
      "  2. characters going wild\n",
      "  3. goes wild\n",
      "  4. go wild\n",
      "  5. going wild\n",
      "----------------------------------------\n",
      "=== Cluster 31 | Size: 14 phrases ===\n",
      "  1. concealed\n",
      "  2. concealed\n",
      "  3. concealed by\n",
      "  4. concealed\n",
      "  5. concealed by\n",
      "----------------------------------------\n",
      "=== Cluster 168 | Size: 14 phrases ===\n",
      "  1. coming from\n",
      "  2. comes from\n",
      "  3. comes from this\n",
      "  4. comes out of\n",
      "  5. coming out of\n",
      "----------------------------------------\n",
      "=== Cluster 286 | Size: 14 phrases ===\n",
      "  1. departs\n",
      "  2. pass up\n",
      "  3. to leave\n",
      "  4. queen leaving\n",
      "  5. leave\n",
      "----------------------------------------\n",
      "=== Cluster 30 | Size: 14 phrases ===\n",
      "  1. disguised\n",
      "  2. disguising\n",
      "  3. disguise\n",
      "  4. disguise\n",
      "  5. disguised\n",
      "----------------------------------------\n",
      "=== Cluster 323 | Size: 14 phrases ===\n",
      "  1. gets smashed\n",
      "  2. smashed\n",
      "  3. in smash\n",
      "  4. smash\n",
      "  5. smashed\n",
      "----------------------------------------\n",
      "=== Cluster 275 | Size: 14 phrases ===\n",
      "  1. and interrupting\n",
      "  2. interrupts\n",
      "  3. interruptus\n",
      "  4. irrupts\n",
      "  5. to interrupt\n",
      "----------------------------------------\n",
      "=== Cluster 289 | Size: 14 phrases ===\n",
      "  1. sung\n",
      "  2. rings\n",
      "  3. rink\n",
      "  4. rack\n",
      "  5. reels\n",
      "----------------------------------------\n",
      "=== Cluster 302 | Size: 14 phrases ===\n",
      "  1. round\n",
      "  2. round of\n",
      "  3. roundly\n",
      "  4. round\n",
      "  5. rounding\n",
      "----------------------------------------\n",
      "=== Cluster 72 | Size: 14 phrases ===\n",
      "  1. checked by\n",
      "  2. checks\n",
      "  3. checking\n",
      "  4. checks\n",
      "  5. to check\n",
      "----------------------------------------\n",
      "=== Cluster 181 | Size: 14 phrases ===\n",
      "  1. covered in\n",
      "  2. covered\n",
      "  3. covered by\n",
      "  4. covered\n",
      "  5. covered by\n",
      "----------------------------------------\n",
      "=== Cluster 281 | Size: 14 phrases ===\n",
      "  1. locked\n",
      "  2. locking up\n",
      "  3. locked in\n",
      "  4. locked up\n",
      "  5. locked up\n",
      "----------------------------------------\n",
      "=== Cluster 41 | Size: 14 phrases ===\n",
      "  1. will stop\n",
      "  2. to stop\n",
      "  3. stops\n",
      "  4. to stop\n",
      "  5. to stop in\n",
      "----------------------------------------\n",
      "=== Cluster 134 | Size: 13 phrases ===\n",
      "  1. taking only part\n",
      "  2. only five of them\n",
      "  3. only part\n",
      "  4. only partly\n",
      "  5. but only to a limited extent\n",
      "----------------------------------------\n",
      "=== Cluster 78 | Size: 13 phrases ===\n",
      "  1. for facelift\n",
      "  2. gets makeover\n",
      "  3. getting a makeover\n",
      "  4. given makeover\n",
      "  5. given a makeover\n",
      "----------------------------------------\n",
      "=== Cluster 75 | Size: 13 phrases ===\n",
      "  1. after adjustment\n",
      "  2. after alteration\n",
      "  3. after change\n",
      "  4. after changes\n",
      "  5. after changing\n",
      "----------------------------------------\n",
      "=== Cluster 300 | Size: 13 phrases ===\n",
      "  1. all in a flutter\n",
      "  2. flashing\n",
      "  3. flaunting\n",
      "  4. flickering\n",
      "  5. flicks\n",
      "----------------------------------------\n",
      "=== Cluster 274 | Size: 13 phrases ===\n",
      "  1. being disruptive\n",
      "  2. disruptive\n",
      "  3. disrupts\n",
      "  4. disrupting\n",
      "  5. disruption\n",
      "----------------------------------------\n",
      "=== Cluster 201 | Size: 13 phrases ===\n",
      "  1. being funny\n",
      "  2. comedy of\n",
      "  3. comic\n",
      "  4. comical\n",
      "  5. comically\n",
      "----------------------------------------\n",
      "=== Cluster 58 | Size: 13 phrases ===\n",
      "  1. being repaired\n",
      "  2. for repair\n",
      "  3. getting repaired\n",
      "  4. repair\n",
      "  5. repaired\n",
      "----------------------------------------\n",
      "=== Cluster 264 | Size: 13 phrases ===\n",
      "  1. getting spilt\n",
      "  2. spills\n",
      "  3. spill\n",
      "  4. spill affecting\n",
      "  5. spill of\n",
      "----------------------------------------\n",
      "=== Cluster 173 | Size: 13 phrases ===\n",
      "  1. contrarily\n",
      "  2. contrary\n",
      "  3. providing contrary view\n",
      "  4. on the contrary\n",
      "  5. contrary\n",
      "----------------------------------------\n",
      "=== Cluster 126 | Size: 13 phrases ===\n",
      "  1. delivered\n",
      "  2. delivery\n",
      "  3. delivery of\n",
      "  4. when delivered\n",
      "  5. delivered\n",
      "----------------------------------------\n",
      "=== Cluster 74 | Size: 13 phrases ===\n",
      "  1. find\n",
      "  2. found\n",
      "  3. discovering\n",
      "  4. discovered\n",
      "  5. find\n",
      "----------------------------------------\n",
      "=== Cluster 33 | Size: 13 phrases ===\n",
      "  1. hiding\n",
      "  2. hiding in\n",
      "  3. hiding\n",
      "  4. hiding\n",
      "  5. hiding in\n",
      "----------------------------------------\n",
      "=== Cluster 107 | Size: 13 phrases ===\n",
      "  1. loads\n",
      "  2. charging\n",
      "  3. loading up\n",
      "  4. loads go up\n",
      "  5. loaded\n",
      "----------------------------------------\n",
      "=== Cluster 18 | Size: 13 phrases ===\n",
      "  1. to switch\n",
      "  2. switch\n",
      "  3. switched\n",
      "  4. switches\n",
      "  5. switch\n",
      "----------------------------------------\n",
      "=== Cluster 193 | Size: 13 phrases ===\n",
      "  1. surrounded by\n",
      "  2. bordered by\n",
      "  3. circled by\n",
      "  4. encircled by\n",
      "  5. flanked by\n",
      "----------------------------------------\n",
      "=== Cluster 157 | Size: 13 phrases ===\n",
      "  1. when heading left\n",
      "  2. towards the left\n",
      "  3. to the left\n",
      "  4. to left\n",
      "  5. tipping to the left\n",
      "----------------------------------------\n",
      "=== Cluster 172 | Size: 13 phrases ===\n",
      "  1. suffering reverse\n",
      "  2. reversal\n",
      "  3. reversed\n",
      "  4. reversible\n",
      "  5. reversing\n",
      "----------------------------------------\n",
      "=== Cluster 161 | Size: 12 phrases ===\n",
      "  1. bypassing the odd\n",
      "  2. circumvent\n",
      "  3. circumventing\n",
      "  4. bypassing centre\n",
      "  5. to circumvent\n",
      "----------------------------------------\n",
      "=== Cluster 200 | Size: 12 phrases ===\n",
      "  1. after hacking\n",
      "  2. hack\n",
      "  3. hacked\n",
      "  4. hacking\n",
      "  5. haywire\n",
      "----------------------------------------\n",
      "=== Cluster 108 | Size: 12 phrases ===\n",
      "  1. around\n",
      "  2. around\n",
      "  3. ricochet around\n",
      "  4. around\n",
      "  5. is around\n",
      "----------------------------------------\n",
      "=== Cluster 199 | Size: 12 phrases ===\n",
      "  1. being corrupt\n",
      "  2. being corrupted\n",
      "  3. but corrupt\n",
      "  4. corrupt\n",
      "  5. corruption\n",
      "----------------------------------------\n",
      "=== Cluster 324 | Size: 12 phrases ===\n",
      "  1. being crushed\n",
      "  2. crushed\n",
      "  3. crushing\n",
      "  4. having crushed\n",
      "  5. crushed by\n",
      "----------------------------------------\n",
      "=== Cluster 303 | Size: 12 phrases ===\n",
      "  1. circles\n",
      "  2. circling\n",
      "  3. circles\n",
      "  4. circling\n",
      "  5. circles\n",
      "----------------------------------------\n",
      "=== Cluster 308 | Size: 12 phrases ===\n",
      "  1. clutches\n",
      "  2. clutching\n",
      "  3. clinches\n",
      "  4. clutches\n",
      "  5. clinching\n",
      "----------------------------------------\n",
      "=== Cluster 315 | Size: 12 phrases ===\n",
      "  1. clobber\n",
      "  2. clobbered\n",
      "  3. get squished\n",
      "  4. clobbered\n",
      "  5. quarried\n",
      "----------------------------------------\n",
      "=== Cluster 254 | Size: 12 phrases ===\n",
      "  1. distorted\n",
      "  2. distorting\n",
      "  3. distortion\n",
      "  4. diverging\n",
      "  5. diverted\n",
      "----------------------------------------\n",
      "=== Cluster 162 | Size: 12 phrases ===\n",
      "  1. fall of\n",
      "  2. fallen\n",
      "  3. falls\n",
      "  4. having fallen\n",
      "  5. falling over\n",
      "----------------------------------------\n",
      "=== Cluster 225 | Size: 12 phrases ===\n",
      "  1. hemmed\n",
      "  2. hamper\n",
      "  3. hammers\n",
      "  4. hellish\n",
      "  5. pamper\n",
      "----------------------------------------\n",
      "=== Cluster 89 | Size: 12 phrases ===\n",
      "  1. harboured\n",
      "  2. harboured by\n",
      "  3. harbouring\n",
      "  4. harbours\n",
      "  5. when harbouring\n",
      "----------------------------------------\n",
      "=== Cluster 131 | Size: 12 phrases ===\n",
      "  1. imbibing\n",
      "  2. imbibed\n",
      "  3. ikebana\n",
      "  4. to imbibe\n",
      "  5. imbibed\n",
      "----------------------------------------\n",
      "=== Cluster 185 | Size: 12 phrases ===\n",
      "  1. lop\n",
      "  2. is lax\n",
      "  3. laces\n",
      "  4. lame\n",
      "  5. lamely\n",
      "----------------------------------------\n",
      "=== Cluster 29 | Size: 12 phrases ===\n",
      "  1. obscures\n",
      "  2. obscuring\n",
      "  3. obscuring\n",
      "  4. occult\n",
      "  5. obscura\n",
      "----------------------------------------\n",
      "=== Cluster 265 | Size: 12 phrases ===\n",
      "  1. poured out\n",
      "  2. poured over\n",
      "  3. pour out\n",
      "  4. pour over\n",
      "  5. poured\n",
      "----------------------------------------\n",
      "=== Cluster 228 | Size: 12 phrases ===\n",
      "  1. catching\n",
      "  2. catches\n",
      "  3. catching\n",
      "  4. catch\n",
      "  5. catches\n",
      "----------------------------------------\n",
      "=== Cluster 184 | Size: 12 phrases ===\n",
      "  1. secluded\n",
      "  2. confined\n",
      "  3. confined by\n",
      "  4. confined to\n",
      "  5. confined within\n",
      "----------------------------------------\n",
      "=== Cluster 109 | Size: 12 phrases ===\n",
      "  1. surrounding\n",
      "  2. surrounds\n",
      "  3. environment\n",
      "  4. environment\n",
      "  5. surround\n",
      "----------------------------------------\n",
      "=== Cluster 20 | Size: 12 phrases ===\n",
      "  1. to import\n",
      "  2. import\n",
      "  3. imported\n",
      "  4. importing\n",
      "  5. imports\n",
      "----------------------------------------\n",
      "=== Cluster 111 | Size: 12 phrases ===\n",
      "  1. in the grip of\n",
      "  2. in hands of\n",
      "  3. in possession of\n",
      "  4. in clutches of\n",
      "  5. in grip of\n",
      "----------------------------------------\n",
      "=== Cluster 155 | Size: 12 phrases ===\n",
      "  1. from down under\n",
      "  2. from east of\n",
      "  3. from its east wing\n",
      "  4. from south\n",
      "  5. from the east\n",
      "----------------------------------------\n",
      "=== Cluster 76 | Size: 11 phrases ===\n",
      "  1. at intervals\n",
      "  2. on occasion\n",
      "  3. periodic\n",
      "  4. periodically\n",
      "  5. occasionally\n",
      "----------------------------------------\n",
      "=== Cluster 278 | Size: 11 phrases ===\n",
      "  1. oddly missing\n",
      "  2. missing every other letter\n",
      "  3. missing odd\n",
      "  4. regularly lacking\n",
      "  5. with missing lid\n",
      "----------------------------------------\n",
      "=== Cluster 221 | Size: 11 phrases ===\n",
      "  1. after digesting\n",
      "  2. digested\n",
      "  3. regurgitated\n",
      "  4. digested\n",
      "  5. digests\n",
      "----------------------------------------\n",
      "=== Cluster 272 | Size: 11 phrases ===\n",
      "  1. after embroidery\n",
      "  2. embroidered\n",
      "  3. interweaving\n",
      "  4. to stitch\n",
      "  5. to embroider\n",
      "----------------------------------------\n",
      "=== Cluster 333 | Size: 11 phrases ===\n",
      "  1. after wobble\n",
      "  2. bristling\n",
      "  3. bungling\n",
      "  4. bumbling\n",
      "  5. gobbling\n",
      "----------------------------------------\n",
      "=== Cluster 219 | Size: 11 phrases ===\n",
      "  1. being trained\n",
      "  2. discipline\n",
      "  3. for training\n",
      "  4. in training\n",
      "  5. to be trained\n",
      "----------------------------------------\n",
      "=== Cluster 258 | Size: 11 phrases ===\n",
      "  1. cantering\n",
      "  2. get scattered\n",
      "  3. gets scattered\n",
      "  4. scathing\n",
      "  5. scatter\n",
      "----------------------------------------\n",
      "=== Cluster 341 | Size: 11 phrases ===\n",
      "  1. preposterous\n",
      "  2. perverse\n",
      "  3. perversely\n",
      "  4. perverse\n",
      "  5. perversely\n",
      "----------------------------------------\n",
      "=== Cluster 17 | Size: 11 phrases ===\n",
      "  1. shifted from\n",
      "  2. shifting\n",
      "  3. in shift\n",
      "  4. shift\n",
      "  5. shifted\n",
      "----------------------------------------\n",
      "=== Cluster 153 | Size: 11 phrases ===\n",
      "  1. to recall\n",
      "  2. recalled in\n",
      "  3. recalled in\n",
      "  4. recalling\n",
      "  5. recalls\n",
      "----------------------------------------\n",
      "=== Cluster 124 | Size: 11 phrases ===\n",
      "  1. quoted\n",
      "  2. mention\n",
      "  3. mention of\n",
      "  4. mentioned\n",
      "  5. mentioning\n",
      "----------------------------------------\n",
      "=== Cluster 13 | Size: 11 phrases ===\n",
      "  1. smuggling\n",
      "  2. being smuggled into\n",
      "  3. to smuggle in\n",
      "  4. smuggling\n",
      "  5. smuggled in\n",
      "----------------------------------------\n",
      "=== Cluster 133 | Size: 11 phrases ===\n",
      "  1. taking partial\n",
      "  2. partially\n",
      "  3. partly\n",
      "  4. partial\n",
      "  5. partly helping\n",
      "----------------------------------------\n",
      "=== Cluster 132 | Size: 11 phrases ===\n",
      "  1. read aloud\n",
      "  2. read out loud\n",
      "  3. offered out loud\n",
      "  4. out loud\n",
      "  5. loudly demanding\n",
      "----------------------------------------\n",
      "=== Cluster 139 | Size: 10 phrases ===\n",
      "  1. parts\n",
      "  2. parts of\n",
      "  3. parts\n",
      "  4. phase\n",
      "  5. part\n",
      "----------------------------------------\n",
      "=== Cluster 25 | Size: 10 phrases ===\n",
      "  1. a tranquil ref\n",
      "  2. at ease\n",
      "  3. easily\n",
      "  4. easy\n",
      "  5. comfortably ensconced\n",
      "----------------------------------------\n",
      "=== Cluster 186 | Size: 10 phrases ===\n",
      "  1. after manipulation\n",
      "  2. being manipulated\n",
      "  3. in manipulation of\n",
      "  4. machinations\n",
      "  5. manipulation of\n",
      "----------------------------------------\n",
      "=== Cluster 299 | Size: 10 phrases ===\n",
      "  1. after manoeuvres\n",
      "  2. during manoeuvres\n",
      "  3. for manoeuvring\n",
      "  4. manoeuvre\n",
      "  5. manoeuvred\n",
      "----------------------------------------\n",
      "=== Cluster 46 | Size: 10 phrases ===\n",
      "  1. after negotiation\n",
      "  2. after negotiations\n",
      "  3. being renegotiated\n",
      "  4. for negotiation\n",
      "  5. in negotiation\n",
      "----------------------------------------\n",
      "=== Cluster 337 | Size: 10 phrases ===\n",
      "  1. ambiguous\n",
      "  2. debatable\n",
      "  3. doubtful\n",
      "  4. dubious\n",
      "  5. in doubt\n",
      "----------------------------------------\n",
      "=== Cluster 312 | Size: 10 phrases ===\n",
      "  1. bandied about\n",
      "  2. dashing around\n",
      "  3. going around\n",
      "  4. hops around\n",
      "  5. went around clinging to\n",
      "----------------------------------------\n",
      "=== Cluster 103 | Size: 10 phrases ===\n",
      "  1. being represented\n",
      "  2. is represented\n",
      "  3. letters represented\n",
      "  4. novel representation\n",
      "  5. represent\n",
      "----------------------------------------\n",
      "=== Cluster 246 | Size: 10 phrases ===\n",
      "  1. churn\n",
      "  2. churned\n",
      "  3. churned up\n",
      "  4. churning\n",
      "  5. churning out\n",
      "----------------------------------------\n",
      "=== Cluster 55 | Size: 10 phrases ===\n",
      "  1. drift\n",
      "  2. drifting\n",
      "  3. drifting about\n",
      "  4. drifts\n",
      "  5. having drifted\n",
      "----------------------------------------\n",
      "=== Cluster 142 | Size: 10 phrases ===\n",
      "  1. an element in\n",
      "  2. elements\n",
      "  3. element of\n",
      "  4. elements in\n",
      "  5. component of\n",
      "----------------------------------------\n",
      "=== Cluster 110 | Size: 10 phrases ===\n",
      "  1. posed\n",
      "  2. owning\n",
      "  3. to possess\n",
      "  4. posed\n",
      "  5. possesses\n",
      "----------------------------------------\n",
      "=== Cluster 307 | Size: 10 phrases ===\n",
      "  1. to squeeze\n",
      "  2. squeezing\n",
      "  3. squeezed\n",
      "  4. squeezes\n",
      "  5. has squeezed\n",
      "----------------------------------------\n",
      "=== Cluster 194 | Size: 10 phrases ===\n",
      "  1. frames\n",
      "  2. should frame\n",
      "  3. framed by\n",
      "  4. framing\n",
      "  5. getting framed in\n",
      "----------------------------------------\n",
      "=== Cluster 87 | Size: 10 phrases ===\n",
      "  1. pocketed\n",
      "  2. pockets\n",
      "  3. to pocket\n",
      "  4. pocketing\n",
      "  5. pockets\n",
      "----------------------------------------\n",
      "=== Cluster 51 | Size: 10 phrases ===\n",
      "  1. to restrict\n",
      "  2. restricts\n",
      "  3. will constrain\n",
      "  4. to limit\n",
      "  5. restricting\n",
      "----------------------------------------\n",
      "=== Cluster 269 | Size: 10 phrases ===\n",
      "  1. to trap\n",
      "  2. traps\n",
      "  3. caging\n",
      "  4. to trap\n",
      "  5. traps\n",
      "----------------------------------------\n",
      "=== Cluster 135 | Size: 10 phrases ===\n",
      "  1. view some\n",
      "  2. some\n",
      "  3. some from\n",
      "  4. some items in\n",
      "  5. some of\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate the size of each cluster\n",
    "cluster_counts = df_results[\"cluster\"].value_counts().to_dict()\n",
    "\n",
    "# 3. Get representative phrases (Top 5 by probability)\n",
    "representative_samples = (\n",
    "    df_results[df_results[\"cluster\"] != -1]\n",
    "    .sort_values(\"probability\", ascending=False)\n",
    "    .groupby(\"cluster\")\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "# 4. Print Summary (Sorted by largest clusters first)\n",
    "# Filter out -1 (noise) for the printing loop\n",
    "valid_clusters = [c for c in cluster_counts.keys() if c != -1]\n",
    "sorted_clusters = sorted(valid_clusters, key=lambda x: cluster_counts[x], reverse=True)\n",
    "\n",
    "print(f\"Total Clusters Found: {len(valid_clusters)}\")\n",
    "print(f\"Total Noise Points (Cluster -1): {cluster_counts.get(-1, 0)}\\n\")\n",
    "\n",
    "for cluster_id in sorted_clusters:\n",
    "    size = cluster_counts[cluster_id]\n",
    "    print(f\"=== Cluster {cluster_id} | Size: {size} phrases ===\")\n",
    "\n",
    "    top_phrases = representative_samples[representative_samples[\"cluster\"] == cluster_id][\"phrase\"].tolist()\n",
    "\n",
    "    for i, phrase in enumerate(top_phrases, 1):\n",
    "        print(f\"  {i}. {phrase}\")\n",
    "    print(\"-\" * 40) # Divider for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "opn7JymC-bkR",
    "outputId": "9b53793d-9e2c-498a-ceb8-b078ad7a10e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>cluster</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>will offer</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>pulsing</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>pulled out</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>which shows</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>visiting</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>351</td>\n",
       "      <td>0.731708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>incorrectly</td>\n",
       "      <td>351</td>\n",
       "      <td>0.952843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>in error</td>\n",
       "      <td>351</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>incorrectly delivered</td>\n",
       "      <td>351</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14190</th>\n",
       "      <td>wrongly directed</td>\n",
       "      <td>351</td>\n",
       "      <td>0.740472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      phrase  cluster  probability\n",
       "10208             will offer       -1     0.000000\n",
       "4386                 pulsing       -1     0.000000\n",
       "4383              pulled out       -1     0.000000\n",
       "10203            which shows       -1     0.000000\n",
       "10197               visiting       -1     0.000000\n",
       "...                      ...      ...          ...\n",
       "3105               incorrect      351     0.731708\n",
       "3106             incorrectly      351     0.952843\n",
       "2980                in error      351     1.000000\n",
       "3107   incorrectly delivered      351     1.000000\n",
       "14190       wrongly directed      351     0.740472\n",
       "\n",
       "[14196 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'cluster', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CLWz0M1D-bkR",
    "outputId": "8a162128-2c09-4214-81da-bf9275b5a035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results['cluster'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71CVVJ7hFXvZ"
   },
   "source": [
    "## Performance Comparison\n",
    "\n",
    "We'll compare the clustering above with our group's first attempt to cluster indicators.\n",
    "\n",
    "First Model results from indicators w/ clue context:\n",
    "\n",
    "=== MODEL COMPARISON SUMMARY ===\n",
    "\n",
    "            ARI  Silhouette  MeanVariance\n",
    "\n",
    "DistilRoBERTa 0.005098    0.015992      0.001302\n",
    "\n",
    "\n",
    "MPNet          0.003627    0.014522      0.001302\n",
    "\n",
    "MiniLM         0.003058    0.017184      0.002604\n",
    "\n",
    "CPU times: user 3h 57min 9s, sys: 3min 42s, total: 4h 52s\n",
    "Wall time: 3h 34min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZqxoO5aNvBU",
    "outputId": "c4ee8028-c745-46d2-ac81-5cce79a032d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BGE-M3 + UMAP SUMMARY ===\n",
      "Silhouette Score: 0.292060\n",
      "Mean Variance:    4.463622\n"
     ]
    }
   ],
   "source": [
    "# 1. Silhouette Score\n",
    "# Measures how similar a phrase is to its own cluster vs. other clusters\n",
    "# (Higher is better, range -1 to 1)\n",
    "sil_score = metrics.silhouette_score(embeddings_reduced, clusterer.labels_, metric='cosine')\n",
    "\n",
    "# 2. Mean Variance\n",
    "# Measures the average 'spread' within clusters.\n",
    "# Lower variance usually means tighter, more coherent groups.\n",
    "def mean_variance(data, labels):\n",
    "    variances = []\n",
    "    for cluster in np.unique(labels):\n",
    "        if cluster == -1: continue # Skip noise\n",
    "        cluster_points = data[labels == cluster]\n",
    "        variances.append(np.var(cluster_points))\n",
    "    return np.mean(variances) if variances else 0\n",
    "\n",
    "m_var = mean_variance(embeddings_reduced, clusterer.labels_)\n",
    "\n",
    "# 3. ARI (Adjusted Rand Index)\n",
    "# ONLY run this if you have a variable 'true_labels' (your ground truth)\n",
    "# ari_score = metrics.adjusted_rand_score(true_labels, clusterer.labels_)\n",
    "\n",
    "print(f\"=== BGE-M3 + UMAP SUMMARY ===\")\n",
    "print(f\"Silhouette Score: {sil_score:.6f}\")\n",
    "print(f\"Mean Variance:    {m_var:.6f}\")\n",
    "# print(f\"ARI Score:        {ari_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6WE5iJHPBW-"
   },
   "source": [
    "=== BGE-M3 + UMAP SUMMARY ===\n",
    "\n",
    "Silhouette Score: 0.304369\n",
    "\n",
    "Mean Variance:    5.295987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omibjWMTPGmF"
   },
   "source": [
    "## Technical Interpretation\n",
    "* <b>Silhouette Score (0.30 vs 0.01):</b> A score of 0.30 indicates that the clusters are not just present, but <b>well-separated</b>. In high-dimensional text clustering, anything above 0.25 is typically considered a \"strong\" signal. It means the model has successfully identified dense regions where phrases are significantly closer to each other than they are to phrases in neighboring groups.\n",
    "* <b>Mean Variance (5.29):</b> While this number looks higher than your previous results (~0.001), that is actually an <b>artifact of the math</b>, not a decline in quality. Your previous models were likely \"squashing\" all 14,000 vectors into a tiny, indistinguishable ball near the origin of a 768D space (hence the low variance). This new variance shows that UMAP has \"unfolded\" the data into a 10D space where the phrases have enough \"breathing room\" to form distinct, spread-out islands.\n",
    "## Conceptual Interpretation\n",
    "Conceptually, the difference between your first results and these results is the difference between looking at a crowd from a satellite vs. walking through the crowd.\n",
    "* <b>Previous Models:</b> Saw a blurry mass of words.\n",
    "* <b>BGE-M3 + UMAP:</b> Is seeing the \"groups\" (the 352 clusters). The phrases in Cluster A (e.g., \"alternation\" words) are now mathematically distant from Cluster B (e.g., \"anagram\" words).\n",
    "## Why the jump was so big\n",
    "1. <b>Model Power:</b> BGE-M3 is significantly better at handling short, functional phrases than the \"all-*\" models.\n",
    "2. <b>Noise Removal:</b> UMAP stripped away the 1,014 \"empty\" dimensions that were confusing the Silhouette formula.\n",
    "3. <b>Algorithmic Fit:</b> HDBSCAN is far better at finding \"natural\" shapes in 10D than a standard K-Means approach would be in 768D.\n",
    "### The Verdict:\n",
    "You have moved from a model that was guessing to a model that has learned the underlying structure of your data. The 352 clusters are likely highly reliable.\n",
    "\n",
    "Since you have such a high Silhouette score, we can perform a <b>\"Cluster Cohesion Check\"</b> to see which of those 352 clusters are the \"tightest\" (most synonymous) and which ones are more diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbw-50D8QAt0"
   },
   "source": [
    "## Cluster Cohesion Check\n",
    "\n",
    "To perform a <b>Cluster Cohesion Check</b>, we will calculate the Intra-cluster Distance. This helps you identify which of your 352 clusters are \"Golden Clusters\" (highly synonymous, like \"ignoring the odds\" and \"skipping every other\") versus \"Loose Clusters\" (phrases that share a vibe but aren't strictly identical).\n",
    "\n",
    "We'll use the <b>Medoid</b> (the most central point) as the anchor and measure how far away, on average, the other phrases in that cluster are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_2_GaboIOBv6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "cohesion_results = []\n",
    "\n",
    "# We'll use the reduced 10D embeddings for this\n",
    "for cluster_id in np.unique(clusterer.labels_):\n",
    "    if cluster_id == -1:\n",
    "        continue # Skip noise\n",
    "\n",
    "    # Get points belonging to this cluster\n",
    "    cluster_indices = np.where(clusterer.labels_ == cluster_id)[0]\n",
    "    cluster_points = embeddings_reduced[cluster_indices]\n",
    "\n",
    "    # Find the Medoid (the point with the lowest average distance to all others)\n",
    "    dist_matrix = pairwise_distances(cluster_points, metric='euclidean')\n",
    "    dist_sums = dist_matrix.sum(axis=1)\n",
    "    medoid_idx = np.argmin(dist_sums)\n",
    "\n",
    "    # Calculate average distance to medoid\n",
    "    avg_dist = np.mean(dist_matrix[medoid_idx])\n",
    "\n",
    "    # Store results\n",
    "    cohesion_results.append({\n",
    "        'cluster': cluster_id,\n",
    "        'cohesion_score': avg_dist,\n",
    "        'size': len(cluster_indices),\n",
    "        'representative': verified_indicators_list[cluster_indices[medoid_idx]]\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy analysis\n",
    "df_cohesion = pd.DataFrame(cohesion_results).sort_values('cohesion_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxWmk38OQp4B",
    "outputId": "8f4f06a8-683f-456a-8e81-e7e237235422",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 5 TIGHTEST CLUSTERS (High Cohesion) ===\n",
      "     cluster  cohesion_score  size representative\n",
      "131      131        0.006957    12        imbibed\n",
      "5          5        0.007098    25  being retired\n",
      "11        11        0.008047    18      invest in\n",
      "33        33        0.008129    13      hiding in\n",
      "149      149        0.008435    17     reflection\n",
      "\n",
      "=== TOP 5 LOOSEST CLUSTERS (Low Cohesion) ===\n",
      "     cluster  cohesion_score  size   representative\n",
      "235      235        0.222534    34       creatively\n",
      "331      331        0.237024    47          muddled\n",
      "289      289        0.240192    14            reels\n",
      "187      187        0.287006    70         to house\n",
      "154      154        0.342581    97  to be put right\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== TOP 5 TIGHTEST CLUSTERS (High Cohesion) ===\")\n",
    "print(df_cohesion.head(5)[['cluster', 'cohesion_score', 'size', 'representative']])\n",
    "\n",
    "print(\"\\n=== TOP 5 LOOSEST CLUSTERS (Low Cohesion) ===\")\n",
    "print(df_cohesion.tail(5)[['cluster', 'cohesion_score', 'size', 'representative']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JpF7l1urRpd-",
    "outputId": "a464a325-ced5-4b4c-a979-75ad5c9661bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>cohesion_score</th>\n",
       "      <th>size</th>\n",
       "      <th>representative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0.175856</td>\n",
       "      <td>185</td>\n",
       "      <td>awakening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.133930</td>\n",
       "      <td>150</td>\n",
       "      <td>reshaping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0.145040</td>\n",
       "      <td>150</td>\n",
       "      <td>to return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>0.172197</td>\n",
       "      <td>131</td>\n",
       "      <td>in unusual way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>0.207011</td>\n",
       "      <td>126</td>\n",
       "      <td>scatty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster  cohesion_score  size  representative\n",
       "176      176        0.175856   185       awakening\n",
       "95        95        0.133930   150       reshaping\n",
       "175      175        0.145040   150       to return\n",
       "321      321        0.172197   131  in unusual way\n",
       "327      327        0.207011   126          scatty"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the cohesion for the largest clusters\n",
    "df_cohesion.sort_values(by='size', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cHudCfmSNq8",
    "outputId": "f000c4c7-4175-474b-b35f-d6dddb0fe312"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cohesion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JShZt5sw-bkT"
   },
   "source": [
    "# Agglomerative Clustering (Bottom - Up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1771272902265,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "DHBeLqqq-bkT"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1771273160883,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "aNs9pM9DGNQs",
    "outputId": "aa42d0e0-08af-4de6-a174-366e3097b968"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14196"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verified_indicators_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1771273228206,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "NgnBNfwTG8Hy"
   },
   "outputs": [],
   "source": [
    "embeddings_placeholder = np.random.rand(len(verified_indicators_list), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1771272907631,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "6Mw_XH8e-bkT"
   },
   "outputs": [],
   "source": [
    "# Read the different seeds\n",
    "cc_for_dummies_ALL = pd.read_excel(f'{DATA_DIR}/Wordplay Seeds.xlsx', sheet_name = \"cc_for_dummies_ALL\")\n",
    "cc_for_dummies_ho_6 = pd.read_excel(f'{DATA_DIR}/Wordplay Seeds.xlsx', sheet_name = \"cc_for_dummies_ho_6\")\n",
    "minute_cryptic_ALL = pd.read_excel(f'{DATA_DIR}/Wordplay Seeds.xlsx', sheet_name = \"minute_cryptic_ALL\")\n",
    "minute_cryptic_ho_7 = pd.read_excel(f'{DATA_DIR}/Wordplay Seeds.xlsx', sheet_name = \"minute_cryptic_ho_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bghYX7dz-bkT"
   },
   "outputs": [],
   "source": [
    "seed_category_counts = {'cc_for_dummies_ALL': len(cc_for_dummies_ALL.columns), 'cc_for_dummies_ho_6' : len(cc_for_dummies_ho_6.columns),\n",
    "                       'minute_cryptic_ALL': len(minute_cryptic_ALL.columns), 'minute_cryptic_ho_7': len(minute_cryptic_ho_7.columns)}\n",
    "seed_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1771277862838,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "IEtQtOF7-bkT"
   },
   "outputs": [],
   "source": [
    "indicator_groupings = [cc_for_dummies_ALL, cc_for_dummies_ho_6, minute_cryptic_ALL, minute_cryptic_ho_7]\n",
    "indicator_dicts = []\n",
    "for grouping in indicator_groupings:\n",
    "  grouping_index_lookup = {}\n",
    "  grouping_list = grouping.columns.tolist()\n",
    "  for group in grouping_list:\n",
    "    group_values = grouping[group].values\n",
    "    group_values = group_values[~pd.isna(group_values)]\n",
    "    indexes = []\n",
    "    for value in group_values:\n",
    "      try:\n",
    "        index = verified_indicators_list.index(value)\n",
    "        indexes.append(index)\n",
    "      except ValueError:\n",
    "          pass\n",
    "    grouping_index_lookup[group] = indexes\n",
    "  indicator_dicts.append(grouping_index_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1771277870271,
     "user": {
      "displayName": "Sahana Sundar",
      "userId": "03795334916576235274"
     },
     "user_tz": 480
    },
    "id": "64iGSE70UbBJ",
    "outputId": "4a413870-d474-4335-fc32-b555002b6717"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anagram': [954,\n",
       "  1486,\n",
       "  1323,\n",
       "  1279,\n",
       "  6325,\n",
       "  1858,\n",
       "  6195,\n",
       "  1891,\n",
       "  4144,\n",
       "  1571,\n",
       "  3725,\n",
       "  1834,\n",
       "  978,\n",
       "  6368,\n",
       "  4485,\n",
       "  5175,\n",
       "  600],\n",
       " 'container': [566,\n",
       "  7588,\n",
       "  6848,\n",
       "  7652,\n",
       "  7855,\n",
       "  7167,\n",
       "  7512,\n",
       "  10856,\n",
       "  7767,\n",
       "  7342,\n",
       "  5034],\n",
       " 'hidden': [9600, 7310, 7588, 7107, 9250, 996, 9560, 2347, 7474, 9891, 9985],\n",
       " 'reversal': [12822,\n",
       "  566,\n",
       "  960,\n",
       "  12913,\n",
       "  13030,\n",
       "  2645,\n",
       "  3394,\n",
       "  13568,\n",
       "  13680,\n",
       "  11585,\n",
       "  8891,\n",
       "  13770,\n",
       "  6314,\n",
       "  14081],\n",
       " 'deletion': [4637, 8565, 8899, 4005, 8707, 1475, 8541, 9077],\n",
       " 'deletion_positioning': [],\n",
       " 'homophone': [10505,\n",
       "  10545,\n",
       "  947,\n",
       "  10621,\n",
       "  10346,\n",
       "  10276,\n",
       "  10562,\n",
       "  10608,\n",
       "  10651,\n",
       "  10741],\n",
       " 'charade_positioning': [10836, 10863, 7540, 3528, 9947, 11831, 7770, 8519]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OEG1A92I-bkT"
   },
   "outputs": [],
   "source": [
    "for grouping, num_categories in seed_category_counts.items():\n",
    "    bottom_up_clustering = AgglomerativeClustering(n_clusters = num_categories, linkage = 'ward', compute_distances = True)\n",
    "    bottom_up_clustering_predictions = bottom_up_clustering.fit_predict(embeddings_reduced)\n",
    "    df_bottom_up_results = pd.DataFrame({\n",
    "        \"phrase\": verified_indicators_list,  # The exact list used for model.encode\n",
    "        \"cluster\": bottom_up_clustering.labels_       # The output from clusterer.fit_predict\n",
    "    })\n",
    "    sil_score = metrics.silhouette_score(embeddings_reduced, bottom_up_clustering.labels_, metric='cosine')\n",
    "    seed_results[grouping] = (sil_score, df_bottom_up_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GebJt1mU-bkT",
    "outputId": "45f582c1-c2e7-410b-a208-a58968e7ef38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping:  cc_for_dummies_ALL\n",
      "Number of Groupings : 8\n",
      "Silhouette Score:  0.3847180902957916\n",
      "Grouping:  cc_for_dummies_ho_6\n",
      "Number of Groupings : 6\n",
      "Silhouette Score:  0.4153389036655426\n",
      "Grouping:  minute_cryptic_ALL\n",
      "Number of Groupings : 26\n",
      "Silhouette Score:  0.45207664370536804\n",
      "Grouping:  minute_cryptic_ho_7\n",
      "Number of Groupings : 12\n",
      "Silhouette Score:  0.4649384617805481\n"
     ]
    }
   ],
   "source": [
    "for grouping, results in seed_results.items():\n",
    "    print(\"Grouping: \", grouping)\n",
    "    print(\"Number of Groupings :\", seed_category_counts[grouping])\n",
    "    print(\"Silhouette Score: \", results[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "crossword",
   "language": "python",
   "name": "crossword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}