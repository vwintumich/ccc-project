{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ec790e",
   "metadata": {},
   "source": [
    "# EDA and Data Cleaning for Indicator Clustering\n",
    "Unsupervised Learning Component of Milestone II group project: \n",
    "\n",
    "Exploring Wordplay and Misdirection in Cryptic Crossword Clues with Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8c1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86531dc4",
   "metadata": {},
   "source": [
    "## Data Requirements & Unresolved Dilemmas\n",
    "\n",
    "### Indicator must be a single word\n",
    "We will (initially) represent single words as vectors in a semantic space (words with similar meanings are nearby).\n",
    "\n",
    "* Once we restrict our dataset, do we have enough indicators for clustering (assume $2 < k < 12$)?\n",
    "\n",
    "### Indicator must be a valid word\n",
    "Browsing indicators, it appears some are not valid words. \n",
    "\n",
    "* What dictionary should we use to verify a word is valid? Keep in mind that puzzle creators are often from the UK and Australia, not just the USA.\n",
    "* Look at indicators of unreasonable letter lengths to see <i>how</i> the data is malformed, in case we can correct it? \n",
    "\n",
    "### Exclude an indicator if it comes from a clue that was malformed?\n",
    "If we go back to the `df_clues` dataframe, we could identify all clues (rows) corresponding to malformed data, and then use the `clue_rowid` field in `df_indicators` to exclude those indicators.\n",
    "\n",
    "### When are two indicators \"the same\"?\n",
    "What sort of stemming or lemmatization do we want to use, if any? For example, the \"hidden\" wordplay type in `df_indicators_consolidated` contains some very similar entries for `indicator`:\n",
    "* contribute to\n",
    "* contributes to\n",
    "* contributing\n",
    "* contributing in\n",
    "* contributing to\n",
    "* contribution from\n",
    "* contribution to\n",
    "* contributors to\n",
    "\n",
    "Do we want to preserve part of speech (POS), even if it means we have multiple instances of very similar words (contribute versus contributor)?\n",
    "\n",
    "### When is it appropriate to just define a stopword (and salvage a 2-word indicator)?\n",
    "How important are common words often dismissed as stopwords in NLP, like \"to\", \"in\" and \"from\"? In the \"contribute\" example above, is it safe to drop these words?\n",
    "\n",
    "Or are there words in indicators we can justify excluding based on our domain knowledge of cryptics? How about <a href=\"https://chesterley.github.io/howto/linkwords.htm#:~:text=Wordplay%20devices%20Connectors-,Wordplay%20devices,or%20connectors%20depending%20on%20context.\">common \"link\" words</a>, which function to make the surface reading of a clue more natural and \"link\" the definition to the wordplay. By definition they don't belong to the fodder, indicator, or definition.\n",
    "\n",
    "### BIG PICTURE ISSUE: `wordplay` labels are subjective, interconnected, hierarchical \n",
    "There may not exist clear-cut clusters, even if we had impeccable data.\n",
    "\n",
    "George Ho's wordplay categories don't align with Minute Cryptic (and others), but presumably were aligned with the blogs he scraped. This is relevant if we try constrained clustering (semi-supervised technique), or when we try to interpret unsupervised clustering results. Might be relevant to our choice of clustering algorithms and parameters.\n",
    "\n",
    "Most clear cut and distinct wordplay types:\n",
    "* Anagram\n",
    "* Reversal\n",
    "* Homophone\n",
    "* Hidden\n",
    "\n",
    "These may be messy (because they're opposites?):\n",
    "* Container\n",
    "* Insertion (Ho only), opposite of Container?\n",
    "\n",
    "Messier and interconnected:\n",
    "* Alternation (Ho only), entangled with Deletion? A subset of Selection?\n",
    "* Selection (Minute only), maybe need to define Extraction as a type?\n",
    "* Deletion, entangled with Alternation and Selection?\n",
    "\n",
    "Not sure if this counts as wordplay:\n",
    "* Substitution (Minute only), a wordplay type(?) but no associated indicator, maybe derived from charade?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8540e",
   "metadata": {},
   "source": [
    "## All Tables Available from the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ad991",
   "metadata": {},
   "outputs": [],
   "source": "# Connect to the sqlite3 file\ndata_file = \"../data/data.sqlite3\"\nconn = sqlite3.connect(data_file)"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f41ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see what data tables exist in the file\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "#tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a4e362",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT COUNT(*) AS n FROM clues;': no such table: clues",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/crossword/lib/python3.12/site-packages/pandas/io/sql.py:2702\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2701\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2702\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2703\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: clues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m summary = []\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tables:\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# count rows\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     row_count = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT COUNT(*) AS n FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m.iloc[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# count rows and columns\u001b[39;00m\n\u001b[32m     20\u001b[39m     col_info = pd.read_sql(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPRAGMA table_info(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m);\u001b[39m\u001b[33m\"\u001b[39m, conn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/crossword/lib/python3.12/site-packages/pandas/io/sql.py:702\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m    701\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    714\u001b[39m         _is_table_name = pandas_sql.has_table(sql)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/crossword/lib/python3.12/site-packages/pandas/io/sql.py:2766\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2757\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2764\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2765\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2766\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2767\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/crossword/lib/python3.12/site-packages/pandas/io/sql.py:2714\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2713\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2714\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql 'SELECT COUNT(*) AS n FROM clues;': no such table: clues"
     ]
    }
   ],
   "source": [
    "# Keep track of all tables that might be of interest from the original dataset\n",
    "# Display the names and sizes of all tables.\n",
    "\n",
    "tables = [\n",
    "    \"clues\",\n",
    "    \"indicators\",\n",
    "    \"charades\",\n",
    "    \"indicators_by_clue\",\n",
    "    \"charades_by_clue\",\n",
    "    \"indicators_consolidated\"\n",
    "]\n",
    "\n",
    "summary = []\n",
    "\n",
    "for t in tables:\n",
    "    # count rows\n",
    "    row_count = pd.read_sql(f\"SELECT COUNT(*) AS n FROM {t};\", conn).iloc[0][\"n\"]\n",
    "    \n",
    "    # count rows and columns\n",
    "    col_info = pd.read_sql(f\"PRAGMA table_info({t});\", conn)\n",
    "    col_count = len(col_info)\n",
    "\n",
    "    summary.append({\n",
    "        \"table\": t,\n",
    "        \"rows\": row_count,\n",
    "        \"columns\": col_count\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.style.format({\"rows\": \"{:,}\"}) # display with commas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9bb68",
   "metadata": {},
   "source": [
    "## Tables Useful for Clustering Indicators\n",
    "\n",
    "Create a dataframe for each table involving indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842147a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes related to indicators\n",
    "df_indicators = pd.read_sql(\"SELECT * FROM indicators;\", conn)\n",
    "df_ind_by_clue = pd.read_sql(\"SELECT * FROM indicators_by_clue;\", conn)\n",
    "df_indicators_consolidated = pd.read_sql(\"SELECT * FROM indicators_consolidated;\", conn)\n",
    "\n",
    "# Uncomment to create dataframes pertaining to clue and charade\n",
    "df_clues = pd.read_sql(\"SELECT * FROM clues;\", conn)\n",
    "df_charades = pd.read_sql(\"SELECT * FROM charades;\", conn)\n",
    "df_charades_by_clue = pd.read_sql(\"SELECT * FROM charades_by_clue;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 139327\n",
    "display(df_clues[df_clues['rowid'] == n])\n",
    "display(df_charades_by_clue[df_charades_by_clue['clue_rowid']== n])\n",
    "display(df_indicators[df_indicators['rowid'] == n])\n",
    "display(df_ind_by_clue[df_ind_by_clue[\"clue_rowid\"] == n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa049c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c692287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind_by_clue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab35cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicators_consolidated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457448e",
   "metadata": {},
   "source": [
    "## Requirements & Dilemmas for Unsupervised Learning Data\n",
    "\n",
    "### Indicator must be a single word\n",
    "We will (initially) represent single words as vectors in a semantic space (words with similar meanings are nearby).\n",
    "\n",
    "* Once we restrict our dataset, do we have enough indicators for clustering (assume $2 < k < 12$)?\n",
    "\n",
    "### Indicator must be a valid word\n",
    "Browsing indicators, it appears some are not valid words. \n",
    "\n",
    "* What dictionary should we use to verify a word is valid? Keep in mind that puzzle creators are often from the UK and Australia, not just the USA.\n",
    "* Look at indicators of unreasonable letter lengths to see <i>how</i> the data is malformed, in case we can correct it? \n",
    "\n",
    "### Indicator must not come from a clue that was malformed\n",
    "If we go back to the `df_clues` dataframe, we could identify all clues (rows) corresponding to malformed data, and then use the `clue_rowid` field in `df_indicators` to exclude those indicators.\n",
    "\n",
    "### When are two indicators \"the same\"?\n",
    "What sort of stemming or lemmatization do we want to use, if any? For example, the \"hidden\" wordplay type in `df_indicators_consolidated` contains some very similar entries:\n",
    "* contribute to\n",
    "* contributes to\n",
    "* contributing\n",
    "* contributing in\n",
    "* contributing to\n",
    "* contribution from\n",
    "* contribution to\n",
    "* contributors to\n",
    "\n",
    "Do we want to preserve part of speech (POS), even if it means we have multiple instances of very similar words (contribute versus contributor)?\n",
    "\n",
    "### When is it appropriate to just define a stopword (and salvage a 2-word indicator)?\n",
    "How important are common words often dismissed as stopwords in NLP, like \"to\", \"in\" and \"from\"? In the \"contribute\" example above, is it safe to drop these words?\n",
    "\n",
    "Or are there words in indicators we can justify excluding based on our domain knowledge of cryptics? How about <a href=\"https://chesterley.github.io/howto/linkwords.htm#:~:text=Wordplay%20devices%20Connectors-,Wordplay%20devices,or%20connectors%20depending%20on%20context.\">common \"link\" words</a>, which function to make the surface reading of a clue more natural and \"link\" the definition to the wordplay. By definition they don't belong to the fodder, indicator, or definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61832744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossword",
   "language": "python",
   "name": "crossword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}